{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59110,"databundleVersionId":6536030,"sourceType":"competition"},{"sourceId":3102326,"sourceType":"datasetVersion","datasetId":1894788}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# imports","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import get_scorer_names\nimport optuna \nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import learning_curve\n\n#############################\nimport lightgbm as lgb\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom scipy import stats\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n#################################\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.datasets import load_iris\nfrom sklearn.feature_selection import SelectKBest, chi2\nimport warnings\nwarnings.filterwarnings('ignore')\nimport missingno as msno\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.impute import KNNImputer\nfrom sklearn.feature_selection import SelectKBest, f_classif","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:30.011562Z","iopub.execute_input":"2023-10-02T16:23:30.011950Z","iopub.status.idle":"2023-10-02T16:23:30.020219Z","shell.execute_reply.started":"2023-10-02T16:23:30.011921Z","shell.execute_reply":"2023-10-02T16:23:30.018709Z"},"trusted":true},"execution_count":660,"outputs":[]},{"cell_type":"markdown","source":"# Data loading","metadata":{}},{"cell_type":"code","source":"trainx = pd.read_csv('../input/playground-series-s3e22/train.csv')\ntest = pd.read_csv('../input/playground-series-s3e22/test.csv')\noriginal = pd.read_csv('../input/horse-survival-dataset/horse.csv')\nsubmission = pd.read_csv('../input/playground-series-s3e22/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:30.064923Z","iopub.execute_input":"2023-10-02T16:23:30.065337Z","iopub.status.idle":"2023-10-02T16:23:30.099016Z","shell.execute_reply.started":"2023-10-02T16:23:30.065297Z","shell.execute_reply":"2023-10-02T16:23:30.098197Z"},"trusted":true},"execution_count":661,"outputs":[]},{"cell_type":"code","source":"train = pd.concat([trainx, original], ignore_index=True)\ntrain.drop_duplicates(inplace=True)\ntotal = pd.concat([train, test], ignore_index=True)\ntarget='outcome'","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:30.130504Z","iopub.execute_input":"2023-10-02T16:23:30.131589Z","iopub.status.idle":"2023-10-02T16:23:30.152448Z","shell.execute_reply.started":"2023-10-02T16:23:30.131551Z","shell.execute_reply":"2023-10-02T16:23:30.151474Z"},"trusted":true},"execution_count":662,"outputs":[]},{"cell_type":"markdown","source":"concatenating  the train dataset with the original dataset for later analysis to later check if it would positively affect the model performance ( update : it did )  ","metadata":{}},{"cell_type":"code","source":"print('The dimension of the total dataset is:', total.shape)\nprint('The dimension of the test dataset is:', test.shape)\nprint('The dimension of the original train dataset is:', original.shape)\nprint('The dimension of the train dataset is:', trainx.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:30.201650Z","iopub.execute_input":"2023-10-02T16:23:30.202471Z","iopub.status.idle":"2023-10-02T16:23:30.208583Z","shell.execute_reply.started":"2023-10-02T16:23:30.202434Z","shell.execute_reply":"2023-10-02T16:23:30.207380Z"},"trusted":true},"execution_count":663,"outputs":[{"name":"stdout","text":"The dimension of the total dataset is: (2358, 29)\nThe dimension of the test dataset is: (824, 28)\nThe dimension of the original train dataset is: (299, 28)\nThe dimension of the train dataset is: (1235, 29)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# EDA and preprocessing","metadata":{}},{"cell_type":"code","source":"\nfiltered_data = train[(train['peripheral_pulse'] =='reduced') ]\n\n\nprint(filtered_data['outcome'])\nplt.figure(figsize=(8, 6))  \nsns.countplot(data=filtered_data, x='outcome')\n\n\nplt.xlabel('Outcome')\nplt.ylabel('Count')\nplt.title('Count Plot of Outcome for Filtered Data')\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:30.270058Z","iopub.execute_input":"2023-10-02T16:23:30.270395Z","iopub.status.idle":"2023-10-02T16:23:30.496275Z","shell.execute_reply.started":"2023-10-02T16:23:30.270369Z","shell.execute_reply":"2023-10-02T16:23:30.494988Z"},"trusted":true},"execution_count":664,"outputs":[{"name":"stdout","text":"0             died\n2            lived\n3            lived\n6       euthanized\n7             died\n           ...    \n1525          died\n1526          died\n1527    euthanized\n1531          died\n1532         lived\nName: outcome, Length: 827, dtype: object\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"total.drop('id',axis=1,inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:30.498585Z","iopub.execute_input":"2023-10-02T16:23:30.499295Z","iopub.status.idle":"2023-10-02T16:23:30.507064Z","shell.execute_reply.started":"2023-10-02T16:23:30.499252Z","shell.execute_reply":"2023-10-02T16:23:30.505546Z"},"trusted":true},"execution_count":665,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data = total, x = 'outcome')\nplt.ylabel('Frequency');","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:30.508695Z","iopub.execute_input":"2023-10-02T16:23:30.509289Z","iopub.status.idle":"2023-10-02T16:23:30.760569Z","shell.execute_reply.started":"2023-10-02T16:23:30.509246Z","shell.execute_reply":"2023-10-02T16:23:30.759425Z"},"trusted":true},"execution_count":666,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"0->died\n\n1->euthanized\n\n2->lived","metadata":{}},{"cell_type":"code","source":"\n# # Criteria 1: Normal in abdominal_distention and severe in abdominal appearance\n# criteria1_count = len(total[(total['abdominal_distention'] == 'slight') & (total['abdomo_appearance'] == 'clear')])\n\n# # Criteria 2: Normal in abdominal_distention and cloudy in abdominal appearance\n# criteria2_count = len(total[(total['abdominal_distention'] == 'normal') & (total['abdomo_appearance'] == 'cloudy')])\n\n# # Criteria 3: Normal in abdominal_distention and serosanguinous in abdominal appearance\n# criteria3_count = len(total[(total['abdominal_distention'] == 'severe') & (total['abdomo_appearance'] == 'serosanguinous')])\n\n# # Print the outcomes\n# print(f\"Number of rows with 'slight' in abdominal_distention and 'clear' in abdominal appearance: {criteria1_count}\")\n# print(f\"Number of rows with 'Normal' in abdominal_distention and 'Cloudy' in abdominal appearance: {criteria2_count}\")\n# print(f\"Number of rows with 'severe' in abdominal_distention and 'Serosanguinous' in abdominal appearance: {criteria3_count}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:30.762465Z","iopub.execute_input":"2023-10-02T16:23:30.762794Z","iopub.status.idle":"2023-10-02T16:23:30.771724Z","shell.execute_reply.started":"2023-10-02T16:23:30.762765Z","shell.execute_reply":"2023-10-02T16:23:30.770451Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":667,"outputs":[]},{"cell_type":"code","source":"# # Assuming your DataFrame is named 'total' and the target variable is 'outcome'\n\n# # Filter rows based on criteria\n# filtered_rows = train[(train['abdominal_distention'] == 'severe') & (train['abdomo_appearance'] == 'cloudy')]\n\n# # Create a histogram of the 'outcome' variable for the filtered rows\n# plt.figure(figsize=(8, 6))\n# sns.histplot(data=filtered_rows, x='outcome', bins=2, discrete=True)\n# plt.xlabel(\"Outcome\")\n# plt.ylabel(\"Frequency\")\n# plt.title(\"Histogram of 'Outcome' Variable for Filtered Rows\")\n# plt.xticks([0, 1 ,2])  # Assuming binary outcome (0 and 1)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:30.774339Z","iopub.execute_input":"2023-10-02T16:23:30.774845Z","iopub.status.idle":"2023-10-02T16:23:30.789929Z","shell.execute_reply.started":"2023-10-02T16:23:30.774812Z","shell.execute_reply":"2023-10-02T16:23:30.789105Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":668,"outputs":[]},{"cell_type":"code","source":"\n# total.drop('cp_data',axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.098232Z","iopub.execute_input":"2023-10-02T16:23:31.099086Z","iopub.status.idle":"2023-10-02T16:23:31.104648Z","shell.execute_reply.started":"2023-10-02T16:23:31.099043Z","shell.execute_reply":"2023-10-02T16:23:31.103295Z"},"trusted":true},"execution_count":669,"outputs":[]},{"cell_type":"markdown","source":"***removing CP data has worsen the model , which i expected after analysing the data , CP data has effectively helped with deciding if the horse needed to be euthanized or not ***","metadata":{}},{"cell_type":"code","source":"categorical_feats=[]\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.139493Z","iopub.execute_input":"2023-10-02T16:23:31.139890Z","iopub.status.idle":"2023-10-02T16:23:31.148436Z","shell.execute_reply.started":"2023-10-02T16:23:31.139839Z","shell.execute_reply":"2023-10-02T16:23:31.147127Z"},"trusted":true},"execution_count":670,"outputs":[]},{"cell_type":"code","source":"for column in total.columns:\n  \n    if total[column].dtype == 'object':\n        \n        categorical_feats.append(column)\n\n\nprint(categorical_feats)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.195782Z","iopub.execute_input":"2023-10-02T16:23:31.196517Z","iopub.status.idle":"2023-10-02T16:23:31.203884Z","shell.execute_reply.started":"2023-10-02T16:23:31.196480Z","shell.execute_reply":"2023-10-02T16:23:31.202356Z"},"trusted":true},"execution_count":671,"outputs":[{"name":"stdout","text":"['surgery', 'age', 'temp_of_extremities', 'peripheral_pulse', 'mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis', 'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', 'rectal_exam_feces', 'abdomen', 'abdomo_appearance', 'surgical_lesion', 'cp_data', 'outcome']\n","output_type":"stream"}]},{"cell_type":"code","source":"categorical_feats.remove('outcome')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.238405Z","iopub.execute_input":"2023-10-02T16:23:31.238967Z","iopub.status.idle":"2023-10-02T16:23:31.243063Z","shell.execute_reply.started":"2023-10-02T16:23:31.238936Z","shell.execute_reply":"2023-10-02T16:23:31.242268Z"},"trusted":true},"execution_count":672,"outputs":[]},{"cell_type":"code","source":"numerical_features = []\n\n\nfor column in total.columns:\n    \n    if pd.api.types.is_numeric_dtype(total[column]):\n     \n        numerical_features.append(column)\n\n\nprint(numerical_features)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.286038Z","iopub.execute_input":"2023-10-02T16:23:31.286616Z","iopub.status.idle":"2023-10-02T16:23:31.295901Z","shell.execute_reply.started":"2023-10-02T16:23:31.286584Z","shell.execute_reply":"2023-10-02T16:23:31.294699Z"},"trusted":true},"execution_count":673,"outputs":[{"name":"stdout","text":"['hospital_number', 'rectal_temp', 'pulse', 'respiratory_rate', 'nasogastric_reflux_ph', 'packed_cell_volume', 'total_protein', 'abdomo_protein', 'lesion_1', 'lesion_2', 'lesion_3']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.options.display.float_format = '{:,.2f}'.format\ndef summary(df):\n    print(f'data shape: {df.shape}')\n    summ = pd.DataFrame(df.dtypes, columns=['data type'])\n    summ['#missing'] = df.isnull().sum().values \n    summ['%missing'] = df.isnull().sum().values / len(df) * 100\n    summ['#unique'] = df.nunique().values\n    desc = pd.DataFrame(df.describe(include='all').transpose())\n    summ['min'] = desc['min'].values\n    summ['max'] = desc['max'].values\n    summ['average'] = desc['mean'].values\n    summ['standard_deviation'] = desc['std'].values\n    summ['first value'] = df.loc[0].values\n    summ['second value'] = df.loc[1].values\n    summ['third value'] = df.loc[2].values\n    \n    return summ","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.366149Z","iopub.execute_input":"2023-10-02T16:23:31.366746Z","iopub.status.idle":"2023-10-02T16:23:31.374369Z","shell.execute_reply.started":"2023-10-02T16:23:31.366715Z","shell.execute_reply":"2023-10-02T16:23:31.372927Z"},"trusted":true},"execution_count":674,"outputs":[]},{"cell_type":"code","source":"summary(total).style.background_gradient(cmap='YlOrBr')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.406230Z","iopub.execute_input":"2023-10-02T16:23:31.406573Z","iopub.status.idle":"2023-10-02T16:23:31.497114Z","shell.execute_reply.started":"2023-10-02T16:23:31.406547Z","shell.execute_reply":"2023-10-02T16:23:31.496131Z"},"trusted":true},"execution_count":675,"outputs":[{"name":"stdout","text":"data shape: (2358, 28)\n","output_type":"stream"},{"execution_count":675,"output_type":"execute_result","data":{"text/plain":"<pandas.io.formats.style.Styler at 0x7d0f56021570>","text/html":"<style type=\"text/css\">\n#T_6362b_row0_col1, #T_6362b_row0_col2, #T_6362b_row0_col3, #T_6362b_row1_col1, #T_6362b_row1_col2, #T_6362b_row1_col3, #T_6362b_row2_col1, #T_6362b_row2_col2, #T_6362b_row9_col3, #T_6362b_row13_col3, #T_6362b_row20_col3, #T_6362b_row22_col1, #T_6362b_row22_col2, #T_6362b_row22_col3, #T_6362b_row23_col1, #T_6362b_row23_col2, #T_6362b_row24_col1, #T_6362b_row24_col2, #T_6362b_row25_col1, #T_6362b_row25_col2, #T_6362b_row25_col3, #T_6362b_row26_col1, #T_6362b_row26_col2, #T_6362b_row26_col3, #T_6362b_row27_col3 {\n  background-color: #ffffe5;\n  color: #000000;\n}\n#T_6362b_row2_col3, #T_6362b_row27_col1, #T_6362b_row27_col2 {\n  background-color: #662506;\n  color: #f1f1f1;\n}\n#T_6362b_row3_col1, #T_6362b_row3_col2, #T_6362b_row5_col1, #T_6362b_row5_col2 {\n  background-color: #ffface;\n  color: #000000;\n}\n#T_6362b_row3_col3, #T_6362b_row5_col3 {\n  background-color: #fff4b6;\n  color: #000000;\n}\n#T_6362b_row4_col1, #T_6362b_row4_col2 {\n  background-color: #fffddc;\n  color: #000000;\n}\n#T_6362b_row4_col3 {\n  background-color: #ffefac;\n  color: #000000;\n}\n#T_6362b_row6_col1, #T_6362b_row6_col2 {\n  background-color: #fff2b1;\n  color: #000000;\n}\n#T_6362b_row6_col3, #T_6362b_row7_col3, #T_6362b_row12_col3, #T_6362b_row14_col3 {\n  background-color: #ffffe4;\n  color: #000000;\n}\n#T_6362b_row7_col1, #T_6362b_row7_col2 {\n  background-color: #fee99e;\n  color: #000000;\n}\n#T_6362b_row8_col1, #T_6362b_row8_col2, #T_6362b_row11_col1, #T_6362b_row11_col2 {\n  background-color: #fff9c5;\n  color: #000000;\n}\n#T_6362b_row8_col3 {\n  background-color: #fffee1;\n  color: #000000;\n}\n#T_6362b_row9_col1, #T_6362b_row9_col2 {\n  background-color: #fffcd4;\n  color: #000000;\n}\n#T_6362b_row10_col1, #T_6362b_row10_col2 {\n  background-color: #fff3b2;\n  color: #000000;\n}\n#T_6362b_row10_col3, #T_6362b_row24_col3 {\n  background-color: #fffee0;\n  color: #000000;\n}\n#T_6362b_row11_col3, #T_6362b_row16_col3, #T_6362b_row17_col3 {\n  background-color: #fffee2;\n  color: #000000;\n}\n#T_6362b_row12_col1, #T_6362b_row12_col2 {\n  background-color: #fff7bd;\n  color: #000000;\n}\n#T_6362b_row13_col1, #T_6362b_row13_col2 {\n  background-color: #fed676;\n  color: #000000;\n}\n#T_6362b_row14_col1, #T_6362b_row14_col2, #T_6362b_row18_col3 {\n  background-color: #fff0ad;\n  color: #000000;\n}\n#T_6362b_row15_col1, #T_6362b_row15_col2 {\n  background-color: #fed778;\n  color: #000000;\n}\n#T_6362b_row15_col3 {\n  background-color: #fff9c6;\n  color: #000000;\n}\n#T_6362b_row16_col1, #T_6362b_row16_col2 {\n  background-color: #fd9728;\n  color: #000000;\n}\n#T_6362b_row17_col1, #T_6362b_row17_col2 {\n  background-color: #f17c1a;\n  color: #f1f1f1;\n}\n#T_6362b_row18_col1, #T_6362b_row18_col2 {\n  background-color: #fffdd9;\n  color: #000000;\n}\n#T_6362b_row19_col1, #T_6362b_row19_col2 {\n  background-color: #fffcd8;\n  color: #000000;\n}\n#T_6362b_row19_col3, #T_6362b_row20_col1, #T_6362b_row20_col2 {\n  background-color: #fed87a;\n  color: #000000;\n}\n#T_6362b_row21_col1, #T_6362b_row21_col2 {\n  background-color: #fee595;\n  color: #000000;\n}\n#T_6362b_row21_col3 {\n  background-color: #feeba2;\n  color: #000000;\n}\n#T_6362b_row23_col3 {\n  background-color: #fee89b;\n  color: #000000;\n}\n</style>\n<table id=\"T_6362b\">\n  <thead>\n    <tr>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_6362b_level0_col0\" class=\"col_heading level0 col0\" >data type</th>\n      <th id=\"T_6362b_level0_col1\" class=\"col_heading level0 col1\" >#missing</th>\n      <th id=\"T_6362b_level0_col2\" class=\"col_heading level0 col2\" >%missing</th>\n      <th id=\"T_6362b_level0_col3\" class=\"col_heading level0 col3\" >#unique</th>\n      <th id=\"T_6362b_level0_col4\" class=\"col_heading level0 col4\" >min</th>\n      <th id=\"T_6362b_level0_col5\" class=\"col_heading level0 col5\" >max</th>\n      <th id=\"T_6362b_level0_col6\" class=\"col_heading level0 col6\" >average</th>\n      <th id=\"T_6362b_level0_col7\" class=\"col_heading level0 col7\" >standard_deviation</th>\n      <th id=\"T_6362b_level0_col8\" class=\"col_heading level0 col8\" >first value</th>\n      <th id=\"T_6362b_level0_col9\" class=\"col_heading level0 col9\" >second value</th>\n      <th id=\"T_6362b_level0_col10\" class=\"col_heading level0 col10\" >third value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_6362b_level0_row0\" class=\"row_heading level0 row0\" >surgery</th>\n      <td id=\"T_6362b_row0_col0\" class=\"data row0 col0\" >object</td>\n      <td id=\"T_6362b_row0_col1\" class=\"data row0 col1\" >0</td>\n      <td id=\"T_6362b_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n      <td id=\"T_6362b_row0_col3\" class=\"data row0 col3\" >2</td>\n      <td id=\"T_6362b_row0_col4\" class=\"data row0 col4\" >nan</td>\n      <td id=\"T_6362b_row0_col5\" class=\"data row0 col5\" >nan</td>\n      <td id=\"T_6362b_row0_col6\" class=\"data row0 col6\" >nan</td>\n      <td id=\"T_6362b_row0_col7\" class=\"data row0 col7\" >nan</td>\n      <td id=\"T_6362b_row0_col8\" class=\"data row0 col8\" >yes</td>\n      <td id=\"T_6362b_row0_col9\" class=\"data row0 col9\" >yes</td>\n      <td id=\"T_6362b_row0_col10\" class=\"data row0 col10\" >yes</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row1\" class=\"row_heading level0 row1\" >age</th>\n      <td id=\"T_6362b_row1_col0\" class=\"data row1 col0\" >object</td>\n      <td id=\"T_6362b_row1_col1\" class=\"data row1 col1\" >0</td>\n      <td id=\"T_6362b_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n      <td id=\"T_6362b_row1_col3\" class=\"data row1 col3\" >2</td>\n      <td id=\"T_6362b_row1_col4\" class=\"data row1 col4\" >nan</td>\n      <td id=\"T_6362b_row1_col5\" class=\"data row1 col5\" >nan</td>\n      <td id=\"T_6362b_row1_col6\" class=\"data row1 col6\" >nan</td>\n      <td id=\"T_6362b_row1_col7\" class=\"data row1 col7\" >nan</td>\n      <td id=\"T_6362b_row1_col8\" class=\"data row1 col8\" >adult</td>\n      <td id=\"T_6362b_row1_col9\" class=\"data row1 col9\" >adult</td>\n      <td id=\"T_6362b_row1_col10\" class=\"data row1 col10\" >adult</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row2\" class=\"row_heading level0 row2\" >hospital_number</th>\n      <td id=\"T_6362b_row2_col0\" class=\"data row2 col0\" >int64</td>\n      <td id=\"T_6362b_row2_col1\" class=\"data row2 col1\" >0</td>\n      <td id=\"T_6362b_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n      <td id=\"T_6362b_row2_col3\" class=\"data row2 col3\" >289</td>\n      <td id=\"T_6362b_row2_col4\" class=\"data row2 col4\" >518476.000000</td>\n      <td id=\"T_6362b_row2_col5\" class=\"data row2 col5\" >5305629.000000</td>\n      <td id=\"T_6362b_row2_col6\" class=\"data row2 col6\" >1025159.628923</td>\n      <td id=\"T_6362b_row2_col7\" class=\"data row2 col7\" >1452759.343805</td>\n      <td id=\"T_6362b_row2_col8\" class=\"data row2 col8\" >530001</td>\n      <td id=\"T_6362b_row2_col9\" class=\"data row2 col9\" >533836</td>\n      <td id=\"T_6362b_row2_col10\" class=\"data row2 col10\" >529812</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row3\" class=\"row_heading level0 row3\" >rectal_temp</th>\n      <td id=\"T_6362b_row3_col0\" class=\"data row3 col0\" >float64</td>\n      <td id=\"T_6362b_row3_col1\" class=\"data row3 col1\" >60</td>\n      <td id=\"T_6362b_row3_col2\" class=\"data row3 col2\" >2.544529</td>\n      <td id=\"T_6362b_row3_col3\" class=\"data row3 col3\" >43</td>\n      <td id=\"T_6362b_row3_col4\" class=\"data row3 col4\" >35.400000</td>\n      <td id=\"T_6362b_row3_col5\" class=\"data row3 col5\" >40.800000</td>\n      <td id=\"T_6362b_row3_col6\" class=\"data row3 col6\" >38.213882</td>\n      <td id=\"T_6362b_row3_col7\" class=\"data row3 col7\" >0.781971</td>\n      <td id=\"T_6362b_row3_col8\" class=\"data row3 col8\" >38.100000</td>\n      <td id=\"T_6362b_row3_col9\" class=\"data row3 col9\" >37.500000</td>\n      <td id=\"T_6362b_row3_col10\" class=\"data row3 col10\" >38.300000</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row4\" class=\"row_heading level0 row4\" >pulse</th>\n      <td id=\"T_6362b_row4_col0\" class=\"data row4 col0\" >float64</td>\n      <td id=\"T_6362b_row4_col1\" class=\"data row4 col1\" >24</td>\n      <td id=\"T_6362b_row4_col2\" class=\"data row4 col2\" >1.017812</td>\n      <td id=\"T_6362b_row4_col3\" class=\"data row4 col3\" >52</td>\n      <td id=\"T_6362b_row4_col4\" class=\"data row4 col4\" >30.000000</td>\n      <td id=\"T_6362b_row4_col5\" class=\"data row4 col5\" >184.000000</td>\n      <td id=\"T_6362b_row4_col6\" class=\"data row4 col6\" >78.913025</td>\n      <td id=\"T_6362b_row4_col7\" class=\"data row4 col7\" >29.173259</td>\n      <td id=\"T_6362b_row4_col8\" class=\"data row4 col8\" >132.000000</td>\n      <td id=\"T_6362b_row4_col9\" class=\"data row4 col9\" >88.000000</td>\n      <td id=\"T_6362b_row4_col10\" class=\"data row4 col10\" >120.000000</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row5\" class=\"row_heading level0 row5\" >respiratory_rate</th>\n      <td id=\"T_6362b_row5_col0\" class=\"data row5 col0\" >float64</td>\n      <td id=\"T_6362b_row5_col1\" class=\"data row5 col1\" >58</td>\n      <td id=\"T_6362b_row5_col2\" class=\"data row5 col2\" >2.459712</td>\n      <td id=\"T_6362b_row5_col3\" class=\"data row5 col3\" >43</td>\n      <td id=\"T_6362b_row5_col4\" class=\"data row5 col4\" >8.000000</td>\n      <td id=\"T_6362b_row5_col5\" class=\"data row5 col5\" >96.000000</td>\n      <td id=\"T_6362b_row5_col6\" class=\"data row5 col6\" >30.335217</td>\n      <td id=\"T_6362b_row5_col7\" class=\"data row5 col7\" >16.933441</td>\n      <td id=\"T_6362b_row5_col8\" class=\"data row5 col8\" >24.000000</td>\n      <td id=\"T_6362b_row5_col9\" class=\"data row5 col9\" >12.000000</td>\n      <td id=\"T_6362b_row5_col10\" class=\"data row5 col10\" >28.000000</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row6\" class=\"row_heading level0 row6\" >temp_of_extremities</th>\n      <td id=\"T_6362b_row6_col0\" class=\"data row6 col0\" >object</td>\n      <td id=\"T_6362b_row6_col1\" class=\"data row6 col1\" >130</td>\n      <td id=\"T_6362b_row6_col2\" class=\"data row6 col2\" >5.513147</td>\n      <td id=\"T_6362b_row6_col3\" class=\"data row6 col3\" >4</td>\n      <td id=\"T_6362b_row6_col4\" class=\"data row6 col4\" >nan</td>\n      <td id=\"T_6362b_row6_col5\" class=\"data row6 col5\" >nan</td>\n      <td id=\"T_6362b_row6_col6\" class=\"data row6 col6\" >nan</td>\n      <td id=\"T_6362b_row6_col7\" class=\"data row6 col7\" >nan</td>\n      <td id=\"T_6362b_row6_col8\" class=\"data row6 col8\" >cool</td>\n      <td id=\"T_6362b_row6_col9\" class=\"data row6 col9\" >cool</td>\n      <td id=\"T_6362b_row6_col10\" class=\"data row6 col10\" >cool</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row7\" class=\"row_heading level0 row7\" >peripheral_pulse</th>\n      <td id=\"T_6362b_row7_col0\" class=\"data row7 col0\" >object</td>\n      <td id=\"T_6362b_row7_col1\" class=\"data row7 col1\" >176</td>\n      <td id=\"T_6362b_row7_col2\" class=\"data row7 col2\" >7.463953</td>\n      <td id=\"T_6362b_row7_col3\" class=\"data row7 col3\" >4</td>\n      <td id=\"T_6362b_row7_col4\" class=\"data row7 col4\" >nan</td>\n      <td id=\"T_6362b_row7_col5\" class=\"data row7 col5\" >nan</td>\n      <td id=\"T_6362b_row7_col6\" class=\"data row7 col6\" >nan</td>\n      <td id=\"T_6362b_row7_col7\" class=\"data row7 col7\" >nan</td>\n      <td id=\"T_6362b_row7_col8\" class=\"data row7 col8\" >reduced</td>\n      <td id=\"T_6362b_row7_col9\" class=\"data row7 col9\" >normal</td>\n      <td id=\"T_6362b_row7_col10\" class=\"data row7 col10\" >reduced</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row8\" class=\"row_heading level0 row8\" >mucous_membrane</th>\n      <td id=\"T_6362b_row8_col0\" class=\"data row8 col0\" >object</td>\n      <td id=\"T_6362b_row8_col1\" class=\"data row8 col1\" >81</td>\n      <td id=\"T_6362b_row8_col2\" class=\"data row8 col2\" >3.435115</td>\n      <td id=\"T_6362b_row8_col3\" class=\"data row8 col3\" >6</td>\n      <td id=\"T_6362b_row8_col4\" class=\"data row8 col4\" >nan</td>\n      <td id=\"T_6362b_row8_col5\" class=\"data row8 col5\" >nan</td>\n      <td id=\"T_6362b_row8_col6\" class=\"data row8 col6\" >nan</td>\n      <td id=\"T_6362b_row8_col7\" class=\"data row8 col7\" >nan</td>\n      <td id=\"T_6362b_row8_col8\" class=\"data row8 col8\" >dark_cyanotic</td>\n      <td id=\"T_6362b_row8_col9\" class=\"data row8 col9\" >pale_cyanotic</td>\n      <td id=\"T_6362b_row8_col10\" class=\"data row8 col10\" >pale_pink</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row9\" class=\"row_heading level0 row9\" >capillary_refill_time</th>\n      <td id=\"T_6362b_row9_col0\" class=\"data row9 col0\" >object</td>\n      <td id=\"T_6362b_row9_col1\" class=\"data row9 col1\" >44</td>\n      <td id=\"T_6362b_row9_col2\" class=\"data row9 col2\" >1.865988</td>\n      <td id=\"T_6362b_row9_col3\" class=\"data row9 col3\" >3</td>\n      <td id=\"T_6362b_row9_col4\" class=\"data row9 col4\" >nan</td>\n      <td id=\"T_6362b_row9_col5\" class=\"data row9 col5\" >nan</td>\n      <td id=\"T_6362b_row9_col6\" class=\"data row9 col6\" >nan</td>\n      <td id=\"T_6362b_row9_col7\" class=\"data row9 col7\" >nan</td>\n      <td id=\"T_6362b_row9_col8\" class=\"data row9 col8\" >more_3_sec</td>\n      <td id=\"T_6362b_row9_col9\" class=\"data row9 col9\" >more_3_sec</td>\n      <td id=\"T_6362b_row9_col10\" class=\"data row9 col10\" >less_3_sec</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row10\" class=\"row_heading level0 row10\" >pain</th>\n      <td id=\"T_6362b_row10_col0\" class=\"data row10 col0\" >object</td>\n      <td id=\"T_6362b_row10_col1\" class=\"data row10 col1\" >128</td>\n      <td id=\"T_6362b_row10_col2\" class=\"data row10 col2\" >5.428329</td>\n      <td id=\"T_6362b_row10_col3\" class=\"data row10 col3\" >7</td>\n      <td id=\"T_6362b_row10_col4\" class=\"data row10 col4\" >nan</td>\n      <td id=\"T_6362b_row10_col5\" class=\"data row10 col5\" >nan</td>\n      <td id=\"T_6362b_row10_col6\" class=\"data row10 col6\" >nan</td>\n      <td id=\"T_6362b_row10_col7\" class=\"data row10 col7\" >nan</td>\n      <td id=\"T_6362b_row10_col8\" class=\"data row10 col8\" >depressed</td>\n      <td id=\"T_6362b_row10_col9\" class=\"data row10 col9\" >mild_pain</td>\n      <td id=\"T_6362b_row10_col10\" class=\"data row10 col10\" >extreme_pain</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row11\" class=\"row_heading level0 row11\" >peristalsis</th>\n      <td id=\"T_6362b_row11_col0\" class=\"data row11 col0\" >object</td>\n      <td id=\"T_6362b_row11_col1\" class=\"data row11 col1\" >83</td>\n      <td id=\"T_6362b_row11_col2\" class=\"data row11 col2\" >3.519932</td>\n      <td id=\"T_6362b_row11_col3\" class=\"data row11 col3\" >5</td>\n      <td id=\"T_6362b_row11_col4\" class=\"data row11 col4\" >nan</td>\n      <td id=\"T_6362b_row11_col5\" class=\"data row11 col5\" >nan</td>\n      <td id=\"T_6362b_row11_col6\" class=\"data row11 col6\" >nan</td>\n      <td id=\"T_6362b_row11_col7\" class=\"data row11 col7\" >nan</td>\n      <td id=\"T_6362b_row11_col8\" class=\"data row11 col8\" >absent</td>\n      <td id=\"T_6362b_row11_col9\" class=\"data row11 col9\" >absent</td>\n      <td id=\"T_6362b_row11_col10\" class=\"data row11 col10\" >hypomotile</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row12\" class=\"row_heading level0 row12\" >abdominal_distention</th>\n      <td id=\"T_6362b_row12_col0\" class=\"data row12 col0\" >object</td>\n      <td id=\"T_6362b_row12_col1\" class=\"data row12 col1\" >101</td>\n      <td id=\"T_6362b_row12_col2\" class=\"data row12 col2\" >4.283291</td>\n      <td id=\"T_6362b_row12_col3\" class=\"data row12 col3\" >4</td>\n      <td id=\"T_6362b_row12_col4\" class=\"data row12 col4\" >nan</td>\n      <td id=\"T_6362b_row12_col5\" class=\"data row12 col5\" >nan</td>\n      <td id=\"T_6362b_row12_col6\" class=\"data row12 col6\" >nan</td>\n      <td id=\"T_6362b_row12_col7\" class=\"data row12 col7\" >nan</td>\n      <td id=\"T_6362b_row12_col8\" class=\"data row12 col8\" >slight</td>\n      <td id=\"T_6362b_row12_col9\" class=\"data row12 col9\" >moderate</td>\n      <td id=\"T_6362b_row12_col10\" class=\"data row12 col10\" >moderate</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row13\" class=\"row_heading level0 row13\" >nasogastric_tube</th>\n      <td id=\"T_6362b_row13_col0\" class=\"data row13 col0\" >object</td>\n      <td id=\"T_6362b_row13_col1\" class=\"data row13 col1\" >248</td>\n      <td id=\"T_6362b_row13_col2\" class=\"data row13 col2\" >10.517388</td>\n      <td id=\"T_6362b_row13_col3\" class=\"data row13 col3\" >3</td>\n      <td id=\"T_6362b_row13_col4\" class=\"data row13 col4\" >nan</td>\n      <td id=\"T_6362b_row13_col5\" class=\"data row13 col5\" >nan</td>\n      <td id=\"T_6362b_row13_col6\" class=\"data row13 col6\" >nan</td>\n      <td id=\"T_6362b_row13_col7\" class=\"data row13 col7\" >nan</td>\n      <td id=\"T_6362b_row13_col8\" class=\"data row13 col8\" >slight</td>\n      <td id=\"T_6362b_row13_col9\" class=\"data row13 col9\" >none</td>\n      <td id=\"T_6362b_row13_col10\" class=\"data row13 col10\" >slight</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row14\" class=\"row_heading level0 row14\" >nasogastric_reflux</th>\n      <td id=\"T_6362b_row14_col0\" class=\"data row14 col0\" >object</td>\n      <td id=\"T_6362b_row14_col1\" class=\"data row14 col1\" >141</td>\n      <td id=\"T_6362b_row14_col2\" class=\"data row14 col2\" >5.979644</td>\n      <td id=\"T_6362b_row14_col3\" class=\"data row14 col3\" >4</td>\n      <td id=\"T_6362b_row14_col4\" class=\"data row14 col4\" >nan</td>\n      <td id=\"T_6362b_row14_col5\" class=\"data row14 col5\" >nan</td>\n      <td id=\"T_6362b_row14_col6\" class=\"data row14 col6\" >nan</td>\n      <td id=\"T_6362b_row14_col7\" class=\"data row14 col7\" >nan</td>\n      <td id=\"T_6362b_row14_col8\" class=\"data row14 col8\" >less_1_liter</td>\n      <td id=\"T_6362b_row14_col9\" class=\"data row14 col9\" >more_1_liter</td>\n      <td id=\"T_6362b_row14_col10\" class=\"data row14 col10\" >none</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row15\" class=\"row_heading level0 row15\" >nasogastric_reflux_ph</th>\n      <td id=\"T_6362b_row15_col0\" class=\"data row15 col0\" >float64</td>\n      <td id=\"T_6362b_row15_col1\" class=\"data row15 col1\" >246</td>\n      <td id=\"T_6362b_row15_col2\" class=\"data row15 col2\" >10.432570</td>\n      <td id=\"T_6362b_row15_col3\" class=\"data row15 col3\" >30</td>\n      <td id=\"T_6362b_row15_col4\" class=\"data row15 col4\" >1.000000</td>\n      <td id=\"T_6362b_row15_col5\" class=\"data row15 col5\" >7.500000</td>\n      <td id=\"T_6362b_row15_col6\" class=\"data row15 col6\" >4.439867</td>\n      <td id=\"T_6362b_row15_col7\" class=\"data row15 col7\" >1.918180</td>\n      <td id=\"T_6362b_row15_col8\" class=\"data row15 col8\" >6.500000</td>\n      <td id=\"T_6362b_row15_col9\" class=\"data row15 col9\" >2.000000</td>\n      <td id=\"T_6362b_row15_col10\" class=\"data row15 col10\" >3.500000</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row16\" class=\"row_heading level0 row16\" >rectal_exam_feces</th>\n      <td id=\"T_6362b_row16_col0\" class=\"data row16 col0\" >object</td>\n      <td id=\"T_6362b_row16_col1\" class=\"data row16 col1\" >417</td>\n      <td id=\"T_6362b_row16_col2\" class=\"data row16 col2\" >17.684478</td>\n      <td id=\"T_6362b_row16_col3\" class=\"data row16 col3\" >5</td>\n      <td id=\"T_6362b_row16_col4\" class=\"data row16 col4\" >nan</td>\n      <td id=\"T_6362b_row16_col5\" class=\"data row16 col5\" >nan</td>\n      <td id=\"T_6362b_row16_col6\" class=\"data row16 col6\" >nan</td>\n      <td id=\"T_6362b_row16_col7\" class=\"data row16 col7\" >nan</td>\n      <td id=\"T_6362b_row16_col8\" class=\"data row16 col8\" >decreased</td>\n      <td id=\"T_6362b_row16_col9\" class=\"data row16 col9\" >absent</td>\n      <td id=\"T_6362b_row16_col10\" class=\"data row16 col10\" >nan</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row17\" class=\"row_heading level0 row17\" >abdomen</th>\n      <td id=\"T_6362b_row17_col0\" class=\"data row17 col0\" >object</td>\n      <td id=\"T_6362b_row17_col1\" class=\"data row17 col1\" >485</td>\n      <td id=\"T_6362b_row17_col2\" class=\"data row17 col2\" >20.568278</td>\n      <td id=\"T_6362b_row17_col3\" class=\"data row17 col3\" >5</td>\n      <td id=\"T_6362b_row17_col4\" class=\"data row17 col4\" >nan</td>\n      <td id=\"T_6362b_row17_col5\" class=\"data row17 col5\" >nan</td>\n      <td id=\"T_6362b_row17_col6\" class=\"data row17 col6\" >nan</td>\n      <td id=\"T_6362b_row17_col7\" class=\"data row17 col7\" >nan</td>\n      <td id=\"T_6362b_row17_col8\" class=\"data row17 col8\" >distend_small</td>\n      <td id=\"T_6362b_row17_col9\" class=\"data row17 col9\" >distend_small</td>\n      <td id=\"T_6362b_row17_col10\" class=\"data row17 col10\" >distend_large</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row18\" class=\"row_heading level0 row18\" >packed_cell_volume</th>\n      <td id=\"T_6362b_row18_col0\" class=\"data row18 col0\" >float64</td>\n      <td id=\"T_6362b_row18_col1\" class=\"data row18 col1\" >29</td>\n      <td id=\"T_6362b_row18_col2\" class=\"data row18 col2\" >1.229856</td>\n      <td id=\"T_6362b_row18_col3\" class=\"data row18 col3\" >51</td>\n      <td id=\"T_6362b_row18_col4\" class=\"data row18 col4\" >23.000000</td>\n      <td id=\"T_6362b_row18_col5\" class=\"data row18 col5\" >75.000000</td>\n      <td id=\"T_6362b_row18_col6\" class=\"data row18 col6\" >49.029712</td>\n      <td id=\"T_6362b_row18_col7\" class=\"data row18 col7\" >10.538788</td>\n      <td id=\"T_6362b_row18_col8\" class=\"data row18 col8\" >57.000000</td>\n      <td id=\"T_6362b_row18_col9\" class=\"data row18 col9\" >33.000000</td>\n      <td id=\"T_6362b_row18_col10\" class=\"data row18 col10\" >37.000000</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row19\" class=\"row_heading level0 row19\" >total_protein</th>\n      <td id=\"T_6362b_row19_col0\" class=\"data row19 col0\" >float64</td>\n      <td id=\"T_6362b_row19_col1\" class=\"data row19 col1\" >33</td>\n      <td id=\"T_6362b_row19_col2\" class=\"data row19 col2\" >1.399491</td>\n      <td id=\"T_6362b_row19_col3\" class=\"data row19 col3\" >87</td>\n      <td id=\"T_6362b_row19_col4\" class=\"data row19 col4\" >3.300000</td>\n      <td id=\"T_6362b_row19_col5\" class=\"data row19 col5\" >89.000000</td>\n      <td id=\"T_6362b_row19_col6\" class=\"data row19 col6\" >21.508516</td>\n      <td id=\"T_6362b_row19_col7\" class=\"data row19 col7\" >26.671705</td>\n      <td id=\"T_6362b_row19_col8\" class=\"data row19 col8\" >8.500000</td>\n      <td id=\"T_6362b_row19_col9\" class=\"data row19 col9\" >64.000000</td>\n      <td id=\"T_6362b_row19_col10\" class=\"data row19 col10\" >6.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row20\" class=\"row_heading level0 row20\" >abdomo_appearance</th>\n      <td id=\"T_6362b_row20_col0\" class=\"data row20 col0\" >object</td>\n      <td id=\"T_6362b_row20_col1\" class=\"data row20 col1\" >244</td>\n      <td id=\"T_6362b_row20_col2\" class=\"data row20 col2\" >10.347752</td>\n      <td id=\"T_6362b_row20_col3\" class=\"data row20 col3\" >3</td>\n      <td id=\"T_6362b_row20_col4\" class=\"data row20 col4\" >nan</td>\n      <td id=\"T_6362b_row20_col5\" class=\"data row20 col5\" >nan</td>\n      <td id=\"T_6362b_row20_col6\" class=\"data row20 col6\" >nan</td>\n      <td id=\"T_6362b_row20_col7\" class=\"data row20 col7\" >nan</td>\n      <td id=\"T_6362b_row20_col8\" class=\"data row20 col8\" >serosanguious</td>\n      <td id=\"T_6362b_row20_col9\" class=\"data row20 col9\" >serosanguious</td>\n      <td id=\"T_6362b_row20_col10\" class=\"data row20 col10\" >serosanguious</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row21\" class=\"row_heading level0 row21\" >abdomo_protein</th>\n      <td id=\"T_6362b_row21_col0\" class=\"data row21 col0\" >float64</td>\n      <td id=\"T_6362b_row21_col1\" class=\"data row21 col1\" >198</td>\n      <td id=\"T_6362b_row21_col2\" class=\"data row21 col2\" >8.396947</td>\n      <td id=\"T_6362b_row21_col3\" class=\"data row21 col3\" >60</td>\n      <td id=\"T_6362b_row21_col4\" class=\"data row21 col4\" >0.100000</td>\n      <td id=\"T_6362b_row21_col5\" class=\"data row21 col5\" >10.100000</td>\n      <td id=\"T_6362b_row21_col6\" class=\"data row21 col6\" >3.296532</td>\n      <td id=\"T_6362b_row21_col7\" class=\"data row21 col7\" >1.590515</td>\n      <td id=\"T_6362b_row21_col8\" class=\"data row21 col8\" >3.400000</td>\n      <td id=\"T_6362b_row21_col9\" class=\"data row21 col9\" >2.000000</td>\n      <td id=\"T_6362b_row21_col10\" class=\"data row21 col10\" >3.400000</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row22\" class=\"row_heading level0 row22\" >surgical_lesion</th>\n      <td id=\"T_6362b_row22_col0\" class=\"data row22 col0\" >object</td>\n      <td id=\"T_6362b_row22_col1\" class=\"data row22 col1\" >0</td>\n      <td id=\"T_6362b_row22_col2\" class=\"data row22 col2\" >0.000000</td>\n      <td id=\"T_6362b_row22_col3\" class=\"data row22 col3\" >2</td>\n      <td id=\"T_6362b_row22_col4\" class=\"data row22 col4\" >nan</td>\n      <td id=\"T_6362b_row22_col5\" class=\"data row22 col5\" >nan</td>\n      <td id=\"T_6362b_row22_col6\" class=\"data row22 col6\" >nan</td>\n      <td id=\"T_6362b_row22_col7\" class=\"data row22 col7\" >nan</td>\n      <td id=\"T_6362b_row22_col8\" class=\"data row22 col8\" >yes</td>\n      <td id=\"T_6362b_row22_col9\" class=\"data row22 col9\" >yes</td>\n      <td id=\"T_6362b_row22_col10\" class=\"data row22 col10\" >yes</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row23\" class=\"row_heading level0 row23\" >lesion_1</th>\n      <td id=\"T_6362b_row23_col0\" class=\"data row23 col0\" >int64</td>\n      <td id=\"T_6362b_row23_col1\" class=\"data row23 col1\" >0</td>\n      <td id=\"T_6362b_row23_col2\" class=\"data row23 col2\" >0.000000</td>\n      <td id=\"T_6362b_row23_col3\" class=\"data row23 col3\" >65</td>\n      <td id=\"T_6362b_row23_col4\" class=\"data row23 col4\" >0.000000</td>\n      <td id=\"T_6362b_row23_col5\" class=\"data row23 col5\" >41110.000000</td>\n      <td id=\"T_6362b_row23_col6\" class=\"data row23 col6\" >3767.711620</td>\n      <td id=\"T_6362b_row23_col7\" class=\"data row23 col7\" >5320.367977</td>\n      <td id=\"T_6362b_row23_col8\" class=\"data row23 col8\" >2209</td>\n      <td id=\"T_6362b_row23_col9\" class=\"data row23 col9\" >2208</td>\n      <td id=\"T_6362b_row23_col10\" class=\"data row23 col10\" >5124</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row24\" class=\"row_heading level0 row24\" >lesion_2</th>\n      <td id=\"T_6362b_row24_col0\" class=\"data row24 col0\" >int64</td>\n      <td id=\"T_6362b_row24_col1\" class=\"data row24 col1\" >0</td>\n      <td id=\"T_6362b_row24_col2\" class=\"data row24 col2\" >0.000000</td>\n      <td id=\"T_6362b_row24_col3\" class=\"data row24 col3\" >7</td>\n      <td id=\"T_6362b_row24_col4\" class=\"data row24 col4\" >0.000000</td>\n      <td id=\"T_6362b_row24_col5\" class=\"data row24 col5\" >7111.000000</td>\n      <td id=\"T_6362b_row24_col6\" class=\"data row24 col6\" >23.462680</td>\n      <td id=\"T_6362b_row24_col7\" class=\"data row24 col7\" >295.603731</td>\n      <td id=\"T_6362b_row24_col8\" class=\"data row24 col8\" >0</td>\n      <td id=\"T_6362b_row24_col9\" class=\"data row24 col9\" >0</td>\n      <td id=\"T_6362b_row24_col10\" class=\"data row24 col10\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row25\" class=\"row_heading level0 row25\" >lesion_3</th>\n      <td id=\"T_6362b_row25_col0\" class=\"data row25 col0\" >int64</td>\n      <td id=\"T_6362b_row25_col1\" class=\"data row25 col1\" >0</td>\n      <td id=\"T_6362b_row25_col2\" class=\"data row25 col2\" >0.000000</td>\n      <td id=\"T_6362b_row25_col3\" class=\"data row25 col3\" >2</td>\n      <td id=\"T_6362b_row25_col4\" class=\"data row25 col4\" >0.000000</td>\n      <td id=\"T_6362b_row25_col5\" class=\"data row25 col5\" >2209.000000</td>\n      <td id=\"T_6362b_row25_col6\" class=\"data row25 col6\" >2.810433</td>\n      <td id=\"T_6362b_row25_col7\" class=\"data row25 col7\" >78.758984</td>\n      <td id=\"T_6362b_row25_col8\" class=\"data row25 col8\" >0</td>\n      <td id=\"T_6362b_row25_col9\" class=\"data row25 col9\" >0</td>\n      <td id=\"T_6362b_row25_col10\" class=\"data row25 col10\" >0</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row26\" class=\"row_heading level0 row26\" >cp_data</th>\n      <td id=\"T_6362b_row26_col0\" class=\"data row26 col0\" >object</td>\n      <td id=\"T_6362b_row26_col1\" class=\"data row26 col1\" >0</td>\n      <td id=\"T_6362b_row26_col2\" class=\"data row26 col2\" >0.000000</td>\n      <td id=\"T_6362b_row26_col3\" class=\"data row26 col3\" >2</td>\n      <td id=\"T_6362b_row26_col4\" class=\"data row26 col4\" >nan</td>\n      <td id=\"T_6362b_row26_col5\" class=\"data row26 col5\" >nan</td>\n      <td id=\"T_6362b_row26_col6\" class=\"data row26 col6\" >nan</td>\n      <td id=\"T_6362b_row26_col7\" class=\"data row26 col7\" >nan</td>\n      <td id=\"T_6362b_row26_col8\" class=\"data row26 col8\" >no</td>\n      <td id=\"T_6362b_row26_col9\" class=\"data row26 col9\" >no</td>\n      <td id=\"T_6362b_row26_col10\" class=\"data row26 col10\" >no</td>\n    </tr>\n    <tr>\n      <th id=\"T_6362b_level0_row27\" class=\"row_heading level0 row27\" >outcome</th>\n      <td id=\"T_6362b_row27_col0\" class=\"data row27 col0\" >object</td>\n      <td id=\"T_6362b_row27_col1\" class=\"data row27 col1\" >824</td>\n      <td id=\"T_6362b_row27_col2\" class=\"data row27 col2\" >34.944869</td>\n      <td id=\"T_6362b_row27_col3\" class=\"data row27 col3\" >3</td>\n      <td id=\"T_6362b_row27_col4\" class=\"data row27 col4\" >nan</td>\n      <td id=\"T_6362b_row27_col5\" class=\"data row27 col5\" >nan</td>\n      <td id=\"T_6362b_row27_col6\" class=\"data row27 col6\" >nan</td>\n      <td id=\"T_6362b_row27_col7\" class=\"data row27 col7\" >nan</td>\n      <td id=\"T_6362b_row27_col8\" class=\"data row27 col8\" >died</td>\n      <td id=\"T_6362b_row27_col9\" class=\"data row27 col9\" >euthanized</td>\n      <td id=\"T_6362b_row27_col10\" class=\"data row27 col10\" >lived</td>\n    </tr>\n  </tbody>\n</table>\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****there are some inconsistencies in the train data and test  , for example in pain there is slight  which doesnt exist in test data ( there is moderate instead )\nrectal exam feces , there is serosanguious ( only 1 case ) which doesn't exist in test data ****","metadata":{}},{"cell_type":"code","source":"total[\"rectal_exam_feces\"] = np.where(total[\"rectal_exam_feces\"].isin([\"serosanguious\"]), total[\"rectal_exam_feces\"].mode()[0], \n                                              total[\"rectal_exam_feces\"])\ntotal[\"pain\"] = np.where(total[\"pain\"].isin([\"slight\", \"moderate\"]), \"mild_pain\", total[\"pain\"])\ntotal[\"peristalsis\"] = np.where(total[\"peristalsis\"].isin([\"distend_small\"]), total[\"peristalsis\"].mode()[0], \n                                              total[\"peristalsis\"])\n\ntotal[\"nasogastric_reflux\"] = np.where(total[\"nasogastric_reflux\"].isin([\"slight\"]), \n                                               total[\"nasogastric_reflux\"].mode()[0],\n                                               total[\"nasogastric_reflux\"])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.499204Z","iopub.execute_input":"2023-10-02T16:23:31.499497Z","iopub.status.idle":"2023-10-02T16:23:31.512279Z","shell.execute_reply.started":"2023-10-02T16:23:31.499472Z","shell.execute_reply":"2023-10-02T16:23:31.511133Z"},"trusted":true},"execution_count":676,"outputs":[]},{"cell_type":"code","source":"total['frequency'] = total['hospital_number'].map(total['hospital_number'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.527196Z","iopub.execute_input":"2023-10-02T16:23:31.527560Z","iopub.status.idle":"2023-10-02T16:23:31.535174Z","shell.execute_reply.started":"2023-10-02T16:23:31.527531Z","shell.execute_reply":"2023-10-02T16:23:31.534065Z"},"trusted":true},"execution_count":677,"outputs":[]},{"cell_type":"markdown","source":"****as the original data states , hospital number is merely an indicator for how many times did a horse visit the hosipital ( it still doesn't make sense to me because after analysing the data  , alot of  hospital numbers has many cases marked dead , how can a horse die more than one time ? ) ****","metadata":{}},{"cell_type":"code","source":"total.drop('hospital_number' , axis =1 , inplace = True )","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.564753Z","iopub.execute_input":"2023-10-02T16:23:31.565110Z","iopub.status.idle":"2023-10-02T16:23:31.572654Z","shell.execute_reply.started":"2023-10-02T16:23:31.565083Z","shell.execute_reply":"2023-10-02T16:23:31.571330Z"},"trusted":true},"execution_count":678,"outputs":[]},{"cell_type":"code","source":"total['frequency']","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.629826Z","iopub.execute_input":"2023-10-02T16:23:31.630258Z","iopub.status.idle":"2023-10-02T16:23:31.639510Z","shell.execute_reply.started":"2023-10-02T16:23:31.630228Z","shell.execute_reply":"2023-10-02T16:23:31.638176Z"},"trusted":true},"execution_count":679,"outputs":[{"execution_count":679,"output_type":"execute_result","data":{"text/plain":"0       20\n1       16\n2        2\n3        3\n4        9\n        ..\n2353    83\n2354     9\n2355     5\n2356    35\n2357    19\nName: frequency, Length: 2358, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****respiratory rate doesn't seem very good in influencing the outcome state for horses  \nlesion 2 , lesion 3 are probably going to just add noise \ncan work in total protein and packed cell volume to construct a feature which would be usefull , they seem some what well distributed ( if i have time i will work on this , if not i will just add my research  findings at the top i hope you find it useful :) )  \npulse is very solid as it seems , will probably be very effective indicator ****\n\n****outliers on the other hand i can't seem to find a good solution for it (yet ) becuase for most features , there are too many of them everywhere in every category  to be considered \"outliers\" , tell me what you think **** ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainpl['Combined_Feature'] = trainpl['packed_cell_volume'] + trainpl['total_protein']","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.812706Z","iopub.execute_input":"2023-10-02T16:23:31.813066Z","iopub.status.idle":"2023-10-02T16:23:31.820454Z","shell.execute_reply.started":"2023-10-02T16:23:31.813036Z","shell.execute_reply":"2023-10-02T16:23:31.819192Z"},"trusted":true},"execution_count":680,"outputs":[]},{"cell_type":"code","source":"# plt.scatter(total['Combined_Feature'], total['outcome'], alpha=0.5)\n# plt.xlabel('Combined Feature')\n# plt.ylabel('Target_Variable')\n# plt.title('Scatter Plot: Combined Feature vs. Target Variable')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.867272Z","iopub.execute_input":"2023-10-02T16:23:31.867617Z","iopub.status.idle":"2023-10-02T16:23:31.875048Z","shell.execute_reply.started":"2023-10-02T16:23:31.867590Z","shell.execute_reply":"2023-10-02T16:23:31.873881Z"},"trusted":true},"execution_count":681,"outputs":[]},{"cell_type":"code","source":"# correlation_matrix2 = trainpl[['Combined_Feature', 'outcome']].corr()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.911603Z","iopub.execute_input":"2023-10-02T16:23:31.912252Z","iopub.status.idle":"2023-10-02T16:23:31.916525Z","shell.execute_reply.started":"2023-10-02T16:23:31.912220Z","shell.execute_reply":"2023-10-02T16:23:31.915148Z"},"trusted":true},"execution_count":682,"outputs":[]},{"cell_type":"code","source":"# sns.heatmap(correlation_matrix2, annot=True, cmap='coolwarm')\n# plt.title('Correlation Heatmap')\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:31.963318Z","iopub.execute_input":"2023-10-02T16:23:31.963653Z","iopub.status.idle":"2023-10-02T16:23:31.968114Z","shell.execute_reply.started":"2023-10-02T16:23:31.963627Z","shell.execute_reply":"2023-10-02T16:23:31.966653Z"},"trusted":true},"execution_count":683,"outputs":[]},{"cell_type":"code","source":"def IQR(col):\n    q1 = np.percentile(col, 25)\n    q3 = np.percentile(col, 75)\n    iqr = q3 - q1\n    upper_bound = q3 + (1.5 * iqr)\n    upper_outliers = col > upper_bound\n\n    # Replace outliers with upper bound values\n    col = np.where(upper_outliers, round(upper_bound, 2), col)  \n    return col\n\n\ntotal[\"total_protein\"] = IQR(total[\"total_protein\"])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:32.015575Z","iopub.execute_input":"2023-10-02T16:23:32.016033Z","iopub.status.idle":"2023-10-02T16:23:32.023546Z","shell.execute_reply.started":"2023-10-02T16:23:32.016000Z","shell.execute_reply":"2023-10-02T16:23:32.022289Z"},"trusted":true},"execution_count":684,"outputs":[]},{"cell_type":"code","source":"# total['pcv_tp_ratio']=total['packed_cell_volume']/total['total_protein']","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:32.057797Z","iopub.execute_input":"2023-10-02T16:23:32.058251Z","iopub.status.idle":"2023-10-02T16:23:32.065821Z","shell.execute_reply.started":"2023-10-02T16:23:32.058219Z","shell.execute_reply":"2023-10-02T16:23:32.064608Z"},"trusted":true},"execution_count":685,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(train[train['lesion_1'] ==11300 ]['outcome'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:32.116526Z","iopub.execute_input":"2023-10-02T16:23:32.116880Z","iopub.status.idle":"2023-10-02T16:23:32.125685Z","shell.execute_reply.started":"2023-10-02T16:23:32.116837Z","shell.execute_reply":"2023-10-02T16:23:32.124135Z"},"trusted":true},"execution_count":686,"outputs":[]},{"cell_type":"code","source":"# train[train['lesion_1'] > 9999]['lesion_1'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:32.161564Z","iopub.execute_input":"2023-10-02T16:23:32.161922Z","iopub.status.idle":"2023-10-02T16:23:32.170130Z","shell.execute_reply.started":"2023-10-02T16:23:32.161895Z","shell.execute_reply":"2023-10-02T16:23:32.168148Z"},"trusted":true},"execution_count":687,"outputs":[]},{"cell_type":"code","source":"\ntotal['lesion_1'] = total['lesion_1'].astype(str)\nsite_of_lesion_mapping = {\n    '1': 'gastric',\n    '2': 'small intestine',\n    '3': 'large colon',\n    '4': 'large colon and cecum',\n    '5': 'cecum',\n    '6': 'transverse colon',\n    '7': 'rectum/descending colon',\n    '8': 'uterus',\n    '9': 'bladder',\n    '11': 'all intestinal sites',\n    '0': 'none',\n}\n\ntype_mapping = {\n    '1': 'simple',\n    '2': 'strangulation',\n    '3': 'inflammation',\n    '4': 'other',\n}\n\nsubtype_mapping = {\n    '1': 'mechanical',\n    '2': 'paralytic',\n    '0': 'n/a',\n}\n\nspecific_code_mapping = {\n    '1': 'obturation',\n    '2': 'intrinsic',\n    '3': 'extrinsic',\n    '4': 'adynamic',\n    '5': 'volvulus/torsion',\n    '6': 'intussusception',\n    '7': 'thromboembolic',\n    '8': 'hernia',\n    '9': 'lipoma/splenic incarceration',\n    '10': 'displacement',\n    '0': 'n/a',\n}\n\n\ntotal['site'] = total['lesion_1'].str[0].map(site_of_lesion_mapping)\ntotal['type'] = total['lesion_1'].str[1].map(type_mapping)\ntotal['subtype'] = total['lesion_1'].str[2].map(subtype_mapping)\ntotal['specific_code'] = total['lesion_1'].str[3].map(specific_code_mapping)\nspecial_cases = {\n    '31110': ('large colon', 'simple', 'mechanical', 'displacement'),\n    '12208': ('small intestine', 'strangulation', 'n/a', 'hernia'),\n    '11300': ('gastric', 'simple', 'n/a', 'n/a'),\n    '11400': ('all intestinal sites', 'other', 'n/a', 'n/a'),\n    '11124': ('all intestinal sites', 'simple', 'paralytic', 'adynamic'),\n    '21110': ('small intestine', 'simple', 'mechanical', 'displacement'),\n    '41110': ('large colon and cecum', 'simple', 'mechanical', 'displacement'),\n}\n\n\nfor case, (site, type, subtype, specific_code) in special_cases.items():\n    total.loc[total['lesion_1'] == case, 'site'] = site\n    total.loc[total['lesion_1'] == case, 'type'] = type\n    total.loc[total['lesion_1'] == case, 'subtype'] = subtype\n    total.loc[total['lesion_1'] == case, 'specific_code'] = specific_code\n\ntotal.drop(['lesion_1', 'lesion_2', 'lesion_3'], axis=1, inplace=True)\n","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2023-10-02T16:23:32.324451Z","iopub.execute_input":"2023-10-02T16:23:32.324799Z","iopub.status.idle":"2023-10-02T16:23:32.369139Z","shell.execute_reply.started":"2023-10-02T16:23:32.324774Z","shell.execute_reply":"2023-10-02T16:23:32.368033Z"},"trusted":true},"execution_count":688,"outputs":[]},{"cell_type":"markdown","source":"****decoding lesion as the original dataset  clarified  ( update : subtype doesn't seem to be relevant to the outcome , dropping it proved to be worth , as for lesion 2 and 3  they have very little cases ) ****","metadata":{}},{"cell_type":"code","source":"total['site'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:32.678976Z","iopub.execute_input":"2023-10-02T16:23:32.679324Z","iopub.status.idle":"2023-10-02T16:23:32.687381Z","shell.execute_reply.started":"2023-10-02T16:23:32.679297Z","shell.execute_reply":"2023-10-02T16:23:32.686464Z"},"trusted":true},"execution_count":689,"outputs":[{"execution_count":689,"output_type":"execute_result","data":{"text/plain":"site\nsmall intestine            1016\nlarge colon                 577\nnone                        209\nlarge colon and cecum       165\ngastric                     113\ncecum                       112\nrectum/descending colon     101\nuterus                       22\ntransverse colon             21\nall intestinal sites         12\nbladder                      10\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"total[\"outcome\"] = total[\"outcome\"].map({'died': 1,'euthanized': 0, 'lived':2})\ncategorical_feats = []\nfor column in total.columns:\n   \n    if total[column].dtype == 'object':\n    \n        categorical_feats.append(column)\n        \nprint(categorical_feats)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:32.924807Z","iopub.execute_input":"2023-10-02T16:23:32.925170Z","iopub.status.idle":"2023-10-02T16:23:32.934435Z","shell.execute_reply.started":"2023-10-02T16:23:32.925142Z","shell.execute_reply":"2023-10-02T16:23:32.933055Z"},"trusted":true},"execution_count":690,"outputs":[{"name":"stdout","text":"['surgery', 'age', 'temp_of_extremities', 'peripheral_pulse', 'mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis', 'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', 'rectal_exam_feces', 'abdomen', 'abdomo_appearance', 'surgical_lesion', 'cp_data', 'site', 'type', 'subtype', 'specific_code']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numerical_features = []\n\n\nfor column in total.columns:\n    \n    if pd.api.types.is_numeric_dtype(total[column]):\n        if column != 'outcome':\n            numerical_features.append(column)\n\n\nprint(numerical_features)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:33.018918Z","iopub.execute_input":"2023-10-02T16:23:33.019390Z","iopub.status.idle":"2023-10-02T16:23:33.025772Z","shell.execute_reply.started":"2023-10-02T16:23:33.019349Z","shell.execute_reply":"2023-10-02T16:23:33.024400Z"},"trusted":true},"execution_count":691,"outputs":[{"name":"stdout","text":"['rectal_temp', 'pulse', 'respiratory_rate', 'nasogastric_reflux_ph', 'packed_cell_volume', 'total_protein', 'abdomo_protein', 'frequency']\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imputer = KNNImputer(n_neighbors=8)  \ntotal[numerical_features] = imputer.fit_transform(total[numerical_features])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:33.188386Z","iopub.execute_input":"2023-10-02T16:23:33.189239Z","iopub.status.idle":"2023-10-02T16:23:33.342566Z","shell.execute_reply.started":"2023-10-02T16:23:33.188980Z","shell.execute_reply":"2023-10-02T16:23:33.340744Z"},"trusted":true},"execution_count":692,"outputs":[]},{"cell_type":"code","source":"columns_to_fill = ['capillary_refill_time', 'nasogastric_reflux', 'peristalsis', 'mucous_membrane', 'abdominal_distention', 'pain', 'temp_of_extremities', 'abdomo_appearance', 'peripheral_pulse', 'nasogastric_tube', 'rectal_exam_feces', 'abdomen', 'type', 'subtype', 'specific_code']","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:33.345066Z","iopub.execute_input":"2023-10-02T16:23:33.345511Z","iopub.status.idle":"2023-10-02T16:23:33.355761Z","shell.execute_reply.started":"2023-10-02T16:23:33.345463Z","shell.execute_reply":"2023-10-02T16:23:33.354561Z"},"trusted":true},"execution_count":693,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:33.357576Z","iopub.execute_input":"2023-10-02T16:23:33.357987Z","iopub.status.idle":"2023-10-02T16:23:33.393514Z","shell.execute_reply.started":"2023-10-02T16:23:33.357957Z","shell.execute_reply":"2023-10-02T16:23:33.392154Z"},"trusted":true},"execution_count":694,"outputs":[{"execution_count":694,"output_type":"execute_result","data":{"text/plain":"     surgery    age  rectal_temp  pulse  respiratory_rate temp_of_extremities  \\\n0        yes  adult        38.10 132.00             24.00                cool   \n1        yes  adult        37.50  88.00             12.00                cool   \n2        yes  adult        38.30 120.00             28.00                cool   \n3        yes  adult        37.10  72.00             30.00                cold   \n4         no  adult        38.00  52.00             48.00              normal   \n...      ...    ...          ...    ...               ...                 ...   \n2353      no  adult        40.30 114.00             36.00                cool   \n2354     yes  adult        37.20 100.00             20.00                cool   \n2355     yes  adult        39.20 132.00             12.00                cool   \n2356      no  adult        38.30  54.00             66.00              normal   \n2357     yes  adult        38.10  66.00             12.00                cold   \n\n     peripheral_pulse mucous_membrane capillary_refill_time          pain  \\\n0             reduced   dark_cyanotic            more_3_sec     depressed   \n1              normal   pale_cyanotic            more_3_sec     mild_pain   \n2             reduced       pale_pink            less_3_sec  extreme_pain   \n3             reduced       pale_pink            more_3_sec     mild_pain   \n4              normal     normal_pink            less_3_sec         alert   \n...               ...             ...                   ...           ...   \n2353          reduced     normal_pink            more_3_sec     depressed   \n2354          reduced   pale_cyanotic            more_3_sec  extreme_pain   \n2355          reduced   dark_cyanotic            more_3_sec     depressed   \n2356           normal     normal_pink            less_3_sec     mild_pain   \n2357           normal     normal_pink            less_3_sec     mild_pain   \n\n      ... abdomo_appearance abdomo_protein surgical_lesion cp_data  outcome  \\\n0     ...     serosanguious           3.40             yes      no     1.00   \n1     ...     serosanguious           2.00             yes      no     0.00   \n2     ...     serosanguious           3.40             yes      no     2.00   \n3     ...            cloudy           3.90             yes     yes     2.00   \n4     ...            cloudy           2.60              no     yes     2.00   \n...   ...               ...            ...             ...     ...      ...   \n2353  ...     serosanguious           4.50             yes     yes      NaN   \n2354  ...     serosanguious           2.00             yes      no      NaN   \n2355  ...     serosanguious           4.50             yes      no      NaN   \n2356  ...             clear           5.00              no     yes      NaN   \n2357  ...               NaN           1.60             yes     yes      NaN   \n\n     frequency             site           type     subtype  \\\n0        20.00  small intestine  strangulation         n/a   \n1        16.00  small intestine  strangulation         n/a   \n2         2.00            cecum         simple   paralytic   \n3         3.00  small intestine  strangulation         n/a   \n4         9.00             none            NaN         NaN   \n...        ...              ...            ...         ...   \n2353     83.00      large colon  strangulation         n/a   \n2354      9.00  small intestine  strangulation         n/a   \n2355      5.00  small intestine  strangulation         n/a   \n2356     35.00      large colon         simple  mechanical   \n2357     19.00  small intestine  strangulation         n/a   \n\n                     specific_code  \n0     lipoma/splenic incarceration  \n1                           hernia  \n2                         adynamic  \n3                           hernia  \n4                              NaN  \n...                            ...  \n2353              volvulus/torsion  \n2354  lipoma/splenic incarceration  \n2355              volvulus/torsion  \n2356                    obturation  \n2357              volvulus/torsion  \n\n[2358 rows x 29 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>surgery</th>\n      <th>age</th>\n      <th>rectal_temp</th>\n      <th>pulse</th>\n      <th>respiratory_rate</th>\n      <th>temp_of_extremities</th>\n      <th>peripheral_pulse</th>\n      <th>mucous_membrane</th>\n      <th>capillary_refill_time</th>\n      <th>pain</th>\n      <th>...</th>\n      <th>abdomo_appearance</th>\n      <th>abdomo_protein</th>\n      <th>surgical_lesion</th>\n      <th>cp_data</th>\n      <th>outcome</th>\n      <th>frequency</th>\n      <th>site</th>\n      <th>type</th>\n      <th>subtype</th>\n      <th>specific_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>yes</td>\n      <td>adult</td>\n      <td>38.10</td>\n      <td>132.00</td>\n      <td>24.00</td>\n      <td>cool</td>\n      <td>reduced</td>\n      <td>dark_cyanotic</td>\n      <td>more_3_sec</td>\n      <td>depressed</td>\n      <td>...</td>\n      <td>serosanguious</td>\n      <td>3.40</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>1.00</td>\n      <td>20.00</td>\n      <td>small intestine</td>\n      <td>strangulation</td>\n      <td>n/a</td>\n      <td>lipoma/splenic incarceration</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>yes</td>\n      <td>adult</td>\n      <td>37.50</td>\n      <td>88.00</td>\n      <td>12.00</td>\n      <td>cool</td>\n      <td>normal</td>\n      <td>pale_cyanotic</td>\n      <td>more_3_sec</td>\n      <td>mild_pain</td>\n      <td>...</td>\n      <td>serosanguious</td>\n      <td>2.00</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>0.00</td>\n      <td>16.00</td>\n      <td>small intestine</td>\n      <td>strangulation</td>\n      <td>n/a</td>\n      <td>hernia</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>yes</td>\n      <td>adult</td>\n      <td>38.30</td>\n      <td>120.00</td>\n      <td>28.00</td>\n      <td>cool</td>\n      <td>reduced</td>\n      <td>pale_pink</td>\n      <td>less_3_sec</td>\n      <td>extreme_pain</td>\n      <td>...</td>\n      <td>serosanguious</td>\n      <td>3.40</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>2.00</td>\n      <td>2.00</td>\n      <td>cecum</td>\n      <td>simple</td>\n      <td>paralytic</td>\n      <td>adynamic</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>yes</td>\n      <td>adult</td>\n      <td>37.10</td>\n      <td>72.00</td>\n      <td>30.00</td>\n      <td>cold</td>\n      <td>reduced</td>\n      <td>pale_pink</td>\n      <td>more_3_sec</td>\n      <td>mild_pain</td>\n      <td>...</td>\n      <td>cloudy</td>\n      <td>3.90</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>2.00</td>\n      <td>3.00</td>\n      <td>small intestine</td>\n      <td>strangulation</td>\n      <td>n/a</td>\n      <td>hernia</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>no</td>\n      <td>adult</td>\n      <td>38.00</td>\n      <td>52.00</td>\n      <td>48.00</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>normal_pink</td>\n      <td>less_3_sec</td>\n      <td>alert</td>\n      <td>...</td>\n      <td>cloudy</td>\n      <td>2.60</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>2.00</td>\n      <td>9.00</td>\n      <td>none</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2353</th>\n      <td>no</td>\n      <td>adult</td>\n      <td>40.30</td>\n      <td>114.00</td>\n      <td>36.00</td>\n      <td>cool</td>\n      <td>reduced</td>\n      <td>normal_pink</td>\n      <td>more_3_sec</td>\n      <td>depressed</td>\n      <td>...</td>\n      <td>serosanguious</td>\n      <td>4.50</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>NaN</td>\n      <td>83.00</td>\n      <td>large colon</td>\n      <td>strangulation</td>\n      <td>n/a</td>\n      <td>volvulus/torsion</td>\n    </tr>\n    <tr>\n      <th>2354</th>\n      <td>yes</td>\n      <td>adult</td>\n      <td>37.20</td>\n      <td>100.00</td>\n      <td>20.00</td>\n      <td>cool</td>\n      <td>reduced</td>\n      <td>pale_cyanotic</td>\n      <td>more_3_sec</td>\n      <td>extreme_pain</td>\n      <td>...</td>\n      <td>serosanguious</td>\n      <td>2.00</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>9.00</td>\n      <td>small intestine</td>\n      <td>strangulation</td>\n      <td>n/a</td>\n      <td>lipoma/splenic incarceration</td>\n    </tr>\n    <tr>\n      <th>2355</th>\n      <td>yes</td>\n      <td>adult</td>\n      <td>39.20</td>\n      <td>132.00</td>\n      <td>12.00</td>\n      <td>cool</td>\n      <td>reduced</td>\n      <td>dark_cyanotic</td>\n      <td>more_3_sec</td>\n      <td>depressed</td>\n      <td>...</td>\n      <td>serosanguious</td>\n      <td>4.50</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>NaN</td>\n      <td>5.00</td>\n      <td>small intestine</td>\n      <td>strangulation</td>\n      <td>n/a</td>\n      <td>volvulus/torsion</td>\n    </tr>\n    <tr>\n      <th>2356</th>\n      <td>no</td>\n      <td>adult</td>\n      <td>38.30</td>\n      <td>54.00</td>\n      <td>66.00</td>\n      <td>normal</td>\n      <td>normal</td>\n      <td>normal_pink</td>\n      <td>less_3_sec</td>\n      <td>mild_pain</td>\n      <td>...</td>\n      <td>clear</td>\n      <td>5.00</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>NaN</td>\n      <td>35.00</td>\n      <td>large colon</td>\n      <td>simple</td>\n      <td>mechanical</td>\n      <td>obturation</td>\n    </tr>\n    <tr>\n      <th>2357</th>\n      <td>yes</td>\n      <td>adult</td>\n      <td>38.10</td>\n      <td>66.00</td>\n      <td>12.00</td>\n      <td>cold</td>\n      <td>normal</td>\n      <td>normal_pink</td>\n      <td>less_3_sec</td>\n      <td>mild_pain</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>1.60</td>\n      <td>yes</td>\n      <td>yes</td>\n      <td>NaN</td>\n      <td>19.00</td>\n      <td>small intestine</td>\n      <td>strangulation</td>\n      <td>n/a</td>\n      <td>volvulus/torsion</td>\n    </tr>\n  </tbody>\n</table>\n<p>2358 rows  29 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\nencoder = LabelEncoder()\nfor column in columns_to_fill:\n    column_not_null_firstly = total[total[column].notnull()].copy()\n    column_not_null = column_not_null_firstly.copy()\n    column_null_firstly = total[total[column].isnull()].copy()\n    column_null = column_null_firstly.copy()\n    \n    column_not_null_self = pd.DataFrame(encoder.fit_transform(column_not_null[column]), columns=[column])\n    column_not_null.drop(numerical_features + [column], axis=1, inplace=True)\n    column_not_null = pd.DataFrame(ohe.fit_transform(column_not_null))\n    column_not_null.columns = ohe.get_feature_names_out()\n    column_not_null = pd.concat([column_not_null, column_not_null_firstly[numerical_features].reset_index(drop=True)], axis=1)\n\n    column_null.drop(numerical_features + [column], axis=1, inplace=True)\n    column_null = pd.DataFrame(ohe.fit_transform(column_null), columns=ohe.get_feature_names_out())\n    column_null = pd.concat([column_null, column_null_firstly[numerical_features].reset_index(drop=True)], axis=1)    \n    \n    column_dependences = list(set(column_null.columns).intersection(set(column_not_null.columns)) - set(['outcome_0', 'outcome_1', 'outcome_2', 'outcome_3']))\n    column_X_train, column_X_test, column_y_train, column_y_test = train_test_split(column_not_null[column_dependences], column_not_null_self, test_size=0.2, random_state=21, stratify=column_not_null_self)\n    def objective(trial): \n        param = {  \n        'loss': 'log_loss',\n        'max_iter': trial.suggest_int('max_iter', 30, 300),\n        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3),\n        'max_depth': trial.suggest_int('max_depth', 2, 25),\n        'scoring': 'f1_micro',\n        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 2, 80),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 50),\n        'l2_regularization': trial.suggest_float('l2_regularization', 0, 1),\n        'warm_start': False,\n        'early_stopping': 'auto',\n        'scoring': 'loss',\n        }\n    \n        model = HistGradientBoostingClassifier(**param).fit(column_X_train, np.ravel(column_y_train))  \n        result = accuracy_score(column_y_test,(model.predict(column_X_test)))\n        return result\n        \n    study = optuna.create_study(direction='maximize')\n    study.optimize(objective, n_trials=20, n_jobs = -1, show_progress_bar = True)\n    best_params = study.best_params\n    best_accuracy = study.best_value\n    print('Current column: ', column)\n    print(\"Best Parameters: \", best_params)\n    print(\"Best Accuracy: \", best_accuracy)\n    \n    xgb_column = HistGradientBoostingClassifier(**best_params)\n    xgb_column.fit(column_X_train, column_y_train)\n    y_pred = xgb_column.predict(column_X_test)\n    accuracy = accuracy_score(y_pred, column_y_test)\n    \n    y_pred_proba_null = xgb_column.predict_proba(column_null[column_dependences])[:, 1]\n    final_pred = xgb_column.predict(column_null[column_dependences])\n    \n    ###  taking only predictions with the best confidence (othes will be filled with mode)\n    threshold = np.percentile(y_pred_proba_null, 0)\n    \n    final_pred_labels = encoder.inverse_transform(final_pred)\n    \n    final_pred_confident = np.where(y_pred_proba_null >= threshold, final_pred_labels, np.nan)\n    total.loc[total[column].isnull(), column] = final_pred_confident\nprint(total)\nprint(total.columns)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:23:33.396008Z","iopub.execute_input":"2023-10-02T16:23:33.396806Z","iopub.status.idle":"2023-10-02T16:49:32.307236Z","shell.execute_reply.started":"2023-10-02T16:23:33.396762Z","shell.execute_reply":"2023-10-02T16:49:32.306260Z"},"trusted":true},"execution_count":695,"outputs":[{"name":"stderr","text":"[I 2023-10-02 16:23:33,467] A new study created in memory with name: no-name-2617d670-21df-4151-b569-0478b831195d\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6f1bece027f4a4abfdb841dc46c3c48"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:23:35,260] Trial 2 finished with value: 0.7667386609071274 and parameters: {'max_iter': 30, 'learning_rate': 0.16464630185722573, 'max_depth': 18, 'max_leaf_nodes': 15, 'min_samples_leaf': 34, 'l2_regularization': 0.019389625853240555}. Best is trial 2 with value: 0.7667386609071274.\n[I 2023-10-02 16:23:40,050] Trial 3 finished with value: 0.7732181425485961 and parameters: {'max_iter': 91, 'learning_rate': 0.06337061810874905, 'max_depth': 21, 'max_leaf_nodes': 43, 'min_samples_leaf': 50, 'l2_regularization': 0.745381973980237}. Best is trial 3 with value: 0.7732181425485961.\n[I 2023-10-02 16:23:42,586] Trial 4 finished with value: 0.7688984881209503 and parameters: {'max_iter': 100, 'learning_rate': 0.08194628798040535, 'max_depth': 12, 'max_leaf_nodes': 68, 'min_samples_leaf': 48, 'l2_regularization': 0.046922153960999746}. Best is trial 3 with value: 0.7732181425485961.\n[I 2023-10-02 16:23:45,836] Trial 0 finished with value: 0.755939524838013 and parameters: {'max_iter': 187, 'learning_rate': 0.217159876428476, 'max_depth': 12, 'max_leaf_nodes': 19, 'min_samples_leaf': 30, 'l2_regularization': 0.26760067403302834}. Best is trial 3 with value: 0.7732181425485961.\n[I 2023-10-02 16:23:46,023] Trial 6 finished with value: 0.7710583153347732 and parameters: {'max_iter': 49, 'learning_rate': 0.23434265219190642, 'max_depth': 8, 'max_leaf_nodes': 61, 'min_samples_leaf': 47, 'l2_regularization': 0.6609942429849845}. Best is trial 3 with value: 0.7732181425485961.\n[I 2023-10-02 16:23:50,260] Trial 8 finished with value: 0.7667386609071274 and parameters: {'max_iter': 95, 'learning_rate': 0.04323954355906633, 'max_depth': 12, 'max_leaf_nodes': 9, 'min_samples_leaf': 30, 'l2_regularization': 0.14758554315756178}. Best is trial 3 with value: 0.7732181425485961.\n[I 2023-10-02 16:23:51,077] Trial 5 finished with value: 0.7602591792656588 and parameters: {'max_iter': 206, 'learning_rate': 0.18253709297734527, 'max_depth': 6, 'max_leaf_nodes': 28, 'min_samples_leaf': 49, 'l2_regularization': 0.15802647454658425}. Best is trial 3 with value: 0.7732181425485961.\n[I 2023-10-02 16:23:56,775] Trial 10 finished with value: 0.7840172786177105 and parameters: {'max_iter': 50, 'learning_rate': 0.018823306916618456, 'max_depth': 11, 'max_leaf_nodes': 38, 'min_samples_leaf': 12, 'l2_regularization': 0.8005677957501857}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:24:08,118] Trial 11 finished with value: 0.7688984881209503 and parameters: {'max_iter': 72, 'learning_rate': 0.006257811214035541, 'max_depth': 7, 'max_leaf_nodes': 69, 'min_samples_leaf': 8, 'l2_regularization': 0.18510133407667095}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:24:13,751] Trial 1 finished with value: 0.7667386609071274 and parameters: {'max_iter': 240, 'learning_rate': 0.19922043293677602, 'max_depth': 20, 'max_leaf_nodes': 53, 'min_samples_leaf': 4, 'l2_regularization': 0.5613620986875126}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:24:17,711] Trial 7 finished with value: 0.775377969762419 and parameters: {'max_iter': 184, 'learning_rate': 0.16403709937300523, 'max_depth': 12, 'max_leaf_nodes': 66, 'min_samples_leaf': 3, 'l2_regularization': 0.010382239493409218}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:24:20,045] Trial 13 finished with value: 0.7688984881209503 and parameters: {'max_iter': 283, 'learning_rate': 0.2974802097966159, 'max_depth': 2, 'max_leaf_nodes': 36, 'min_samples_leaf': 16, 'l2_regularization': 0.9853467932517153}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:24:30,237] Trial 9 finished with value: 0.7710583153347732 and parameters: {'max_iter': 263, 'learning_rate': 0.021807699490894554, 'max_depth': 15, 'max_leaf_nodes': 54, 'min_samples_leaf': 12, 'l2_regularization': 0.3089858712186654}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:24:30,701] Trial 12 finished with value: 0.7602591792656588 and parameters: {'max_iter': 294, 'learning_rate': 0.21788174856977818, 'max_depth': 18, 'max_leaf_nodes': 77, 'min_samples_leaf': 46, 'l2_regularization': 0.3840352497215629}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:24:40,988] Trial 15 finished with value: 0.7840172786177105 and parameters: {'max_iter': 149, 'learning_rate': 0.11112199558919922, 'max_depth': 16, 'max_leaf_nodes': 50, 'min_samples_leaf': 14, 'l2_regularization': 0.49750424632942547}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:24:46,755] Trial 17 finished with value: 0.7688984881209503 and parameters: {'max_iter': 145, 'learning_rate': 0.11475206577754944, 'max_depth': 9, 'max_leaf_nodes': 41, 'min_samples_leaf': 16, 'l2_regularization': 0.4402162293793719}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:24:57,068] Trial 18 finished with value: 0.755939524838013 and parameters: {'max_iter': 133, 'learning_rate': 0.10216264803263167, 'max_depth': 23, 'max_leaf_nodes': 43, 'min_samples_leaf': 18, 'l2_regularization': 0.4462714193647044}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:24:59,035] Trial 19 finished with value: 0.7667386609071274 and parameters: {'max_iter': 142, 'learning_rate': 0.11712883664103811, 'max_depth': 23, 'max_leaf_nodes': 29, 'min_samples_leaf': 21, 'l2_regularization': 0.550523843233051}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:25:00,745] Trial 14 finished with value: 0.7602591792656588 and parameters: {'max_iter': 288, 'learning_rate': 0.12525032093987595, 'max_depth': 16, 'max_leaf_nodes': 80, 'min_samples_leaf': 15, 'l2_regularization': 0.9366759255853169}. Best is trial 10 with value: 0.7840172786177105.\n[I 2023-10-02 16:25:00,944] Trial 16 finished with value: 0.7775377969762419 and parameters: {'max_iter': 143, 'learning_rate': 0.1234766392620387, 'max_depth': 16, 'max_leaf_nodes': 79, 'min_samples_leaf': 1, 'l2_regularization': 0.44280142530010813}. Best is trial 10 with value: 0.7840172786177105.\nCurrent column:  capillary_refill_time\nBest Parameters:  {'max_iter': 50, 'learning_rate': 0.018823306916618456, 'max_depth': 11, 'max_leaf_nodes': 38, 'min_samples_leaf': 12, 'l2_regularization': 0.8005677957501857}\nBest Accuracy:  0.7840172786177105\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:25:02,442] A new study created in memory with name: no-name-b151a8b5-b62b-472e-b773-4545975571ef\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef7fadbe7e6f492ab7e173e8ee4e3f0b"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:25:16,844] Trial 2 finished with value: 0.6036036036036037 and parameters: {'max_iter': 291, 'learning_rate': 0.059355709641327616, 'max_depth': 4, 'max_leaf_nodes': 75, 'min_samples_leaf': 6, 'l2_regularization': 0.43120560739526426}. Best is trial 2 with value: 0.6036036036036037.\n[I 2023-10-02 16:25:17,430] Trial 3 finished with value: 0.6126126126126126 and parameters: {'max_iter': 131, 'learning_rate': 0.23549873908059368, 'max_depth': 18, 'max_leaf_nodes': 29, 'min_samples_leaf': 33, 'l2_regularization': 0.6128483734204553}. Best is trial 3 with value: 0.6126126126126126.\n[I 2023-10-02 16:25:20,167] Trial 5 finished with value: 0.6081081081081081 and parameters: {'max_iter': 52, 'learning_rate': 0.016293902576921884, 'max_depth': 10, 'max_leaf_nodes': 9, 'min_samples_leaf': 47, 'l2_regularization': 0.4206126554991144}. Best is trial 3 with value: 0.6126126126126126.\n[I 2023-10-02 16:25:22,370] Trial 1 finished with value: 0.6103603603603603 and parameters: {'max_iter': 292, 'learning_rate': 0.28790267673742986, 'max_depth': 6, 'max_leaf_nodes': 57, 'min_samples_leaf': 42, 'l2_regularization': 0.3208993884825976}. Best is trial 3 with value: 0.6126126126126126.\n[I 2023-10-02 16:25:22,883] Trial 0 finished with value: 0.6081081081081081 and parameters: {'max_iter': 177, 'learning_rate': 0.07424621673228116, 'max_depth': 12, 'max_leaf_nodes': 59, 'min_samples_leaf': 36, 'l2_regularization': 0.3855127090262017}. Best is trial 3 with value: 0.6126126126126126.\n[I 2023-10-02 16:25:25,439] Trial 6 finished with value: 0.6103603603603603 and parameters: {'max_iter': 226, 'learning_rate': 0.289652861458542, 'max_depth': 2, 'max_leaf_nodes': 58, 'min_samples_leaf': 30, 'l2_regularization': 0.8774985264035899}. Best is trial 3 with value: 0.6126126126126126.\n[I 2023-10-02 16:25:37,546] Trial 8 finished with value: 0.6328828828828829 and parameters: {'max_iter': 77, 'learning_rate': 0.01706692314515555, 'max_depth': 10, 'max_leaf_nodes': 46, 'min_samples_leaf': 4, 'l2_regularization': 0.35956967468678325}. Best is trial 8 with value: 0.6328828828828829.\n[I 2023-10-02 16:25:39,519] Trial 9 finished with value: 0.6081081081081081 and parameters: {'max_iter': 126, 'learning_rate': 0.19727581185191573, 'max_depth': 11, 'max_leaf_nodes': 28, 'min_samples_leaf': 21, 'l2_regularization': 0.5139144434556379}. Best is trial 8 with value: 0.6328828828828829.\n[I 2023-10-02 16:25:40,045] Trial 10 finished with value: 0.6396396396396397 and parameters: {'max_iter': 110, 'learning_rate': 0.11569601747243334, 'max_depth': 2, 'max_leaf_nodes': 18, 'min_samples_leaf': 50, 'l2_regularization': 0.47518985934724634}. Best is trial 10 with value: 0.6396396396396397.\n[I 2023-10-02 16:25:40,937] Trial 4 finished with value: 0.6148648648648649 and parameters: {'max_iter': 172, 'learning_rate': 0.20507827585983102, 'max_depth': 14, 'max_leaf_nodes': 30, 'min_samples_leaf': 2, 'l2_regularization': 0.8575934908472158}. Best is trial 10 with value: 0.6396396396396397.\n[I 2023-10-02 16:25:42,401] Trial 13 finished with value: 0.6328828828828829 and parameters: {'max_iter': 30, 'learning_rate': 0.13105662656589992, 'max_depth': 25, 'max_leaf_nodes': 7, 'min_samples_leaf': 17, 'l2_regularization': 0.06735211846576672}. Best is trial 10 with value: 0.6396396396396397.\n[I 2023-10-02 16:25:43,326] Trial 7 finished with value: 0.6126126126126126 and parameters: {'max_iter': 175, 'learning_rate': 0.09097840082618742, 'max_depth': 10, 'max_leaf_nodes': 77, 'min_samples_leaf': 29, 'l2_regularization': 0.33141723009777213}. Best is trial 10 with value: 0.6396396396396397.\n[I 2023-10-02 16:25:46,882] Trial 12 finished with value: 0.6036036036036037 and parameters: {'max_iter': 43, 'learning_rate': 0.18621902603980706, 'max_depth': 22, 'max_leaf_nodes': 48, 'min_samples_leaf': 26, 'l2_regularization': 0.5188148482179412}. Best is trial 10 with value: 0.6396396396396397.\n[I 2023-10-02 16:25:52,309] Trial 14 finished with value: 0.6126126126126126 and parameters: {'max_iter': 93, 'learning_rate': 0.11954893138365674, 'max_depth': 7, 'max_leaf_nodes': 42, 'min_samples_leaf': 14, 'l2_regularization': 0.2037193240488681}. Best is trial 10 with value: 0.6396396396396397.\n[I 2023-10-02 16:25:54,321] Trial 15 finished with value: 0.581081081081081 and parameters: {'max_iter': 87, 'learning_rate': 0.004923321089823907, 'max_depth': 6, 'max_leaf_nodes': 43, 'min_samples_leaf': 12, 'l2_regularization': 0.17192268952507817}. Best is trial 10 with value: 0.6396396396396397.\n[I 2023-10-02 16:25:55,377] Trial 16 finished with value: 0.5518018018018018 and parameters: {'max_iter': 91, 'learning_rate': 0.002390564813384413, 'max_depth': 7, 'max_leaf_nodes': 20, 'min_samples_leaf': 11, 'l2_regularization': 0.17964088203904716}. Best is trial 10 with value: 0.6396396396396397.\n[I 2023-10-02 16:25:59,532] Trial 17 finished with value: 0.5585585585585585 and parameters: {'max_iter': 85, 'learning_rate': 0.003982721751450641, 'max_depth': 16, 'max_leaf_nodes': 19, 'min_samples_leaf': 49, 'l2_regularization': 0.6588036536903206}. Best is trial 10 with value: 0.6396396396396397.\n[I 2023-10-02 16:26:01,407] Trial 18 finished with value: 0.6306306306306306 and parameters: {'max_iter': 87, 'learning_rate': 0.039323220294402286, 'max_depth': 16, 'max_leaf_nodes': 20, 'min_samples_leaf': 40, 'l2_regularization': 0.6455079193694023}. Best is trial 10 with value: 0.6396396396396397.\n[I 2023-10-02 16:26:01,818] Trial 11 finished with value: 0.6171171171171171 and parameters: {'max_iter': 248, 'learning_rate': 0.03280248194750308, 'max_depth': 17, 'max_leaf_nodes': 60, 'min_samples_leaf': 50, 'l2_regularization': 0.6776550063657678}. Best is trial 10 with value: 0.6396396396396397.\n[I 2023-10-02 16:26:02,501] Trial 19 finished with value: 0.6171171171171171 and parameters: {'max_iter': 134, 'learning_rate': 0.05115993219675258, 'max_depth': 15, 'max_leaf_nodes': 18, 'min_samples_leaf': 49, 'l2_regularization': 0.6366225600762203}. Best is trial 10 with value: 0.6396396396396397.\nCurrent column:  nasogastric_reflux\nBest Parameters:  {'max_iter': 110, 'learning_rate': 0.11569601747243334, 'max_depth': 2, 'max_leaf_nodes': 18, 'min_samples_leaf': 50, 'l2_regularization': 0.47518985934724634}\nBest Accuracy:  0.6396396396396397\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:26:03,188] A new study created in memory with name: no-name-f7328dbf-82ca-40aa-aba2-6a0bf793b2a5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccb997ef940e4d0c8391a1c7b1de5fdc"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:26:11,006] Trial 1 finished with value: 0.7604395604395604 and parameters: {'max_iter': 69, 'learning_rate': 0.09178692655323739, 'max_depth': 19, 'max_leaf_nodes': 49, 'min_samples_leaf': 47, 'l2_regularization': 0.7368468585744922}. Best is trial 1 with value: 0.7604395604395604.\n[I 2023-10-02 16:26:19,897] Trial 4 finished with value: 0.7516483516483516 and parameters: {'max_iter': 299, 'learning_rate': 0.24418869184431655, 'max_depth': 2, 'max_leaf_nodes': 5, 'min_samples_leaf': 42, 'l2_regularization': 0.2173788076176787}. Best is trial 1 with value: 0.7604395604395604.\n[I 2023-10-02 16:26:20,848] Trial 0 finished with value: 0.7516483516483516 and parameters: {'max_iter': 203, 'learning_rate': 0.03732301642607429, 'max_depth': 7, 'max_leaf_nodes': 51, 'min_samples_leaf': 47, 'l2_regularization': 0.3721948555391241}. Best is trial 1 with value: 0.7604395604395604.\n[I 2023-10-02 16:26:23,794] Trial 2 finished with value: 0.7582417582417582 and parameters: {'max_iter': 235, 'learning_rate': 0.2145952113498549, 'max_depth': 20, 'max_leaf_nodes': 13, 'min_samples_leaf': 1, 'l2_regularization': 0.907944552857023}. Best is trial 1 with value: 0.7604395604395604.\n[I 2023-10-02 16:26:27,203] Trial 3 finished with value: 0.756043956043956 and parameters: {'max_iter': 183, 'learning_rate': 0.0152504710120254, 'max_depth': 23, 'max_leaf_nodes': 24, 'min_samples_leaf': 18, 'l2_regularization': 0.9174927957005047}. Best is trial 1 with value: 0.7604395604395604.\n[I 2023-10-02 16:26:27,623] Trial 6 finished with value: 0.7670329670329671 and parameters: {'max_iter': 167, 'learning_rate': 0.27094035249613957, 'max_depth': 3, 'max_leaf_nodes': 18, 'min_samples_leaf': 44, 'l2_regularization': 0.5758679307865289}. Best is trial 6 with value: 0.7670329670329671.\n[I 2023-10-02 16:26:32,414] Trial 5 finished with value: 0.7472527472527473 and parameters: {'max_iter': 97, 'learning_rate': 0.16542221756250305, 'max_depth': 24, 'max_leaf_nodes': 29, 'min_samples_leaf': 36, 'l2_regularization': 0.6674058576981289}. Best is trial 6 with value: 0.7670329670329671.\n[I 2023-10-02 16:26:36,790] Trial 9 finished with value: 0.7692307692307693 and parameters: {'max_iter': 71, 'learning_rate': 0.28914242960663894, 'max_depth': 13, 'max_leaf_nodes': 37, 'min_samples_leaf': 41, 'l2_regularization': 0.16911396819805924}. Best is trial 9 with value: 0.7692307692307693.\n[I 2023-10-02 16:26:41,994] Trial 11 finished with value: 0.7538461538461538 and parameters: {'max_iter': 143, 'learning_rate': 0.1625929285636646, 'max_depth': 3, 'max_leaf_nodes': 5, 'min_samples_leaf': 31, 'l2_regularization': 0.15952240858294453}. Best is trial 9 with value: 0.7692307692307693.\n[I 2023-10-02 16:26:58,800] Trial 12 finished with value: 0.7604395604395604 and parameters: {'max_iter': 209, 'learning_rate': 0.2418972660830404, 'max_depth': 8, 'max_leaf_nodes': 13, 'min_samples_leaf': 26, 'l2_regularization': 0.4864179711271923}. Best is trial 9 with value: 0.7692307692307693.\n[I 2023-10-02 16:27:09,477] Trial 10 finished with value: 0.7758241758241758 and parameters: {'max_iter': 259, 'learning_rate': 0.2561269437498609, 'max_depth': 10, 'max_leaf_nodes': 35, 'min_samples_leaf': 31, 'l2_regularization': 0.2620372572979498}. Best is trial 10 with value: 0.7758241758241758.\n[I 2023-10-02 16:27:11,035] Trial 8 finished with value: 0.7384615384615385 and parameters: {'max_iter': 272, 'learning_rate': 0.1517735798971892, 'max_depth': 13, 'max_leaf_nodes': 54, 'min_samples_leaf': 27, 'l2_regularization': 0.679193373286615}. Best is trial 10 with value: 0.7758241758241758.\n[I 2023-10-02 16:27:12,134] Trial 13 finished with value: 0.756043956043956 and parameters: {'max_iter': 54, 'learning_rate': 0.28789172644718974, 'max_depth': 14, 'max_leaf_nodes': 73, 'min_samples_leaf': 15, 'l2_regularization': 0.0824387545155961}. Best is trial 10 with value: 0.7758241758241758.\n[I 2023-10-02 16:27:18,309] Trial 15 finished with value: 0.7494505494505495 and parameters: {'max_iter': 30, 'learning_rate': 0.29729834489262125, 'max_depth': 13, 'max_leaf_nodes': 75, 'min_samples_leaf': 16, 'l2_regularization': 0.02537464690629837}. Best is trial 10 with value: 0.7758241758241758.\n[I 2023-10-02 16:27:18,777] Trial 14 finished with value: 0.7538461538461538 and parameters: {'max_iter': 39, 'learning_rate': 0.2921015126004322, 'max_depth': 13, 'max_leaf_nodes': 72, 'min_samples_leaf': 16, 'l2_regularization': 0.03072722952162088}. Best is trial 10 with value: 0.7758241758241758.\n[I 2023-10-02 16:27:24,069] Trial 7 finished with value: 0.7538461538461538 and parameters: {'max_iter': 248, 'learning_rate': 0.20512234737270862, 'max_depth': 21, 'max_leaf_nodes': 69, 'min_samples_leaf': 13, 'l2_regularization': 0.2214499349095107}. Best is trial 10 with value: 0.7758241758241758.\n[I 2023-10-02 16:27:29,967] Trial 16 finished with value: 0.756043956043956 and parameters: {'max_iter': 128, 'learning_rate': 0.29856505030438557, 'max_depth': 13, 'max_leaf_nodes': 36, 'min_samples_leaf': 36, 'l2_regularization': 0.3037728629407349}. Best is trial 10 with value: 0.7758241758241758.\n[I 2023-10-02 16:27:33,870] Trial 18 finished with value: 0.7802197802197802 and parameters: {'max_iter': 128, 'learning_rate': 0.20904530458653955, 'max_depth': 9, 'max_leaf_nodes': 34, 'min_samples_leaf': 36, 'l2_regularization': 0.29245630378173365}. Best is trial 18 with value: 0.7802197802197802.\n[I 2023-10-02 16:27:33,965] Trial 17 finished with value: 0.7626373626373626 and parameters: {'max_iter': 133, 'learning_rate': 0.19584366817427457, 'max_depth': 9, 'max_leaf_nodes': 36, 'min_samples_leaf': 36, 'l2_regularization': 0.28441369359160534}. Best is trial 18 with value: 0.7802197802197802.\n[I 2023-10-02 16:27:35,290] Trial 19 finished with value: 0.7670329670329671 and parameters: {'max_iter': 133, 'learning_rate': 0.2450558198906463, 'max_depth': 9, 'max_leaf_nodes': 37, 'min_samples_leaf': 38, 'l2_regularization': 0.3402038061370583}. Best is trial 18 with value: 0.7802197802197802.\nCurrent column:  peristalsis\nBest Parameters:  {'max_iter': 128, 'learning_rate': 0.20904530458653955, 'max_depth': 9, 'max_leaf_nodes': 34, 'min_samples_leaf': 36, 'l2_regularization': 0.29245630378173365}\nBest Accuracy:  0.7802197802197802\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:27:39,389] A new study created in memory with name: no-name-a296b325-db85-4abb-89e9-bacd3ba40d54\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32e67221d91c49869452cfc2e6bfff57"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:27:41,048] Trial 1 finished with value: 0.5394736842105263 and parameters: {'max_iter': 38, 'learning_rate': 0.19003843779136095, 'max_depth': 2, 'max_leaf_nodes': 71, 'min_samples_leaf': 19, 'l2_regularization': 0.8867044367301717}. Best is trial 1 with value: 0.5394736842105263.\n[I 2023-10-02 16:28:07,427] Trial 0 finished with value: 0.5328947368421053 and parameters: {'max_iter': 193, 'learning_rate': 0.2882414502501859, 'max_depth': 8, 'max_leaf_nodes': 16, 'min_samples_leaf': 2, 'l2_regularization': 0.39853620466340134}. Best is trial 1 with value: 0.5394736842105263.\n[I 2023-10-02 16:28:16,809] Trial 4 finished with value: 0.5416666666666666 and parameters: {'max_iter': 188, 'learning_rate': 0.03581490624062013, 'max_depth': 13, 'max_leaf_nodes': 22, 'min_samples_leaf': 2, 'l2_regularization': 0.604324933722333}. Best is trial 4 with value: 0.5416666666666666.\n[I 2023-10-02 16:28:30,731] Trial 2 finished with value: 0.5328947368421053 and parameters: {'max_iter': 233, 'learning_rate': 0.28203495889657626, 'max_depth': 20, 'max_leaf_nodes': 74, 'min_samples_leaf': 32, 'l2_regularization': 0.5461347810564008}. Best is trial 4 with value: 0.5416666666666666.\n[I 2023-10-02 16:28:35,519] Trial 5 finished with value: 0.5219298245614035 and parameters: {'max_iter': 197, 'learning_rate': 0.0869910018278367, 'max_depth': 8, 'max_leaf_nodes': 20, 'min_samples_leaf': 33, 'l2_regularization': 0.0020540374498912994}. Best is trial 4 with value: 0.5416666666666666.\n[I 2023-10-02 16:28:40,347] Trial 3 finished with value: 0.5372807017543859 and parameters: {'max_iter': 287, 'learning_rate': 0.24376155750208364, 'max_depth': 22, 'max_leaf_nodes': 74, 'min_samples_leaf': 34, 'l2_regularization': 0.5513336099565465}. Best is trial 4 with value: 0.5416666666666666.\n[I 2023-10-02 16:28:46,057] Trial 7 finished with value: 0.5350877192982456 and parameters: {'max_iter': 81, 'learning_rate': 0.07372140849512937, 'max_depth': 21, 'max_leaf_nodes': 28, 'min_samples_leaf': 40, 'l2_regularization': 0.16875251108548794}. Best is trial 4 with value: 0.5416666666666666.\n[I 2023-10-02 16:28:51,971] Trial 10 finished with value: 0.5241228070175439 and parameters: {'max_iter': 36, 'learning_rate': 0.04599552818672873, 'max_depth': 11, 'max_leaf_nodes': 23, 'min_samples_leaf': 42, 'l2_regularization': 0.49731360050868234}. Best is trial 4 with value: 0.5416666666666666.\n[I 2023-10-02 16:28:53,053] Trial 6 finished with value: 0.5416666666666666 and parameters: {'max_iter': 284, 'learning_rate': 0.22368445848936885, 'max_depth': 20, 'max_leaf_nodes': 15, 'min_samples_leaf': 43, 'l2_regularization': 0.3580713276762708}. Best is trial 4 with value: 0.5416666666666666.\n[I 2023-10-02 16:29:25,015] Trial 11 finished with value: 0.5350877192982456 and parameters: {'max_iter': 199, 'learning_rate': 0.11290273702730182, 'max_depth': 8, 'max_leaf_nodes': 59, 'min_samples_leaf': 42, 'l2_regularization': 0.548393117123191}. Best is trial 4 with value: 0.5416666666666666.\n[I 2023-10-02 16:29:27,928] Trial 12 finished with value: 0.5416666666666666 and parameters: {'max_iter': 108, 'learning_rate': 0.29097777035256445, 'max_depth': 8, 'max_leaf_nodes': 70, 'min_samples_leaf': 10, 'l2_regularization': 0.02047897903936502}. Best is trial 4 with value: 0.5416666666666666.\n[I 2023-10-02 16:29:30,324] Trial 8 finished with value: 0.5526315789473685 and parameters: {'max_iter': 282, 'learning_rate': 0.022406985728971297, 'max_depth': 13, 'max_leaf_nodes': 75, 'min_samples_leaf': 41, 'l2_regularization': 0.3260692786806305}. Best is trial 8 with value: 0.5526315789473685.\n[I 2023-10-02 16:29:30,333] Trial 13 finished with value: 0.4956140350877193 and parameters: {'max_iter': 118, 'learning_rate': 0.011816256665058478, 'max_depth': 15, 'max_leaf_nodes': 3, 'min_samples_leaf': 3, 'l2_regularization': 0.8385704277800148}. Best is trial 8 with value: 0.5526315789473685.\n[I 2023-10-02 16:29:39,099] Trial 9 finished with value: 0.5241228070175439 and parameters: {'max_iter': 250, 'learning_rate': 0.09774202044430871, 'max_depth': 25, 'max_leaf_nodes': 50, 'min_samples_leaf': 32, 'l2_regularization': 0.2226434885800781}. Best is trial 8 with value: 0.5526315789473685.\n[I 2023-10-02 16:30:02,739] Trial 17 finished with value: 0.5416666666666666 and parameters: {'max_iter': 148, 'learning_rate': 0.007537941764843972, 'max_depth': 15, 'max_leaf_nodes': 36, 'min_samples_leaf': 50, 'l2_regularization': 0.7030474539940356}. Best is trial 8 with value: 0.5526315789473685.\n[I 2023-10-02 16:30:14,666] Trial 14 finished with value: 0.5307017543859649 and parameters: {'max_iter': 296, 'learning_rate': 0.0019423660214542282, 'max_depth': 16, 'max_leaf_nodes': 39, 'min_samples_leaf': 49, 'l2_regularization': 0.8402898047761844}. Best is trial 8 with value: 0.5526315789473685.\n[I 2023-10-02 16:30:34,872] Trial 16 finished with value: 0.5197368421052632 and parameters: {'max_iter': 243, 'learning_rate': 0.006184737828913378, 'max_depth': 16, 'max_leaf_nodes': 45, 'min_samples_leaf': 24, 'l2_regularization': 0.695876219482963}. Best is trial 8 with value: 0.5526315789473685.\n[I 2023-10-02 16:30:37,270] Trial 15 finished with value: 0.5328947368421053 and parameters: {'max_iter': 247, 'learning_rate': 0.005240366505307674, 'max_depth': 15, 'max_leaf_nodes': 44, 'min_samples_leaf': 21, 'l2_regularization': 0.7670402777024619}. Best is trial 8 with value: 0.5526315789473685.\n[I 2023-10-02 16:30:54,122] Trial 18 finished with value: 0.5328947368421053 and parameters: {'max_iter': 244, 'learning_rate': 0.1406464108478418, 'max_depth': 13, 'max_leaf_nodes': 44, 'min_samples_leaf': 21, 'l2_regularization': 0.6961464019405348}. Best is trial 8 with value: 0.5526315789473685.\n[I 2023-10-02 16:30:57,640] Trial 19 finished with value: 0.5285087719298246 and parameters: {'max_iter': 234, 'learning_rate': 0.14234579001753206, 'max_depth': 12, 'max_leaf_nodes': 57, 'min_samples_leaf': 19, 'l2_regularization': 0.6748509911526093}. Best is trial 8 with value: 0.5526315789473685.\nCurrent column:  mucous_membrane\nBest Parameters:  {'max_iter': 282, 'learning_rate': 0.022406985728971297, 'max_depth': 13, 'max_leaf_nodes': 75, 'min_samples_leaf': 41, 'l2_regularization': 0.3260692786806305}\nBest Accuracy:  0.5526315789473685\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:31:11,000] A new study created in memory with name: no-name-40713b8d-3777-4c86-a489-6321b06c8934\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"850b953e6acc4b7cb550360a055e9cc5"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:31:14,362] Trial 3 finished with value: 0.5862831858407079 and parameters: {'max_iter': 41, 'learning_rate': 0.12916470870306146, 'max_depth': 13, 'max_leaf_nodes': 13, 'min_samples_leaf': 44, 'l2_regularization': 0.6661365890280785}. Best is trial 3 with value: 0.5862831858407079.\n[I 2023-10-02 16:31:26,683] Trial 0 finished with value: 0.5575221238938053 and parameters: {'max_iter': 72, 'learning_rate': 0.019118860973154336, 'max_depth': 20, 'max_leaf_nodes': 41, 'min_samples_leaf': 8, 'l2_regularization': 0.982650927731724}. Best is trial 3 with value: 0.5862831858407079.\n[I 2023-10-02 16:31:27,954] Trial 1 finished with value: 0.5973451327433629 and parameters: {'max_iter': 193, 'learning_rate': 0.12785351109600993, 'max_depth': 15, 'max_leaf_nodes': 16, 'min_samples_leaf': 31, 'l2_regularization': 0.559280967258774}. Best is trial 1 with value: 0.5973451327433629.\n[I 2023-10-02 16:31:36,518] Trial 2 finished with value: 0.5929203539823009 and parameters: {'max_iter': 207, 'learning_rate': 0.19175913815170784, 'max_depth': 19, 'max_leaf_nodes': 47, 'min_samples_leaf': 46, 'l2_regularization': 0.13811263166556487}. Best is trial 1 with value: 0.5973451327433629.\n[I 2023-10-02 16:31:36,837] Trial 6 finished with value: 0.581858407079646 and parameters: {'max_iter': 34, 'learning_rate': 0.029936737012157634, 'max_depth': 19, 'max_leaf_nodes': 80, 'min_samples_leaf': 16, 'l2_regularization': 0.9262299964920474}. Best is trial 1 with value: 0.5973451327433629.\n[I 2023-10-02 16:31:49,264] Trial 4 finished with value: 0.5796460176991151 and parameters: {'max_iter': 292, 'learning_rate': 0.038977657239577905, 'max_depth': 25, 'max_leaf_nodes': 51, 'min_samples_leaf': 48, 'l2_regularization': 0.6652293859011532}. Best is trial 1 with value: 0.5973451327433629.\n[I 2023-10-02 16:31:53,480] Trial 5 finished with value: 0.5973451327433629 and parameters: {'max_iter': 221, 'learning_rate': 0.2611816054113636, 'max_depth': 25, 'max_leaf_nodes': 58, 'min_samples_leaf': 46, 'l2_regularization': 0.2905057742968373}. Best is trial 1 with value: 0.5973451327433629.\n[I 2023-10-02 16:31:55,224] Trial 7 finished with value: 0.588495575221239 and parameters: {'max_iter': 145, 'learning_rate': 0.1428384967654989, 'max_depth': 12, 'max_leaf_nodes': 57, 'min_samples_leaf': 43, 'l2_regularization': 0.15016447032574642}. Best is trial 1 with value: 0.5973451327433629.\n[I 2023-10-02 16:32:07,073] Trial 10 finished with value: 0.5641592920353983 and parameters: {'max_iter': 231, 'learning_rate': 0.012241918945765682, 'max_depth': 20, 'max_leaf_nodes': 8, 'min_samples_leaf': 9, 'l2_regularization': 0.9227120718918298}. Best is trial 1 with value: 0.5973451327433629.\n[I 2023-10-02 16:32:09,054] Trial 12 finished with value: 0.5530973451327433 and parameters: {'max_iter': 93, 'learning_rate': 0.17918170302464367, 'max_depth': 18, 'max_leaf_nodes': 2, 'min_samples_leaf': 11, 'l2_regularization': 0.1025889964896437}. Best is trial 1 with value: 0.5973451327433629.\n[I 2023-10-02 16:32:17,491] Trial 9 finished with value: 0.6017699115044248 and parameters: {'max_iter': 167, 'learning_rate': 0.11917946560600008, 'max_depth': 25, 'max_leaf_nodes': 30, 'min_samples_leaf': 6, 'l2_regularization': 0.48431949693347787}. Best is trial 9 with value: 0.6017699115044248.\n[I 2023-10-02 16:32:20,401] Trial 13 finished with value: 0.6150442477876106 and parameters: {'max_iter': 143, 'learning_rate': 0.2948189021425955, 'max_depth': 5, 'max_leaf_nodes': 28, 'min_samples_leaf': 30, 'l2_regularization': 0.3966201958511335}. Best is trial 13 with value: 0.6150442477876106.\n[I 2023-10-02 16:32:28,688] Trial 15 finished with value: 0.5862831858407079 and parameters: {'max_iter': 140, 'learning_rate': 0.2934031823437268, 'max_depth': 4, 'max_leaf_nodes': 28, 'min_samples_leaf': 26, 'l2_regularization': 0.37311121934049496}. Best is trial 13 with value: 0.6150442477876106.\n[I 2023-10-02 16:32:32,218] Trial 16 finished with value: 0.5752212389380531 and parameters: {'max_iter': 117, 'learning_rate': 0.24252015550988726, 'max_depth': 2, 'max_leaf_nodes': 29, 'min_samples_leaf': 1, 'l2_regularization': 0.41657548683063256}. Best is trial 13 with value: 0.6150442477876106.\n[I 2023-10-02 16:32:34,397] Trial 14 finished with value: 0.6017699115044248 and parameters: {'max_iter': 155, 'learning_rate': 0.09779521168257455, 'max_depth': 7, 'max_leaf_nodes': 28, 'min_samples_leaf': 31, 'l2_regularization': 0.4696575556005239}. Best is trial 13 with value: 0.6150442477876106.\n[I 2023-10-02 16:32:49,984] Trial 8 finished with value: 0.5995575221238938 and parameters: {'max_iter': 278, 'learning_rate': 0.14344459612230928, 'max_depth': 19, 'max_leaf_nodes': 50, 'min_samples_leaf': 8, 'l2_regularization': 0.23626047416546248}. Best is trial 13 with value: 0.6150442477876106.\n[I 2023-10-02 16:32:52,329] Trial 11 finished with value: 0.6061946902654868 and parameters: {'max_iter': 255, 'learning_rate': 0.28303596058131625, 'max_depth': 12, 'max_leaf_nodes': 46, 'min_samples_leaf': 6, 'l2_regularization': 0.0408150569585074}. Best is trial 13 with value: 0.6150442477876106.\n[I 2023-10-02 16:32:52,958] Trial 17 finished with value: 0.5929203539823009 and parameters: {'max_iter': 173, 'learning_rate': 0.22064800663622844, 'max_depth': 8, 'max_leaf_nodes': 28, 'min_samples_leaf': 35, 'l2_regularization': 0.26675043436908696}. Best is trial 13 with value: 0.6150442477876106.\n[I 2023-10-02 16:32:57,671] Trial 18 finished with value: 0.5862831858407079 and parameters: {'max_iter': 180, 'learning_rate': 0.21563802161711812, 'max_depth': 8, 'max_leaf_nodes': 37, 'min_samples_leaf': 20, 'l2_regularization': 0.27169574477693226}. Best is trial 13 with value: 0.6150442477876106.\n[I 2023-10-02 16:33:01,651] Trial 19 finished with value: 0.588495575221239 and parameters: {'max_iter': 178, 'learning_rate': 0.19693771252088027, 'max_depth': 9, 'max_leaf_nodes': 36, 'min_samples_leaf': 20, 'l2_regularization': 0.3405027864492757}. Best is trial 13 with value: 0.6150442477876106.\nCurrent column:  abdominal_distention\nBest Parameters:  {'max_iter': 143, 'learning_rate': 0.2948189021425955, 'max_depth': 5, 'max_leaf_nodes': 28, 'min_samples_leaf': 30, 'l2_regularization': 0.3966201958511335}\nBest Accuracy:  0.6150442477876106\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:33:04,401] A new study created in memory with name: no-name-8308cede-1544-40b8-918d-85717083adb3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4b90c39996d4b4a82e3fcbb27656a0b"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:33:15,550] Trial 2 finished with value: 0.6300448430493274 and parameters: {'max_iter': 76, 'learning_rate': 0.04975992568237504, 'max_depth': 20, 'max_leaf_nodes': 55, 'min_samples_leaf': 44, 'l2_regularization': 0.7564023994770652}. Best is trial 2 with value: 0.6300448430493274.\n[I 2023-10-02 16:33:19,136] Trial 3 finished with value: 0.5986547085201793 and parameters: {'max_iter': 106, 'learning_rate': 0.29723249081971254, 'max_depth': 10, 'max_leaf_nodes': 20, 'min_samples_leaf': 12, 'l2_regularization': 0.09920819498490452}. Best is trial 2 with value: 0.6300448430493274.\n[I 2023-10-02 16:33:21,584] Trial 0 finished with value: 0.594170403587444 and parameters: {'max_iter': 111, 'learning_rate': 0.24486202014029235, 'max_depth': 16, 'max_leaf_nodes': 73, 'min_samples_leaf': 43, 'l2_regularization': 0.15600168791306213}. Best is trial 2 with value: 0.6300448430493274.\n[I 2023-10-02 16:33:22,091] Trial 1 finished with value: 0.6031390134529148 and parameters: {'max_iter': 61, 'learning_rate': 0.2656610004989184, 'max_depth': 25, 'max_leaf_nodes': 42, 'min_samples_leaf': 2, 'l2_regularization': 0.258120787197218}. Best is trial 2 with value: 0.6300448430493274.\n[I 2023-10-02 16:33:31,174] Trial 7 finished with value: 0.6098654708520179 and parameters: {'max_iter': 69, 'learning_rate': 0.22126214202921973, 'max_depth': 9, 'max_leaf_nodes': 64, 'min_samples_leaf': 47, 'l2_regularization': 0.20324142645838317}. Best is trial 2 with value: 0.6300448430493274.\n[I 2023-10-02 16:33:33,096] Trial 6 finished with value: 0.6165919282511211 and parameters: {'max_iter': 239, 'learning_rate': 0.07828301572838797, 'max_depth': 6, 'max_leaf_nodes': 5, 'min_samples_leaf': 13, 'l2_regularization': 0.30011897829202727}. Best is trial 2 with value: 0.6300448430493274.\n[I 2023-10-02 16:33:43,082] Trial 9 finished with value: 0.6188340807174888 and parameters: {'max_iter': 40, 'learning_rate': 0.1249838070342141, 'max_depth': 14, 'max_leaf_nodes': 35, 'min_samples_leaf': 1, 'l2_regularization': 0.8593636591426834}. Best is trial 2 with value: 0.6300448430493274.\n[I 2023-10-02 16:33:45,327] Trial 8 finished with value: 0.6143497757847534 and parameters: {'max_iter': 157, 'learning_rate': 0.24941056605224568, 'max_depth': 5, 'max_leaf_nodes': 43, 'min_samples_leaf': 37, 'l2_regularization': 0.5067892337783222}. Best is trial 2 with value: 0.6300448430493274.\n[I 2023-10-02 16:34:06,916] Trial 5 finished with value: 0.5919282511210763 and parameters: {'max_iter': 129, 'learning_rate': 0.004288401196242992, 'max_depth': 19, 'max_leaf_nodes': 71, 'min_samples_leaf': 7, 'l2_regularization': 0.989492920981925}. Best is trial 2 with value: 0.6300448430493274.\n[I 2023-10-02 16:34:17,383] Trial 4 finished with value: 0.600896860986547 and parameters: {'max_iter': 163, 'learning_rate': 0.14932273675647362, 'max_depth': 14, 'max_leaf_nodes': 64, 'min_samples_leaf': 6, 'l2_regularization': 0.49685294826225856}. Best is trial 2 with value: 0.6300448430493274.\n[I 2023-10-02 16:34:18,449] Trial 12 finished with value: 0.6367713004484304 and parameters: {'max_iter': 162, 'learning_rate': 0.06509501698694933, 'max_depth': 11, 'max_leaf_nodes': 9, 'min_samples_leaf': 49, 'l2_regularization': 0.1910645219887036}. Best is trial 12 with value: 0.6367713004484304.\n[I 2023-10-02 16:34:19,226] Trial 11 finished with value: 0.6076233183856502 and parameters: {'max_iter': 186, 'learning_rate': 0.23532373837783815, 'max_depth': 17, 'max_leaf_nodes': 26, 'min_samples_leaf': 11, 'l2_regularization': 0.8525336719801626}. Best is trial 12 with value: 0.6367713004484304.\n[I 2023-10-02 16:34:20,984] Trial 10 finished with value: 0.600896860986547 and parameters: {'max_iter': 106, 'learning_rate': 0.1457652515495586, 'max_depth': 23, 'max_leaf_nodes': 64, 'min_samples_leaf': 9, 'l2_regularization': 0.5740050653295795}. Best is trial 12 with value: 0.6367713004484304.\n[I 2023-10-02 16:34:29,532] Trial 14 finished with value: 0.6390134529147982 and parameters: {'max_iter': 227, 'learning_rate': 0.047924523141253464, 'max_depth': 21, 'max_leaf_nodes': 5, 'min_samples_leaf': 31, 'l2_regularization': 0.037013612544463004}. Best is trial 14 with value: 0.6390134529147982.\n[I 2023-10-02 16:34:43,490] Trial 17 finished with value: 0.6210762331838565 and parameters: {'max_iter': 296, 'learning_rate': 0.08288109946319724, 'max_depth': 10, 'max_leaf_nodes': 5, 'min_samples_leaf': 30, 'l2_regularization': 0.05867817201949114}. Best is trial 14 with value: 0.6390134529147982.\n[I 2023-10-02 16:35:02,002] Trial 13 finished with value: 0.6367713004484304 and parameters: {'max_iter': 235, 'learning_rate': 0.005486176452227265, 'max_depth': 22, 'max_leaf_nodes': 55, 'min_samples_leaf': 29, 'l2_regularization': 0.7438180751719017}. Best is trial 14 with value: 0.6390134529147982.\n[I 2023-10-02 16:35:06,990] Trial 18 finished with value: 0.547085201793722 and parameters: {'max_iter': 214, 'learning_rate': 0.0014314573926790808, 'max_depth': 21, 'max_leaf_nodes': 15, 'min_samples_leaf': 23, 'l2_regularization': 0.012317861944779462}. Best is trial 14 with value: 0.6390134529147982.\n[I 2023-10-02 16:35:08,948] Trial 19 finished with value: 0.6412556053811659 and parameters: {'max_iter': 212, 'learning_rate': 0.056816370806798216, 'max_depth': 2, 'max_leaf_nodes': 15, 'min_samples_leaf': 21, 'l2_regularization': 0.0165230914706624}. Best is trial 19 with value: 0.6412556053811659.\n[I 2023-10-02 16:35:11,008] Trial 16 finished with value: 0.6210762331838565 and parameters: {'max_iter': 268, 'learning_rate': 0.04552233048855299, 'max_depth': 21, 'max_leaf_nodes': 52, 'min_samples_leaf': 31, 'l2_regularization': 0.0020247251610902017}. Best is trial 19 with value: 0.6412556053811659.\n[I 2023-10-02 16:35:11,236] Trial 15 finished with value: 0.6188340807174888 and parameters: {'max_iter': 287, 'learning_rate': 0.049703011555261425, 'max_depth': 21, 'max_leaf_nodes': 54, 'min_samples_leaf': 31, 'l2_regularization': 0.05367921026107758}. Best is trial 19 with value: 0.6412556053811659.\nCurrent column:  pain\nBest Parameters:  {'max_iter': 212, 'learning_rate': 0.056816370806798216, 'max_depth': 2, 'max_leaf_nodes': 15, 'min_samples_leaf': 21, 'l2_regularization': 0.0165230914706624}\nBest Accuracy:  0.6412556053811659\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:35:13,076] A new study created in memory with name: no-name-698c60bf-955d-4a3c-a185-55c23912f063\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6a9394c94d940d582d0e6459970d4b1"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:35:15,947] Trial 3 finished with value: 0.6434977578475336 and parameters: {'max_iter': 70, 'learning_rate': 0.2229999269649512, 'max_depth': 3, 'max_leaf_nodes': 66, 'min_samples_leaf': 35, 'l2_regularization': 0.9123420959354626}. Best is trial 3 with value: 0.6434977578475336.\n[I 2023-10-02 16:35:33,349] Trial 0 finished with value: 0.6322869955156951 and parameters: {'max_iter': 240, 'learning_rate': 0.16473042665062176, 'max_depth': 20, 'max_leaf_nodes': 15, 'min_samples_leaf': 43, 'l2_regularization': 0.324689351645571}. Best is trial 3 with value: 0.6434977578475336.\n[I 2023-10-02 16:35:37,816] Trial 5 finished with value: 0.6569506726457399 and parameters: {'max_iter': 157, 'learning_rate': 0.052890500561450816, 'max_depth': 2, 'max_leaf_nodes': 50, 'min_samples_leaf': 37, 'l2_regularization': 0.4073722777197145}. Best is trial 5 with value: 0.6569506726457399.\n[I 2023-10-02 16:35:41,200] Trial 2 finished with value: 0.6591928251121076 and parameters: {'max_iter': 238, 'learning_rate': 0.00981883117071242, 'max_depth': 15, 'max_leaf_nodes': 79, 'min_samples_leaf': 45, 'l2_regularization': 0.5573842977160278}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:35:46,389] Trial 7 finished with value: 0.6524663677130045 and parameters: {'max_iter': 60, 'learning_rate': 0.04996252867738637, 'max_depth': 5, 'max_leaf_nodes': 44, 'min_samples_leaf': 22, 'l2_regularization': 0.9993258194905525}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:35:50,453] Trial 1 finished with value: 0.6434977578475336 and parameters: {'max_iter': 271, 'learning_rate': 0.017053460768459795, 'max_depth': 11, 'max_leaf_nodes': 28, 'min_samples_leaf': 20, 'l2_regularization': 0.36307909116306636}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:35:50,468] Trial 8 finished with value: 0.6434977578475336 and parameters: {'max_iter': 149, 'learning_rate': 0.2517490977596017, 'max_depth': 2, 'max_leaf_nodes': 3, 'min_samples_leaf': 34, 'l2_regularization': 0.727304063190611}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:35:51,734] Trial 6 finished with value: 0.6322869955156951 and parameters: {'max_iter': 228, 'learning_rate': 0.1931680435011034, 'max_depth': 4, 'max_leaf_nodes': 60, 'min_samples_leaf': 17, 'l2_regularization': 0.8956632672899951}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:36:03,194] Trial 9 finished with value: 0.6233183856502242 and parameters: {'max_iter': 270, 'learning_rate': 0.12658084293503127, 'max_depth': 17, 'max_leaf_nodes': 7, 'min_samples_leaf': 31, 'l2_regularization': 0.21114636896563732}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:36:09,153] Trial 4 finished with value: 0.647982062780269 and parameters: {'max_iter': 294, 'learning_rate': 0.04442651878248558, 'max_depth': 22, 'max_leaf_nodes': 38, 'min_samples_leaf': 18, 'l2_regularization': 0.24893679157407267}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:36:29,934] Trial 12 finished with value: 0.647982062780269 and parameters: {'max_iter': 89, 'learning_rate': 0.1776588705543779, 'max_depth': 16, 'max_leaf_nodes': 56, 'min_samples_leaf': 6, 'l2_regularization': 0.12857037025290718}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:36:31,133] Trial 11 finished with value: 0.6524663677130045 and parameters: {'max_iter': 267, 'learning_rate': 0.01608291557241923, 'max_depth': 21, 'max_leaf_nodes': 75, 'min_samples_leaf': 34, 'l2_regularization': 0.5618434537933871}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:36:36,086] Trial 10 finished with value: 0.6569506726457399 and parameters: {'max_iter': 152, 'learning_rate': 0.00652601606093021, 'max_depth': 23, 'max_leaf_nodes': 54, 'min_samples_leaf': 1, 'l2_regularization': 0.217313716484979}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:36:50,074] Trial 14 finished with value: 0.6591928251121076 and parameters: {'max_iter': 173, 'learning_rate': 0.09256575781674543, 'max_depth': 11, 'max_leaf_nodes': 78, 'min_samples_leaf': 49, 'l2_regularization': 0.5222197370551228}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:36:51,153] Trial 15 finished with value: 0.6569506726457399 and parameters: {'max_iter': 175, 'learning_rate': 0.09061360366269197, 'max_depth': 10, 'max_leaf_nodes': 79, 'min_samples_leaf': 49, 'l2_regularization': 0.5152607004679016}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:36:58,407] Trial 16 finished with value: 0.6502242152466368 and parameters: {'max_iter': 196, 'learning_rate': 0.0906792248749372, 'max_depth': 10, 'max_leaf_nodes': 80, 'min_samples_leaf': 50, 'l2_regularization': 0.5093117883218855}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:37:09,253] Trial 13 finished with value: 0.6524663677130045 and parameters: {'max_iter': 200, 'learning_rate': 0.11293965926780072, 'max_depth': 11, 'max_leaf_nodes': 75, 'min_samples_leaf': 1, 'l2_regularization': 0.008246861653077198}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:37:11,630] Trial 18 finished with value: 0.647982062780269 and parameters: {'max_iter': 201, 'learning_rate': 0.10631150186006333, 'max_depth': 8, 'max_leaf_nodes': 69, 'min_samples_leaf': 48, 'l2_regularization': 0.6324824339734363}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:37:11,653] Trial 17 finished with value: 0.6547085201793722 and parameters: {'max_iter': 197, 'learning_rate': 0.10561292912976485, 'max_depth': 11, 'max_leaf_nodes': 76, 'min_samples_leaf': 50, 'l2_regularization': 0.5416827952780657}. Best is trial 2 with value: 0.6591928251121076.\n[I 2023-10-02 16:37:11,780] Trial 19 finished with value: 0.647982062780269 and parameters: {'max_iter': 116, 'learning_rate': 0.28688103565454864, 'max_depth': 14, 'max_leaf_nodes': 68, 'min_samples_leaf': 43, 'l2_regularization': 0.6461767243937382}. Best is trial 2 with value: 0.6591928251121076.\nCurrent column:  temp_of_extremities\nBest Parameters:  {'max_iter': 238, 'learning_rate': 0.00981883117071242, 'max_depth': 15, 'max_leaf_nodes': 79, 'min_samples_leaf': 45, 'l2_regularization': 0.5573842977160278}\nBest Accuracy:  0.6591928251121076\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:37:18,692] A new study created in memory with name: no-name-9298f415-78c0-4702-bbfd-70db29b5918e\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0d25a14d63e4afeaf37abad2102dcc9"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:37:22,845] Trial 3 finished with value: 0.6666666666666666 and parameters: {'max_iter': 144, 'learning_rate': 0.14432296448087317, 'max_depth': 7, 'max_leaf_nodes': 5, 'min_samples_leaf': 41, 'l2_regularization': 0.519562114266474}. Best is trial 3 with value: 0.6666666666666666.\n[I 2023-10-02 16:37:22,876] Trial 0 finished with value: 0.6761229314420804 and parameters: {'max_iter': 291, 'learning_rate': 0.03583463097155569, 'max_depth': 8, 'max_leaf_nodes': 2, 'min_samples_leaf': 19, 'l2_regularization': 0.9913070810515635}. Best is trial 0 with value: 0.6761229314420804.\n[I 2023-10-02 16:37:28,063] Trial 4 finished with value: 0.6737588652482269 and parameters: {'max_iter': 60, 'learning_rate': 0.289115409860867, 'max_depth': 20, 'max_leaf_nodes': 27, 'min_samples_leaf': 50, 'l2_regularization': 0.41623579921358567}. Best is trial 0 with value: 0.6761229314420804.\n[I 2023-10-02 16:37:29,514] Trial 1 finished with value: 0.6737588652482269 and parameters: {'max_iter': 144, 'learning_rate': 0.2712854099769484, 'max_depth': 9, 'max_leaf_nodes': 20, 'min_samples_leaf': 48, 'l2_regularization': 0.8502388815397095}. Best is trial 0 with value: 0.6761229314420804.\n[I 2023-10-02 16:37:30,537] Trial 2 finished with value: 0.6784869976359338 and parameters: {'max_iter': 140, 'learning_rate': 0.08447692614948207, 'max_depth': 16, 'max_leaf_nodes': 63, 'min_samples_leaf': 50, 'l2_regularization': 0.2040462142721029}. Best is trial 2 with value: 0.6784869976359338.\n[I 2023-10-02 16:37:44,679] Trial 7 finished with value: 0.6666666666666666 and parameters: {'max_iter': 173, 'learning_rate': 0.15107334111895784, 'max_depth': 18, 'max_leaf_nodes': 63, 'min_samples_leaf': 49, 'l2_regularization': 0.2770081797343703}. Best is trial 2 with value: 0.6784869976359338.\n[I 2023-10-02 16:37:47,141] Trial 6 finished with value: 0.6666666666666666 and parameters: {'max_iter': 259, 'learning_rate': 0.07493151733336365, 'max_depth': 14, 'max_leaf_nodes': 18, 'min_samples_leaf': 31, 'l2_regularization': 0.684659675526016}. Best is trial 2 with value: 0.6784869976359338.\n[I 2023-10-02 16:37:48,187] Trial 8 finished with value: 0.6595744680851063 and parameters: {'max_iter': 166, 'learning_rate': 0.17417536442884454, 'max_depth': 23, 'max_leaf_nodes': 54, 'min_samples_leaf': 38, 'l2_regularization': 0.6174603495598366}. Best is trial 2 with value: 0.6784869976359338.\n[I 2023-10-02 16:37:48,931] Trial 5 finished with value: 0.6619385342789598 and parameters: {'max_iter': 254, 'learning_rate': 0.17655742742742564, 'max_depth': 14, 'max_leaf_nodes': 69, 'min_samples_leaf': 39, 'l2_regularization': 0.886046978584256}. Best is trial 2 with value: 0.6784869976359338.\n[I 2023-10-02 16:37:52,473] Trial 10 finished with value: 0.6737588652482269 and parameters: {'max_iter': 54, 'learning_rate': 0.24466974396360727, 'max_depth': 25, 'max_leaf_nodes': 79, 'min_samples_leaf': 44, 'l2_regularization': 0.36734679202305753}. Best is trial 2 with value: 0.6784869976359338.\n[I 2023-10-02 16:37:54,930] Trial 13 finished with value: 0.6146572104018913 and parameters: {'max_iter': 97, 'learning_rate': 0.01149822783729279, 'max_depth': 2, 'max_leaf_nodes': 45, 'min_samples_leaf': 1, 'l2_regularization': 0.030583507236271124}. Best is trial 2 with value: 0.6784869976359338.\n[I 2023-10-02 16:37:58,679] Trial 12 finished with value: 0.6879432624113475 and parameters: {'max_iter': 72, 'learning_rate': 0.0954540998086731, 'max_depth': 12, 'max_leaf_nodes': 45, 'min_samples_leaf': 27, 'l2_regularization': 0.5343070031141008}. Best is trial 12 with value: 0.6879432624113475.\n[I 2023-10-02 16:38:02,459] Trial 9 finished with value: 0.6572104018912529 and parameters: {'max_iter': 212, 'learning_rate': 0.2679848478884378, 'max_depth': 12, 'max_leaf_nodes': 19, 'min_samples_leaf': 31, 'l2_regularization': 0.925464850118266}. Best is trial 12 with value: 0.6879432624113475.\n[I 2023-10-02 16:38:03,039] Trial 11 finished with value: 0.6524822695035462 and parameters: {'max_iter': 163, 'learning_rate': 0.258275640176364, 'max_depth': 13, 'max_leaf_nodes': 49, 'min_samples_leaf': 47, 'l2_regularization': 0.5176593707288658}. Best is trial 12 with value: 0.6879432624113475.\n[I 2023-10-02 16:38:12,154] Trial 15 finished with value: 0.6666666666666666 and parameters: {'max_iter': 91, 'learning_rate': 0.08875200914306906, 'max_depth': 17, 'max_leaf_nodes': 40, 'min_samples_leaf': 19, 'l2_regularization': 0.1981221142153566}. Best is trial 12 with value: 0.6879432624113475.\n[I 2023-10-02 16:38:16,737] Trial 18 finished with value: 0.6997635933806147 and parameters: {'max_iter': 92, 'learning_rate': 0.09904856891858856, 'max_depth': 4, 'max_leaf_nodes': 60, 'min_samples_leaf': 6, 'l2_regularization': 0.17183791279103977}. Best is trial 18 with value: 0.6997635933806147.\n[I 2023-10-02 16:38:16,780] Trial 17 finished with value: 0.6784869976359338 and parameters: {'max_iter': 97, 'learning_rate': 0.08958470902607676, 'max_depth': 19, 'max_leaf_nodes': 37, 'min_samples_leaf': 16, 'l2_regularization': 0.20066038256950647}. Best is trial 18 with value: 0.6997635933806147.\n[I 2023-10-02 16:38:17,701] Trial 16 finished with value: 0.6926713947990544 and parameters: {'max_iter': 103, 'learning_rate': 0.08760588147991948, 'max_depth': 17, 'max_leaf_nodes': 40, 'min_samples_leaf': 16, 'l2_regularization': 0.21762658243950112}. Best is trial 18 with value: 0.6997635933806147.\n[I 2023-10-02 16:38:19,403] Trial 19 finished with value: 0.6737588652482269 and parameters: {'max_iter': 99, 'learning_rate': 0.11130580217101903, 'max_depth': 4, 'max_leaf_nodes': 37, 'min_samples_leaf': 4, 'l2_regularization': 0.05158596868127112}. Best is trial 18 with value: 0.6997635933806147.\n[I 2023-10-02 16:38:21,195] Trial 14 finished with value: 0.6832151300236406 and parameters: {'max_iter': 289, 'learning_rate': 0.037666989939826534, 'max_depth': 8, 'max_leaf_nodes': 38, 'min_samples_leaf': 17, 'l2_regularization': 0.9952427101088616}. Best is trial 18 with value: 0.6997635933806147.\nCurrent column:  abdomo_appearance\nBest Parameters:  {'max_iter': 92, 'learning_rate': 0.09904856891858856, 'max_depth': 4, 'max_leaf_nodes': 60, 'min_samples_leaf': 6, 'l2_regularization': 0.17183791279103977}\nBest Accuracy:  0.6997635933806147\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:38:22,301] A new study created in memory with name: no-name-c85fe9ce-2c3a-4b27-9d76-6f75be6af871\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b50c620a1604ab19366efdfe0f66f6d"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:38:25,791] Trial 3 finished with value: 0.8054919908466819 and parameters: {'max_iter': 45, 'learning_rate': 0.020945338645258063, 'max_depth': 7, 'max_leaf_nodes': 18, 'min_samples_leaf': 50, 'l2_regularization': 0.03404802647330796}. Best is trial 3 with value: 0.8054919908466819.\n[I 2023-10-02 16:38:29,463] Trial 4 finished with value: 0.8237986270022883 and parameters: {'max_iter': 130, 'learning_rate': 0.15625037258764202, 'max_depth': 2, 'max_leaf_nodes': 32, 'min_samples_leaf': 41, 'l2_regularization': 0.2606014307559854}. Best is trial 4 with value: 0.8237986270022883.\n[I 2023-10-02 16:38:30,476] Trial 0 finished with value: 0.8283752860411899 and parameters: {'max_iter': 77, 'learning_rate': 0.0333247682573096, 'max_depth': 13, 'max_leaf_nodes': 20, 'min_samples_leaf': 11, 'l2_regularization': 0.01775308937100506}. Best is trial 0 with value: 0.8283752860411899.\n[I 2023-10-02 16:38:33,488] Trial 5 finished with value: 0.8329519450800915 and parameters: {'max_iter': 143, 'learning_rate': 0.2900576457079718, 'max_depth': 2, 'max_leaf_nodes': 52, 'min_samples_leaf': 11, 'l2_regularization': 0.29689028628203695}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:38:38,615] Trial 1 finished with value: 0.8192219679633868 and parameters: {'max_iter': 196, 'learning_rate': 0.15554158505715904, 'max_depth': 23, 'max_leaf_nodes': 16, 'min_samples_leaf': 28, 'l2_regularization': 0.48616453842525353}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:38:44,151] Trial 2 finished with value: 0.8192219679633868 and parameters: {'max_iter': 188, 'learning_rate': 0.11767212079166006, 'max_depth': 16, 'max_leaf_nodes': 34, 'min_samples_leaf': 21, 'l2_regularization': 0.006227420358683622}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:38:45,383] Trial 8 finished with value: 0.816933638443936 and parameters: {'max_iter': 163, 'learning_rate': 0.15227813177901334, 'max_depth': 3, 'max_leaf_nodes': 42, 'min_samples_leaf': 11, 'l2_regularization': 0.6072107717209085}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:38:47,171] Trial 9 finished with value: 0.816933638443936 and parameters: {'max_iter': 30, 'learning_rate': 0.1405096650361837, 'max_depth': 8, 'max_leaf_nodes': 79, 'min_samples_leaf': 33, 'l2_regularization': 0.5108722532767963}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:38:48,510] Trial 10 finished with value: 0.8123569794050344 and parameters: {'max_iter': 48, 'learning_rate': 0.11747269847224283, 'max_depth': 5, 'max_leaf_nodes': 21, 'min_samples_leaf': 34, 'l2_regularization': 0.0007536019092768687}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:38:54,823] Trial 6 finished with value: 0.816933638443936 and parameters: {'max_iter': 213, 'learning_rate': 0.033641696421983294, 'max_depth': 11, 'max_leaf_nodes': 46, 'min_samples_leaf': 32, 'l2_regularization': 0.7140069634708854}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:38:55,887] Trial 11 finished with value: 0.8283752860411899 and parameters: {'max_iter': 144, 'learning_rate': 0.20948113763275217, 'max_depth': 16, 'max_leaf_nodes': 9, 'min_samples_leaf': 12, 'l2_regularization': 0.6622433354766395}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:38:58,085] Trial 7 finished with value: 0.8146453089244852 and parameters: {'max_iter': 222, 'learning_rate': 0.040596237256062546, 'max_depth': 10, 'max_leaf_nodes': 51, 'min_samples_leaf': 33, 'l2_regularization': 0.831153292552418}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:38:58,090] Trial 12 finished with value: 0.8100686498855835 and parameters: {'max_iter': 82, 'learning_rate': 0.09055665828505138, 'max_depth': 8, 'max_leaf_nodes': 75, 'min_samples_leaf': 20, 'l2_regularization': 0.03477247341890688}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:39:17,525] Trial 14 finished with value: 0.8100686498855835 and parameters: {'max_iter': 97, 'learning_rate': 0.28770178139235214, 'max_depth': 22, 'max_leaf_nodes': 59, 'min_samples_leaf': 3, 'l2_regularization': 0.9380521513849602}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:39:19,252] Trial 16 finished with value: 0.8077803203661327 and parameters: {'max_iter': 98, 'learning_rate': 0.29619210132385704, 'max_depth': 22, 'max_leaf_nodes': 59, 'min_samples_leaf': 2, 'l2_regularization': 0.22825452193776635}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:39:26,774] Trial 18 finished with value: 0.8237986270022883 and parameters: {'max_iter': 266, 'learning_rate': 0.22697473973850757, 'max_depth': 14, 'max_leaf_nodes': 3, 'min_samples_leaf': 11, 'l2_regularization': 0.24794961457681758}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:39:41,623] Trial 17 finished with value: 0.816933638443936 and parameters: {'max_iter': 109, 'learning_rate': 0.27052264575645907, 'max_depth': 19, 'max_leaf_nodes': 61, 'min_samples_leaf': 1, 'l2_regularization': 0.2331538212657958}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:39:41,972] Trial 19 finished with value: 0.8192219679633868 and parameters: {'max_iter': 125, 'learning_rate': 0.08314859427761333, 'max_depth': 20, 'max_leaf_nodes': 31, 'min_samples_leaf': 18, 'l2_regularization': 0.36848065960192156}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:39:48,390] Trial 13 finished with value: 0.8123569794050344 and parameters: {'max_iter': 289, 'learning_rate': 0.2912748307633139, 'max_depth': 19, 'max_leaf_nodes': 59, 'min_samples_leaf': 4, 'l2_regularization': 0.8154433501272705}. Best is trial 5 with value: 0.8329519450800915.\n[I 2023-10-02 16:39:50,027] Trial 15 finished with value: 0.8283752860411899 and parameters: {'max_iter': 296, 'learning_rate': 0.29234593809051673, 'max_depth': 23, 'max_leaf_nodes': 65, 'min_samples_leaf': 2, 'l2_regularization': 0.26931932094756766}. Best is trial 5 with value: 0.8329519450800915.\nCurrent column:  peripheral_pulse\nBest Parameters:  {'max_iter': 143, 'learning_rate': 0.2900576457079718, 'max_depth': 2, 'max_leaf_nodes': 52, 'min_samples_leaf': 11, 'l2_regularization': 0.29689028628203695}\nBest Accuracy:  0.8329519450800915\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:39:51,077] A new study created in memory with name: no-name-8ef13f5f-e9e3-418b-9fd5-915754398a89\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47d251d256b745c590a05b154766192a"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:39:52,192] Trial 2 finished with value: 0.6824644549763034 and parameters: {'max_iter': 49, 'learning_rate': 0.11176802466375277, 'max_depth': 2, 'max_leaf_nodes': 65, 'min_samples_leaf': 32, 'l2_regularization': 0.5050286940978512}. Best is trial 2 with value: 0.6824644549763034.\n[I 2023-10-02 16:39:54,378] Trial 1 finished with value: 0.6635071090047393 and parameters: {'max_iter': 135, 'learning_rate': 0.09224292383311605, 'max_depth': 3, 'max_leaf_nodes': 4, 'min_samples_leaf': 9, 'l2_regularization': 0.2882943706733503}. Best is trial 2 with value: 0.6824644549763034.\n[I 2023-10-02 16:39:58,841] Trial 5 finished with value: 0.6848341232227488 and parameters: {'max_iter': 73, 'learning_rate': 0.24649370671341772, 'max_depth': 5, 'max_leaf_nodes': 60, 'min_samples_leaf': 9, 'l2_regularization': 0.055713005670105176}. Best is trial 5 with value: 0.6848341232227488.\n[I 2023-10-02 16:39:59,979] Trial 0 finished with value: 0.6777251184834123 and parameters: {'max_iter': 73, 'learning_rate': 0.23039948541061453, 'max_depth': 9, 'max_leaf_nodes': 47, 'min_samples_leaf': 23, 'l2_regularization': 0.7916665043519447}. Best is trial 5 with value: 0.6848341232227488.\n[I 2023-10-02 16:40:08,845] Trial 7 finished with value: 0.6777251184834123 and parameters: {'max_iter': 163, 'learning_rate': 0.10896081421627003, 'max_depth': 13, 'max_leaf_nodes': 13, 'min_samples_leaf': 44, 'l2_regularization': 0.5350737408892812}. Best is trial 5 with value: 0.6848341232227488.\n[I 2023-10-02 16:40:17,538] Trial 4 finished with value: 0.6635071090047393 and parameters: {'max_iter': 238, 'learning_rate': 0.0775515016166336, 'max_depth': 15, 'max_leaf_nodes': 30, 'min_samples_leaf': 31, 'l2_regularization': 0.9493507228971599}. Best is trial 5 with value: 0.6848341232227488.\n[I 2023-10-02 16:40:22,848] Trial 8 finished with value: 0.6682464454976303 and parameters: {'max_iter': 169, 'learning_rate': 0.2675090210011819, 'max_depth': 22, 'max_leaf_nodes': 69, 'min_samples_leaf': 50, 'l2_regularization': 0.9478058359942897}. Best is trial 5 with value: 0.6848341232227488.\n[I 2023-10-02 16:40:23,413] Trial 3 finished with value: 0.6943127962085308 and parameters: {'max_iter': 122, 'learning_rate': 0.1825251265868927, 'max_depth': 17, 'max_leaf_nodes': 65, 'min_samples_leaf': 2, 'l2_regularization': 0.10481950230278037}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:40:32,806] Trial 11 finished with value: 0.6824644549763034 and parameters: {'max_iter': 281, 'learning_rate': 0.011156301533198926, 'max_depth': 15, 'max_leaf_nodes': 6, 'min_samples_leaf': 8, 'l2_regularization': 0.2844881905671266}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:40:35,810] Trial 10 finished with value: 0.6729857819905213 and parameters: {'max_iter': 166, 'learning_rate': 0.19028147579645097, 'max_depth': 6, 'max_leaf_nodes': 24, 'min_samples_leaf': 14, 'l2_regularization': 0.6865779093918095}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:40:45,928] Trial 6 finished with value: 0.6635071090047393 and parameters: {'max_iter': 224, 'learning_rate': 0.25170859558565184, 'max_depth': 24, 'max_leaf_nodes': 55, 'min_samples_leaf': 9, 'l2_regularization': 0.3219953435876294}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:40:46,521] Trial 12 finished with value: 0.6706161137440758 and parameters: {'max_iter': 75, 'learning_rate': 0.09077591635541915, 'max_depth': 19, 'max_leaf_nodes': 60, 'min_samples_leaf': 18, 'l2_regularization': 0.6068501284282379}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:41:02,227] Trial 9 finished with value: 0.6753554502369669 and parameters: {'max_iter': 243, 'learning_rate': 0.12418693924222368, 'max_depth': 23, 'max_leaf_nodes': 66, 'min_samples_leaf': 17, 'l2_regularization': 0.5494584452447867}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:41:02,834] Trial 13 finished with value: 0.6753554502369669 and parameters: {'max_iter': 115, 'learning_rate': 0.18043244534812083, 'max_depth': 25, 'max_leaf_nodes': 80, 'min_samples_leaf': 2, 'l2_regularization': 0.0004299507371854777}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:41:04,945] Trial 15 finished with value: 0.6682464454976303 and parameters: {'max_iter': 111, 'learning_rate': 0.29729166137845237, 'max_depth': 9, 'max_leaf_nodes': 78, 'min_samples_leaf': 2, 'l2_regularization': 0.0011353157418358961}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:41:13,838] Trial 14 finished with value: 0.6777251184834123 and parameters: {'max_iter': 100, 'learning_rate': 0.29311385610456264, 'max_depth': 19, 'max_leaf_nodes': 78, 'min_samples_leaf': 1, 'l2_regularization': 0.01837555873073271}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:41:14,000] Trial 18 finished with value: 0.6824644549763034 and parameters: {'max_iter': 48, 'learning_rate': 0.20339577067093972, 'max_depth': 18, 'max_leaf_nodes': 45, 'min_samples_leaf': 2, 'l2_regularization': 0.13564863278720118}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:41:17,589] Trial 17 finished with value: 0.6777251184834123 and parameters: {'max_iter': 98, 'learning_rate': 0.2897750825820041, 'max_depth': 11, 'max_leaf_nodes': 43, 'min_samples_leaf': 1, 'l2_regularization': 0.0019532518678230526}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:41:19,388] Trial 19 finished with value: 0.6800947867298578 and parameters: {'max_iter': 64, 'learning_rate': 0.22445143364753323, 'max_depth': 12, 'max_leaf_nodes': 46, 'min_samples_leaf': 25, 'l2_regularization': 0.1591732444869438}. Best is trial 3 with value: 0.6943127962085308.\n[I 2023-10-02 16:41:19,955] Trial 16 finished with value: 0.6824644549763034 and parameters: {'max_iter': 109, 'learning_rate': 0.2928417328052355, 'max_depth': 8, 'max_leaf_nodes': 79, 'min_samples_leaf': 1, 'l2_regularization': 0.015861703731457538}. Best is trial 3 with value: 0.6943127962085308.\nCurrent column:  nasogastric_tube\nBest Parameters:  {'max_iter': 122, 'learning_rate': 0.1825251265868927, 'max_depth': 17, 'max_leaf_nodes': 65, 'min_samples_leaf': 2, 'l2_regularization': 0.10481950230278037}\nBest Accuracy:  0.6943127962085308\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:41:27,698] A new study created in memory with name: no-name-6c05a2fa-62b3-4f2f-ace6-fe30275e8deb\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1892d237db549dbace403b6631e865d"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:41:42,603] Trial 0 finished with value: 0.6298200514138818 and parameters: {'max_iter': 211, 'learning_rate': 0.25837221847958475, 'max_depth': 16, 'max_leaf_nodes': 12, 'min_samples_leaf': 10, 'l2_regularization': 0.0675095471471171}. Best is trial 0 with value: 0.6298200514138818.\n[I 2023-10-02 16:41:46,328] Trial 1 finished with value: 0.6426735218508998 and parameters: {'max_iter': 59, 'learning_rate': 0.13061872734187743, 'max_depth': 12, 'max_leaf_nodes': 72, 'min_samples_leaf': 5, 'l2_regularization': 0.8777767757136506}. Best is trial 1 with value: 0.6426735218508998.\n[I 2023-10-02 16:41:48,382] Trial 3 finished with value: 0.6580976863753213 and parameters: {'max_iter': 146, 'learning_rate': 0.0530612821950686, 'max_depth': 13, 'max_leaf_nodes': 47, 'min_samples_leaf': 29, 'l2_regularization': 0.6999417684843576}. Best is trial 3 with value: 0.6580976863753213.\n[I 2023-10-02 16:41:59,927] Trial 6 finished with value: 0.6632390745501285 and parameters: {'max_iter': 53, 'learning_rate': 0.013055807512819595, 'max_depth': 15, 'max_leaf_nodes': 58, 'min_samples_leaf': 15, 'l2_regularization': 0.16437655077364866}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:06,748] Trial 5 finished with value: 0.6478149100257069 and parameters: {'max_iter': 183, 'learning_rate': 0.07002443178153997, 'max_depth': 11, 'max_leaf_nodes': 73, 'min_samples_leaf': 39, 'l2_regularization': 0.8349599104109641}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:12,052] Trial 4 finished with value: 0.6195372750642674 and parameters: {'max_iter': 291, 'learning_rate': 0.2501473327907826, 'max_depth': 5, 'max_leaf_nodes': 52, 'min_samples_leaf': 3, 'l2_regularization': 0.5359387325480315}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:13,776] Trial 2 finished with value: 0.6426735218508998 and parameters: {'max_iter': 212, 'learning_rate': 0.25131091453210613, 'max_depth': 24, 'max_leaf_nodes': 39, 'min_samples_leaf': 1, 'l2_regularization': 0.5608979016882419}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:22,084] Trial 7 finished with value: 0.6246786632390745 and parameters: {'max_iter': 72, 'learning_rate': 0.2769164634560711, 'max_depth': 21, 'max_leaf_nodes': 72, 'min_samples_leaf': 8, 'l2_regularization': 0.5166598090081835}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:23,287] Trial 10 finished with value: 0.6349614395886889 and parameters: {'max_iter': 51, 'learning_rate': 0.23858148527188172, 'max_depth': 11, 'max_leaf_nodes': 57, 'min_samples_leaf': 18, 'l2_regularization': 0.8212612374670117}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:30,591] Trial 11 finished with value: 0.6375321336760925 and parameters: {'max_iter': 34, 'learning_rate': 0.2878285366734433, 'max_depth': 13, 'max_leaf_nodes': 80, 'min_samples_leaf': 13, 'l2_regularization': 0.712851289285886}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:32,522] Trial 12 finished with value: 0.6529562982005142 and parameters: {'max_iter': 140, 'learning_rate': 0.06886903140211297, 'max_depth': 6, 'max_leaf_nodes': 20, 'min_samples_leaf': 46, 'l2_regularization': 0.6394142467020534}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:33,862] Trial 13 finished with value: 0.6503856041131105 and parameters: {'max_iter': 120, 'learning_rate': 0.03226453961908379, 'max_depth': 2, 'max_leaf_nodes': 27, 'min_samples_leaf': 49, 'l2_regularization': 0.21353114728587283}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:37,573] Trial 8 finished with value: 0.6555269922879178 and parameters: {'max_iter': 285, 'learning_rate': 0.02998985163793566, 'max_depth': 19, 'max_leaf_nodes': 78, 'min_samples_leaf': 44, 'l2_regularization': 0.7490707392767385}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:49,372] Trial 14 finished with value: 0.6632390745501285 and parameters: {'max_iter': 116, 'learning_rate': 0.013277757030753179, 'max_depth': 18, 'max_leaf_nodes': 37, 'min_samples_leaf': 29, 'l2_regularization': 0.2474945940646086}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:50,493] Trial 15 finished with value: 0.6503856041131105 and parameters: {'max_iter': 109, 'learning_rate': 0.016228091857153182, 'max_depth': 17, 'max_leaf_nodes': 50, 'min_samples_leaf': 28, 'l2_regularization': 0.2641455806329839}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:42:52,294] Trial 16 finished with value: 0.6426735218508998 and parameters: {'max_iter': 104, 'learning_rate': 0.00405622247304005, 'max_depth': 17, 'max_leaf_nodes': 52, 'min_samples_leaf': 29, 'l2_regularization': 0.3830523362519278}. Best is trial 6 with value: 0.6632390745501285.\n[I 2023-10-02 16:43:03,509] Trial 17 finished with value: 0.6760925449871465 and parameters: {'max_iter': 96, 'learning_rate': 0.01040527792284604, 'max_depth': 17, 'max_leaf_nodes': 35, 'min_samples_leaf': 26, 'l2_regularization': 0.25989408744861797}. Best is trial 17 with value: 0.6760925449871465.\n[I 2023-10-02 16:43:03,910] Trial 18 finished with value: 0.6298200514138818 and parameters: {'max_iter': 91, 'learning_rate': 0.004583031178715861, 'max_depth': 25, 'max_leaf_nodes': 34, 'min_samples_leaf': 21, 'l2_regularization': 0.35528594047808665}. Best is trial 17 with value: 0.6760925449871465.\n[I 2023-10-02 16:43:04,111] Trial 19 finished with value: 0.6349614395886889 and parameters: {'max_iter': 79, 'learning_rate': 0.10320223260290719, 'max_depth': 25, 'max_leaf_nodes': 34, 'min_samples_leaf': 20, 'l2_regularization': 0.037452518958478453}. Best is trial 17 with value: 0.6760925449871465.\n[I 2023-10-02 16:43:08,650] Trial 9 finished with value: 0.6401028277634961 and parameters: {'max_iter': 260, 'learning_rate': 0.13955065752943732, 'max_depth': 12, 'max_leaf_nodes': 60, 'min_samples_leaf': 7, 'l2_regularization': 0.7613989473865849}. Best is trial 17 with value: 0.6760925449871465.\nCurrent column:  rectal_exam_feces\nBest Parameters:  {'max_iter': 96, 'learning_rate': 0.01040527792284604, 'max_depth': 17, 'max_leaf_nodes': 35, 'min_samples_leaf': 26, 'l2_regularization': 0.25989408744861797}\nBest Accuracy:  0.6760925449871465\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:43:12,102] A new study created in memory with name: no-name-34134b83-3088-4f45-9208-01bb778141ec\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e48c9677880c42ac988547b12bbf33ce"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:43:14,271] Trial 1 finished with value: 0.752 and parameters: {'max_iter': 64, 'learning_rate': 0.041455694450813374, 'max_depth': 2, 'max_leaf_nodes': 7, 'min_samples_leaf': 12, 'l2_regularization': 0.8080974542449705}. Best is trial 1 with value: 0.752.\n[I 2023-10-02 16:43:15,307] Trial 0 finished with value: 0.7493333333333333 and parameters: {'max_iter': 146, 'learning_rate': 0.08880074804389967, 'max_depth': 16, 'max_leaf_nodes': 2, 'min_samples_leaf': 16, 'l2_regularization': 0.339251162242757}. Best is trial 1 with value: 0.752.\n[I 2023-10-02 16:43:16,656] Trial 5 finished with value: 0.7653333333333333 and parameters: {'max_iter': 41, 'learning_rate': 0.2857727060649253, 'max_depth': 2, 'max_leaf_nodes': 75, 'min_samples_leaf': 35, 'l2_regularization': 0.16499159016149012}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:43:26,842] Trial 2 finished with value: 0.7413333333333333 and parameters: {'max_iter': 284, 'learning_rate': 0.25211191047066306, 'max_depth': 25, 'max_leaf_nodes': 6, 'min_samples_leaf': 4, 'l2_regularization': 0.3511438016083359}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:43:30,790] Trial 3 finished with value: 0.752 and parameters: {'max_iter': 275, 'learning_rate': 0.045774699736737576, 'max_depth': 21, 'max_leaf_nodes': 9, 'min_samples_leaf': 19, 'l2_regularization': 0.364340761972723}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:43:38,107] Trial 6 finished with value: 0.7226666666666667 and parameters: {'max_iter': 144, 'learning_rate': 0.00613965048721847, 'max_depth': 10, 'max_leaf_nodes': 59, 'min_samples_leaf': 27, 'l2_regularization': 0.12202024245380705}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:43:43,632] Trial 4 finished with value: 0.7466666666666667 and parameters: {'max_iter': 243, 'learning_rate': 0.13851616167770145, 'max_depth': 17, 'max_leaf_nodes': 34, 'min_samples_leaf': 42, 'l2_regularization': 0.26716878213099915}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:43:51,542] Trial 9 finished with value: 0.648 and parameters: {'max_iter': 278, 'learning_rate': 0.0012439345431117259, 'max_depth': 3, 'max_leaf_nodes': 22, 'min_samples_leaf': 15, 'l2_regularization': 0.8796285505833247}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:43:51,603] Trial 7 finished with value: 0.7466666666666667 and parameters: {'max_iter': 195, 'learning_rate': 0.24585737581718686, 'max_depth': 8, 'max_leaf_nodes': 75, 'min_samples_leaf': 34, 'l2_regularization': 0.612813383806236}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:43:57,282] Trial 12 finished with value: 0.7573333333333333 and parameters: {'max_iter': 264, 'learning_rate': 0.2553894819357509, 'max_depth': 20, 'max_leaf_nodes': 2, 'min_samples_leaf': 25, 'l2_regularization': 0.19354902809757946}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:43:57,377] Trial 8 finished with value: 0.7466666666666667 and parameters: {'max_iter': 227, 'learning_rate': 0.18526894099357608, 'max_depth': 23, 'max_leaf_nodes': 16, 'min_samples_leaf': 1, 'l2_regularization': 0.05543515898445872}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:44:00,890] Trial 13 finished with value: 0.7493333333333333 and parameters: {'max_iter': 34, 'learning_rate': 0.2908923586468911, 'max_depth': 7, 'max_leaf_nodes': 79, 'min_samples_leaf': 46, 'l2_regularization': 0.00599629894259851}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:44:02,095] Trial 14 finished with value: 0.736 and parameters: {'max_iter': 40, 'learning_rate': 0.2991089454650919, 'max_depth': 12, 'max_leaf_nodes': 53, 'min_samples_leaf': 50, 'l2_regularization': 0.005755978020831276}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:44:13,444] Trial 10 finished with value: 0.7493333333333333 and parameters: {'max_iter': 268, 'learning_rate': 0.15441416413695175, 'max_depth': 25, 'max_leaf_nodes': 65, 'min_samples_leaf': 48, 'l2_regularization': 0.2045883422260263}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:44:15,138] Trial 15 finished with value: 0.76 and parameters: {'max_iter': 101, 'learning_rate': 0.2795613546678447, 'max_depth': 13, 'max_leaf_nodes': 52, 'min_samples_leaf': 33, 'l2_regularization': 0.15663421803010436}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:44:16,397] Trial 16 finished with value: 0.7493333333333333 and parameters: {'max_iter': 99, 'learning_rate': 0.2179530395024067, 'max_depth': 19, 'max_leaf_nodes': 36, 'min_samples_leaf': 33, 'l2_regularization': 0.15326237150595373}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:44:24,747] Trial 19 finished with value: 0.7653333333333333 and parameters: {'max_iter': 99, 'learning_rate': 0.2996509495352152, 'max_depth': 5, 'max_leaf_nodes': 47, 'min_samples_leaf': 38, 'l2_regularization': 0.5387397498834806}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:44:24,880] Trial 18 finished with value: 0.752 and parameters: {'max_iter': 96, 'learning_rate': 0.21346549168020804, 'max_depth': 6, 'max_leaf_nodes': 47, 'min_samples_leaf': 36, 'l2_regularization': 0.5268568630125673}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:44:25,370] Trial 17 finished with value: 0.736 and parameters: {'max_iter': 86, 'learning_rate': 0.23233288843771202, 'max_depth': 19, 'max_leaf_nodes': 42, 'min_samples_leaf': 33, 'l2_regularization': 0.17921537120821107}. Best is trial 5 with value: 0.7653333333333333.\n[I 2023-10-02 16:44:28,957] Trial 11 finished with value: 0.7333333333333333 and parameters: {'max_iter': 159, 'learning_rate': 0.010881261595780487, 'max_depth': 23, 'max_leaf_nodes': 59, 'min_samples_leaf': 4, 'l2_regularization': 0.541337544876602}. Best is trial 5 with value: 0.7653333333333333.\nCurrent column:  abdomen\nBest Parameters:  {'max_iter': 41, 'learning_rate': 0.2857727060649253, 'max_depth': 2, 'max_leaf_nodes': 75, 'min_samples_leaf': 35, 'l2_regularization': 0.16499159016149012}\nBest Accuracy:  0.7653333333333333\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:44:29,358] A new study created in memory with name: no-name-f62d81fe-2b33-443d-96ad-808111fa43ed\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8a8f45628ef464eb3e78062f817b69e"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:44:44,721] Trial 0 finished with value: 0.9879807692307693 and parameters: {'max_iter': 221, 'learning_rate': 0.14986774897719635, 'max_depth': 8, 'max_leaf_nodes': 43, 'min_samples_leaf': 25, 'l2_regularization': 0.7495978515492958}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:44:46,090] Trial 1 finished with value: 0.9831730769230769 and parameters: {'max_iter': 229, 'learning_rate': 0.25121700909387545, 'max_depth': 19, 'max_leaf_nodes': 46, 'min_samples_leaf': 22, 'l2_regularization': 0.9256274708297236}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:44:48,239] Trial 4 finished with value: 0.9855769230769231 and parameters: {'max_iter': 105, 'learning_rate': 0.18101384774931265, 'max_depth': 3, 'max_leaf_nodes': 32, 'min_samples_leaf': 21, 'l2_regularization': 0.21009004806250509}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:44:48,336] Trial 3 finished with value: 0.9831730769230769 and parameters: {'max_iter': 290, 'learning_rate': 0.22353596239544263, 'max_depth': 8, 'max_leaf_nodes': 45, 'min_samples_leaf': 28, 'l2_regularization': 0.40073411575467777}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:44:49,506] Trial 2 finished with value: 0.9879807692307693 and parameters: {'max_iter': 259, 'learning_rate': 0.22788903568530267, 'max_depth': 22, 'max_leaf_nodes': 20, 'min_samples_leaf': 9, 'l2_regularization': 0.9440507159918211}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:44:51,277] Trial 6 finished with value: 0.9759615384615384 and parameters: {'max_iter': 43, 'learning_rate': 0.13987159015144635, 'max_depth': 24, 'max_leaf_nodes': 22, 'min_samples_leaf': 16, 'l2_regularization': 0.5192435093348786}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:44:52,696] Trial 7 finished with value: 0.9759615384615384 and parameters: {'max_iter': 118, 'learning_rate': 0.08743444606190978, 'max_depth': 10, 'max_leaf_nodes': 6, 'min_samples_leaf': 23, 'l2_regularization': 0.7441237148598959}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:44:54,028] Trial 10 finished with value: 0.9759615384615384 and parameters: {'max_iter': 31, 'learning_rate': 0.0311761311073413, 'max_depth': 8, 'max_leaf_nodes': 9, 'min_samples_leaf': 32, 'l2_regularization': 0.062000667995651404}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:44:55,145] Trial 9 finished with value: 0.9807692307692307 and parameters: {'max_iter': 64, 'learning_rate': 0.21027021791481448, 'max_depth': 13, 'max_leaf_nodes': 75, 'min_samples_leaf': 44, 'l2_regularization': 0.49108480456490433}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:44:56,598] Trial 11 finished with value: 0.9879807692307693 and parameters: {'max_iter': 159, 'learning_rate': 0.10766471179498498, 'max_depth': 11, 'max_leaf_nodes': 2, 'min_samples_leaf': 27, 'l2_regularization': 0.7144266449198907}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:45:00,670] Trial 5 finished with value: 0.9855769230769231 and parameters: {'max_iter': 252, 'learning_rate': 0.2825974737014658, 'max_depth': 17, 'max_leaf_nodes': 80, 'min_samples_leaf': 46, 'l2_regularization': 0.8358209045281778}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:45:01,449] Trial 13 finished with value: 0.9879807692307693 and parameters: {'max_iter': 202, 'learning_rate': 0.29697356511283857, 'max_depth': 2, 'max_leaf_nodes': 62, 'min_samples_leaf': 1, 'l2_regularization': 0.7071805890399374}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:45:01,465] Trial 8 finished with value: 0.9855769230769231 and parameters: {'max_iter': 290, 'learning_rate': 0.23500857318631083, 'max_depth': 6, 'max_leaf_nodes': 7, 'min_samples_leaf': 32, 'l2_regularization': 0.20909798990503692}. Best is trial 0 with value: 0.9879807692307693.\n[I 2023-10-02 16:45:07,384] Trial 12 finished with value: 0.9903846153846154 and parameters: {'max_iter': 143, 'learning_rate': 0.2879507948547956, 'max_depth': 23, 'max_leaf_nodes': 39, 'min_samples_leaf': 9, 'l2_regularization': 0.3154106559817914}. Best is trial 12 with value: 0.9903846153846154.\n[I 2023-10-02 16:45:17,554] Trial 16 finished with value: 0.9855769230769231 and parameters: {'max_iter': 185, 'learning_rate': 0.16275435167476168, 'max_depth': 25, 'max_leaf_nodes': 26, 'min_samples_leaf': 8, 'l2_regularization': 0.919407409142281}. Best is trial 12 with value: 0.9903846153846154.\n[I 2023-10-02 16:45:23,460] Trial 17 finished with value: 0.9903846153846154 and parameters: {'max_iter': 177, 'learning_rate': 0.1692791506404699, 'max_depth': 16, 'max_leaf_nodes': 55, 'min_samples_leaf': 9, 'l2_regularization': 0.5848667799566776}. Best is trial 12 with value: 0.9903846153846154.\n[I 2023-10-02 16:45:23,552] Trial 14 finished with value: 0.9831730769230769 and parameters: {'max_iter': 216, 'learning_rate': 0.29505966004168993, 'max_depth': 25, 'max_leaf_nodes': 53, 'min_samples_leaf': 2, 'l2_regularization': 0.9720423370460626}. Best is trial 12 with value: 0.9903846153846154.\n[I 2023-10-02 16:45:25,828] Trial 18 finished with value: 0.9783653846153846 and parameters: {'max_iter': 141, 'learning_rate': 0.18168771425838626, 'max_depth': 16, 'max_leaf_nodes': 55, 'min_samples_leaf': 38, 'l2_regularization': 0.599013392989151}. Best is trial 12 with value: 0.9903846153846154.\n[I 2023-10-02 16:45:26,559] Trial 15 finished with value: 0.9903846153846154 and parameters: {'max_iter': 292, 'learning_rate': 0.17368667758492906, 'max_depth': 23, 'max_leaf_nodes': 27, 'min_samples_leaf': 5, 'l2_regularization': 0.9887523310336611}. Best is trial 12 with value: 0.9903846153846154.\n[I 2023-10-02 16:45:29,194] Trial 19 finished with value: 0.9879807692307693 and parameters: {'max_iter': 145, 'learning_rate': 0.27098934728694923, 'max_depth': 17, 'max_leaf_nodes': 58, 'min_samples_leaf': 1, 'l2_regularization': 0.563270860377687}. Best is trial 12 with value: 0.9903846153846154.\nCurrent column:  type\nBest Parameters:  {'max_iter': 143, 'learning_rate': 0.2879507948547956, 'max_depth': 23, 'max_leaf_nodes': 39, 'min_samples_leaf': 9, 'l2_regularization': 0.3154106559817914}\nBest Accuracy:  0.9903846153846154\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:45:32,232] A new study created in memory with name: no-name-4c774f37-1867-430c-96ca-7aa054bfe0a1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f124fc58179846a3868f074763456ef8"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:45:37,607] Trial 1 finished with value: 0.951048951048951 and parameters: {'max_iter': 87, 'learning_rate': 0.2871397483133162, 'max_depth': 8, 'max_leaf_nodes': 28, 'min_samples_leaf': 28, 'l2_regularization': 0.4650645357113956}. Best is trial 1 with value: 0.951048951048951.\n[I 2023-10-02 16:45:38,696] Trial 4 finished with value: 0.9533799533799534 and parameters: {'max_iter': 62, 'learning_rate': 0.2471626214298992, 'max_depth': 2, 'max_leaf_nodes': 6, 'min_samples_leaf': 47, 'l2_regularization': 0.7382541466542245}. Best is trial 4 with value: 0.9533799533799534.\n[I 2023-10-02 16:45:40,876] Trial 0 finished with value: 0.9487179487179487 and parameters: {'max_iter': 160, 'learning_rate': 0.2779986960518513, 'max_depth': 17, 'max_leaf_nodes': 59, 'min_samples_leaf': 41, 'l2_regularization': 0.9850051444465966}. Best is trial 4 with value: 0.9533799533799534.\n[I 2023-10-02 16:45:43,743] Trial 5 finished with value: 0.9463869463869464 and parameters: {'max_iter': 157, 'learning_rate': 0.04334292752344514, 'max_depth': 4, 'max_leaf_nodes': 62, 'min_samples_leaf': 25, 'l2_regularization': 0.7837563976553864}. Best is trial 4 with value: 0.9533799533799534.\n[I 2023-10-02 16:45:47,394] Trial 2 finished with value: 0.951048951048951 and parameters: {'max_iter': 153, 'learning_rate': 0.1532743540188731, 'max_depth': 23, 'max_leaf_nodes': 35, 'min_samples_leaf': 4, 'l2_regularization': 0.8926724171431151}. Best is trial 4 with value: 0.9533799533799534.\n[I 2023-10-02 16:45:50,714] Trial 8 finished with value: 0.9557109557109557 and parameters: {'max_iter': 139, 'learning_rate': 0.18286937347604418, 'max_depth': 25, 'max_leaf_nodes': 5, 'min_samples_leaf': 15, 'l2_regularization': 0.009523132683176616}. Best is trial 8 with value: 0.9557109557109557.\n[I 2023-10-02 16:45:51,720] Trial 7 finished with value: 0.951048951048951 and parameters: {'max_iter': 132, 'learning_rate': 0.17968622344593885, 'max_depth': 16, 'max_leaf_nodes': 17, 'min_samples_leaf': 9, 'l2_regularization': 0.9564984164076}. Best is trial 8 with value: 0.9557109557109557.\n[I 2023-10-02 16:45:52,807] Trial 3 finished with value: 0.965034965034965 and parameters: {'max_iter': 248, 'learning_rate': 0.03198659887886069, 'max_depth': 17, 'max_leaf_nodes': 78, 'min_samples_leaf': 14, 'l2_regularization': 0.3175745278829234}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:45:57,165] Trial 6 finished with value: 0.9533799533799534 and parameters: {'max_iter': 289, 'learning_rate': 0.015575805627928697, 'max_depth': 22, 'max_leaf_nodes': 58, 'min_samples_leaf': 26, 'l2_regularization': 0.7452404430333865}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:45:58,821] Trial 10 finished with value: 0.951048951048951 and parameters: {'max_iter': 135, 'learning_rate': 0.26251919108565963, 'max_depth': 8, 'max_leaf_nodes': 61, 'min_samples_leaf': 44, 'l2_regularization': 0.8830765334065837}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:46:00,156] Trial 9 finished with value: 0.951048951048951 and parameters: {'max_iter': 285, 'learning_rate': 0.13613539062096602, 'max_depth': 19, 'max_leaf_nodes': 8, 'min_samples_leaf': 35, 'l2_regularization': 0.30478923396477087}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:46:09,626] Trial 11 finished with value: 0.9627039627039627 and parameters: {'max_iter': 204, 'learning_rate': 0.1790961271860847, 'max_depth': 9, 'max_leaf_nodes': 53, 'min_samples_leaf': 9, 'l2_regularization': 0.07350933226081657}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:46:15,168] Trial 14 finished with value: 0.9533799533799534 and parameters: {'max_iter': 220, 'learning_rate': 0.08355209735470895, 'max_depth': 25, 'max_leaf_nodes': 78, 'min_samples_leaf': 14, 'l2_regularization': 0.0030219607797436487}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:46:16,486] Trial 12 finished with value: 0.958041958041958 and parameters: {'max_iter': 267, 'learning_rate': 0.07585733820709206, 'max_depth': 6, 'max_leaf_nodes': 31, 'min_samples_leaf': 2, 'l2_regularization': 0.2232743051484013}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:46:19,329] Trial 13 finished with value: 0.951048951048951 and parameters: {'max_iter': 254, 'learning_rate': 0.07258902630228886, 'max_depth': 11, 'max_leaf_nodes': 79, 'min_samples_leaf': 18, 'l2_regularization': 0.28859784015379164}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:46:30,957] Trial 17 finished with value: 0.958041958041958 and parameters: {'max_iter': 215, 'learning_rate': 0.009971900146735962, 'max_depth': 11, 'max_leaf_nodes': 79, 'min_samples_leaf': 18, 'l2_regularization': 0.17986717131174945}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:46:31,306] Trial 15 finished with value: 0.9557109557109557 and parameters: {'max_iter': 234, 'learning_rate': 0.07955522412316404, 'max_depth': 12, 'max_leaf_nodes': 76, 'min_samples_leaf': 15, 'l2_regularization': 0.1583970040617101}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:46:38,880] Trial 18 finished with value: 0.9557109557109557 and parameters: {'max_iter': 215, 'learning_rate': 0.11264304311409609, 'max_depth': 12, 'max_leaf_nodes': 48, 'min_samples_leaf': 8, 'l2_regularization': 0.15444071999633582}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:46:40,830] Trial 16 finished with value: 0.9207459207459208 and parameters: {'max_iter': 225, 'learning_rate': 0.0020312356597259884, 'max_depth': 12, 'max_leaf_nodes': 74, 'min_samples_leaf': 1, 'l2_regularization': 0.20914831548108548}. Best is trial 3 with value: 0.965034965034965.\n[I 2023-10-02 16:46:42,200] Trial 19 finished with value: 0.958041958041958 and parameters: {'max_iter': 204, 'learning_rate': 0.1307221225495038, 'max_depth': 14, 'max_leaf_nodes': 48, 'min_samples_leaf': 8, 'l2_regularization': 0.4407902469523921}. Best is trial 3 with value: 0.965034965034965.\nCurrent column:  subtype\nBest Parameters:  {'max_iter': 248, 'learning_rate': 0.03198659887886069, 'max_depth': 17, 'max_leaf_nodes': 78, 'min_samples_leaf': 14, 'l2_regularization': 0.3175745278829234}\nBest Accuracy:  0.965034965034965\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:46:47,345] A new study created in memory with name: no-name-eea7f5a6-e335-4b61-ac2f-cf62e5ca4afb\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/20 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f10dc61ca84743e8ad4871e529ccbf21"}},"metadata":{}},{"name":"stdout","text":"[I 2023-10-02 16:46:54,384] Trial 2 finished with value: 0.6864608076009501 and parameters: {'max_iter': 48, 'learning_rate': 0.28742305128290774, 'max_depth': 5, 'max_leaf_nodes': 13, 'min_samples_leaf': 16, 'l2_regularization': 0.5550635227672983}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:47:01,486] Trial 0 finished with value: 0.66270783847981 and parameters: {'max_iter': 163, 'learning_rate': 0.14058235504316313, 'max_depth': 3, 'max_leaf_nodes': 61, 'min_samples_leaf': 36, 'l2_regularization': 0.01421065817813505}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:47:07,622] Trial 1 finished with value: 0.6460807600950119 and parameters: {'max_iter': 58, 'learning_rate': 0.24180486702628645, 'max_depth': 13, 'max_leaf_nodes': 61, 'min_samples_leaf': 14, 'l2_regularization': 0.6955368158026042}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:47:08,766] Trial 4 finished with value: 0.667458432304038 and parameters: {'max_iter': 47, 'learning_rate': 0.2286073835491978, 'max_depth': 17, 'max_leaf_nodes': 32, 'min_samples_leaf': 10, 'l2_regularization': 0.5488593135588243}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:47:16,924] Trial 7 finished with value: 0.6413301662707839 and parameters: {'max_iter': 94, 'learning_rate': 0.215335749652784, 'max_depth': 3, 'max_leaf_nodes': 18, 'min_samples_leaf': 37, 'l2_regularization': 0.8894616248080777}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:47:24,859] Trial 3 finished with value: 0.667458432304038 and parameters: {'max_iter': 237, 'learning_rate': 0.03976539755620315, 'max_depth': 6, 'max_leaf_nodes': 48, 'min_samples_leaf': 27, 'l2_regularization': 0.12130684810026826}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:47:27,528] Trial 5 finished with value: 0.6437054631828979 and parameters: {'max_iter': 133, 'learning_rate': 0.19044112002316044, 'max_depth': 19, 'max_leaf_nodes': 24, 'min_samples_leaf': 47, 'l2_regularization': 0.08291222021304345}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:47:41,380] Trial 8 finished with value: 0.6460807600950119 and parameters: {'max_iter': 168, 'learning_rate': 0.0039577850205963164, 'max_depth': 23, 'max_leaf_nodes': 61, 'min_samples_leaf': 41, 'l2_regularization': 0.016278108096630328}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:47:52,082] Trial 9 finished with value: 0.665083135391924 and parameters: {'max_iter': 98, 'learning_rate': 0.07066645920495489, 'max_depth': 8, 'max_leaf_nodes': 27, 'min_samples_leaf': 1, 'l2_regularization': 0.36195829977873106}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:48:04,875] Trial 12 finished with value: 0.6342042755344418 and parameters: {'max_iter': 63, 'learning_rate': 0.24100834420278422, 'max_depth': 6, 'max_leaf_nodes': 68, 'min_samples_leaf': 15, 'l2_regularization': 0.05430801128709173}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:48:16,704] Trial 6 finished with value: 0.6484560570071259 and parameters: {'max_iter': 286, 'learning_rate': 0.1836570817592157, 'max_depth': 20, 'max_leaf_nodes': 78, 'min_samples_leaf': 31, 'l2_regularization': 0.3479302747607689}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:48:18,404] Trial 10 finished with value: 0.6532066508313539 and parameters: {'max_iter': 272, 'learning_rate': 0.014265049724043872, 'max_depth': 14, 'max_leaf_nodes': 62, 'min_samples_leaf': 29, 'l2_regularization': 0.7714900880659524}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:48:33,174] Trial 13 finished with value: 0.6318289786223278 and parameters: {'max_iter': 283, 'learning_rate': 0.2978111475096141, 'max_depth': 11, 'max_leaf_nodes': 6, 'min_samples_leaf': 24, 'l2_regularization': 0.34803835803738403}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:48:33,354] Trial 11 finished with value: 0.6508313539192399 and parameters: {'max_iter': 246, 'learning_rate': 0.06335103083665944, 'max_depth': 12, 'max_leaf_nodes': 48, 'min_samples_leaf': 38, 'l2_regularization': 0.45695184062956273}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:48:35,187] Trial 14 finished with value: 0.6294536817102138 and parameters: {'max_iter': 241, 'learning_rate': 0.2984703244138754, 'max_depth': 10, 'max_leaf_nodes': 4, 'min_samples_leaf': 23, 'l2_regularization': 0.26353966676875307}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:48:47,457] Trial 15 finished with value: 0.6460807600950119 and parameters: {'max_iter': 230, 'learning_rate': 0.2639862152620284, 'max_depth': 9, 'max_leaf_nodes': 8, 'min_samples_leaf': 22, 'l2_regularization': 0.28952073272091605}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:49:19,733] Trial 18 finished with value: 0.6769596199524941 and parameters: {'max_iter': 207, 'learning_rate': 0.13254348664962556, 'max_depth': 6, 'max_leaf_nodes': 44, 'min_samples_leaf': 22, 'l2_regularization': 0.5817032081043723}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:49:21,953] Trial 17 finished with value: 0.6460807600950119 and parameters: {'max_iter': 209, 'learning_rate': 0.12197962083262734, 'max_depth': 7, 'max_leaf_nodes': 45, 'min_samples_leaf': 24, 'l2_regularization': 0.21207052222854883}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:49:30,283] Trial 16 finished with value: 0.6484560570071259 and parameters: {'max_iter': 228, 'learning_rate': 0.1312967691897892, 'max_depth': 8, 'max_leaf_nodes': 44, 'min_samples_leaf': 19, 'l2_regularization': 0.9900795842129144}. Best is trial 2 with value: 0.6864608076009501.\n[I 2023-10-02 16:49:30,539] Trial 19 finished with value: 0.6817102137767221 and parameters: {'max_iter': 195, 'learning_rate': 0.13923513063788762, 'max_depth': 6, 'max_leaf_nodes': 43, 'min_samples_leaf': 6, 'l2_regularization': 0.5519150793244343}. Best is trial 2 with value: 0.6864608076009501.\nCurrent column:  specific_code\nBest Parameters:  {'max_iter': 48, 'learning_rate': 0.28742305128290774, 'max_depth': 5, 'max_leaf_nodes': 13, 'min_samples_leaf': 16, 'l2_regularization': 0.5550635227672983}\nBest Accuracy:  0.6864608076009501\n     surgery    age  rectal_temp  pulse  respiratory_rate temp_of_extremities  \\\n0        yes  adult        38.10 132.00             24.00                cool   \n1        yes  adult        37.50  88.00             12.00                cool   \n2        yes  adult        38.30 120.00             28.00                cool   \n3        yes  adult        37.10  72.00             30.00                cold   \n4         no  adult        38.00  52.00             48.00              normal   \n...      ...    ...          ...    ...               ...                 ...   \n2353      no  adult        40.30 114.00             36.00                cool   \n2354     yes  adult        37.20 100.00             20.00                cool   \n2355     yes  adult        39.20 132.00             12.00                cool   \n2356      no  adult        38.30  54.00             66.00              normal   \n2357     yes  adult        38.10  66.00             12.00                cold   \n\n     peripheral_pulse mucous_membrane capillary_refill_time          pain  \\\n0             reduced   dark_cyanotic            more_3_sec     depressed   \n1              normal   pale_cyanotic            more_3_sec     mild_pain   \n2             reduced       pale_pink            less_3_sec  extreme_pain   \n3             reduced       pale_pink            more_3_sec     mild_pain   \n4              normal     normal_pink            less_3_sec         alert   \n...               ...             ...                   ...           ...   \n2353          reduced     normal_pink            more_3_sec     depressed   \n2354          reduced   pale_cyanotic            more_3_sec  extreme_pain   \n2355          reduced   dark_cyanotic            more_3_sec     depressed   \n2356           normal     normal_pink            less_3_sec     mild_pain   \n2357           normal     normal_pink            less_3_sec     mild_pain   \n\n      ... abdomo_appearance abdomo_protein surgical_lesion cp_data  outcome  \\\n0     ...     serosanguious           3.40             yes      no     1.00   \n1     ...     serosanguious           2.00             yes      no     0.00   \n2     ...     serosanguious           3.40             yes      no     2.00   \n3     ...            cloudy           3.90             yes     yes     2.00   \n4     ...            cloudy           2.60              no     yes     2.00   \n...   ...               ...            ...             ...     ...      ...   \n2353  ...     serosanguious           4.50             yes     yes      NaN   \n2354  ...     serosanguious           2.00             yes      no      NaN   \n2355  ...     serosanguious           4.50             yes      no      NaN   \n2356  ...             clear           5.00              no     yes      NaN   \n2357  ...            cloudy           1.60             yes     yes      NaN   \n\n     frequency             site           type     subtype  \\\n0        20.00  small intestine  strangulation         n/a   \n1        16.00  small intestine  strangulation         n/a   \n2         2.00            cecum         simple   paralytic   \n3         3.00  small intestine  strangulation         n/a   \n4         9.00             none         simple  mechanical   \n...        ...              ...            ...         ...   \n2353     83.00      large colon  strangulation         n/a   \n2354      9.00  small intestine  strangulation         n/a   \n2355      5.00  small intestine  strangulation         n/a   \n2356     35.00      large colon         simple  mechanical   \n2357     19.00  small intestine  strangulation         n/a   \n\n                     specific_code  \n0     lipoma/splenic incarceration  \n1                           hernia  \n2                         adynamic  \n3                           hernia  \n4                       obturation  \n...                            ...  \n2353              volvulus/torsion  \n2354  lipoma/splenic incarceration  \n2355              volvulus/torsion  \n2356                    obturation  \n2357              volvulus/torsion  \n\n[2358 rows x 29 columns]\nIndex(['surgery', 'age', 'rectal_temp', 'pulse', 'respiratory_rate',\n       'temp_of_extremities', 'peripheral_pulse', 'mucous_membrane',\n       'capillary_refill_time', 'pain', 'peristalsis', 'abdominal_distention',\n       'nasogastric_tube', 'nasogastric_reflux', 'nasogastric_reflux_ph',\n       'rectal_exam_feces', 'abdomen', 'packed_cell_volume', 'total_protein',\n       'abdomo_appearance', 'abdomo_protein', 'surgical_lesion', 'cp_data',\n       'outcome', 'frequency', 'site', 'type', 'subtype', 'specific_code'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"for col in categorical_feats:\n    print(total[col].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.309085Z","iopub.execute_input":"2023-10-02T16:49:32.309372Z","iopub.status.idle":"2023-10-02T16:49:32.322567Z","shell.execute_reply.started":"2023-10-02T16:49:32.309348Z","shell.execute_reply":"2023-10-02T16:49:32.321298Z"},"trusted":true},"execution_count":696,"outputs":[{"name":"stdout","text":"0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nfor col in categorical_feats:\n    total[col] = total[col].fillna(total[col].mode()[0])\n\n'''","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.324719Z","iopub.execute_input":"2023-10-02T16:49:32.325173Z","iopub.status.idle":"2023-10-02T16:49:32.348945Z","shell.execute_reply.started":"2023-10-02T16:49:32.325131Z","shell.execute_reply":"2023-10-02T16:49:32.346883Z"},"trusted":true},"execution_count":697,"outputs":[{"execution_count":697,"output_type":"execute_result","data":{"text/plain":"'\\nfor col in categorical_feats:\\n    total[col] = total[col].fillna(total[col].mode()[0])\\n\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"****would be better to use KNN imputer  ( will try in later vesrion ) ****","metadata":{}},{"cell_type":"code","source":"# def chi_squared_test(df, input_var, target_var, significance_level=0.05):\n#     contingency_table = pd.crosstab(df[input_var], df[target_var])\n    \n    \n#     chi2, p, _, _ = stats.chi2_contingency(contingency_table)\n    \n#     if p < significance_level:\n#         print(f'\\033[32m{input_var} has a significant relationship with the target variable.\\033[0m') \n#     else:\n#         print(f'\\033[31m{input_var} does not have a significant relationship with the target variable.\\033[0m')  \n    \n# for i in categorical_feats:\n#     chi_squared_test(total, i, target)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.353434Z","iopub.execute_input":"2023-10-02T16:49:32.353772Z","iopub.status.idle":"2023-10-02T16:49:32.361986Z","shell.execute_reply.started":"2023-10-02T16:49:32.353746Z","shell.execute_reply":"2023-10-02T16:49:32.361011Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":698,"outputs":[]},{"cell_type":"code","source":"total['mucous_membrane'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.363664Z","iopub.execute_input":"2023-10-02T16:49:32.364615Z","iopub.status.idle":"2023-10-02T16:49:32.389932Z","shell.execute_reply.started":"2023-10-02T16:49:32.364572Z","shell.execute_reply":"2023-10-02T16:49:32.388383Z"},"trusted":true},"execution_count":699,"outputs":[{"execution_count":699,"output_type":"execute_result","data":{"text/plain":"array(['dark_cyanotic', 'pale_cyanotic', 'pale_pink', 'normal_pink',\n       'bright_pink', 'bright_red'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"\npulse_threshold = 80  \nmucous_membrane_colors = ['pale_cyanotic', 'dark_cyanotic']\ncapillary_refill_criteria = 'more_3_sec'\npain_levels = ['severe_pain']\nrespiratory_rate_threshold = 25  \ntemperature_of_extremities_criteria = ['cold']  \nperpulse = ['absent']\nabdominal_distention = ['severe']\nrectal = 36\n\n\npulse_weight = 0.3\nmucous_membrane_weight = 0.25\ncapillary_refill_weight = 0.15\npain_weight = 0.2\nrespiratory_rate_weight = 0.15  \ntemperature_of_extremities_weight = 0.15 \nperipheral_pulse_weight = 0.15\nabdominal_distention_weight = 0.15\nrectal_weight = 0.05\n\n\n\ndef calculate_shock_probability(row):\n    \n    probability = 0  \n\n   \n    if row['pulse'] > pulse_threshold:\n        probability += pulse_weight\n    if row['mucous_membrane'] in mucous_membrane_colors:\n        probability += mucous_membrane_weight\n    if row['capillary_refill_time'] == capillary_refill_criteria:\n        probability += capillary_refill_weight\n    if row['pain'] in pain_levels:\n        probability += pain_weight\n    if row['respiratory_rate'] > respiratory_rate_threshold:\n        probability += respiratory_rate_weight\n    if row['temp_of_extremities'] == temperature_of_extremities_criteria:\n        probability += temperature_of_extremities_weight\n        \n    if row['peripheral_pulse'] == perpulse:\n        probability += peripheral_pulse_weight   \n    if row['abdominal_distention'] == abdominal_distention:\n        probability += abdominal_distention_weight      \n\n    if row['rectal_temp'] < rectal:\n        probability += rectal_weight   \n       \n  \n    probability = min(max(probability, 0), 1)\n\n    return probability\n\n\ntotal['shock_probability'] = total.apply(calculate_shock_probability, axis=1)\n\n\nprint(total['shock_probability'].describe())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.392297Z","iopub.execute_input":"2023-10-02T16:49:32.392716Z","iopub.status.idle":"2023-10-02T16:49:32.545495Z","shell.execute_reply.started":"2023-10-02T16:49:32.392677Z","shell.execute_reply":"2023-10-02T16:49:32.544260Z"},"trusted":true},"execution_count":700,"outputs":[{"name":"stdout","text":"count   2,358.00\nmean        0.36\nstd         0.30\nmin         0.00\n25%         0.00\n50%         0.30\n75%         0.60\nmax         1.00\nName: shock_probability, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"total[\"rectal_temp\"] = (total[\"rectal_temp\"] - 37.8).abs()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.547428Z","iopub.execute_input":"2023-10-02T16:49:32.547892Z","iopub.status.idle":"2023-10-02T16:49:32.555542Z","shell.execute_reply.started":"2023-10-02T16:49:32.547823Z","shell.execute_reply":"2023-10-02T16:49:32.553673Z"},"trusted":true},"execution_count":701,"outputs":[]},{"cell_type":"markdown","source":"****its better to calculate the deviation rather than the values itselt ****","metadata":{}},{"cell_type":"code","source":"encodings = {\n    ('none', 'clear'): 11,\n    ('slight', 'clear'): 10,\n    ('none', 'cloudy'): 9,\n    ('slight', 'cloudy'): 8,\n    ('moderate', 'clear'): 7,\n    ('moderate', 'cloudy'): 6,\n    ('severe', 'clear'): 5,\n    ('severe', 'cloudy'): 4,\n    ('none', 'serosanguious'): 3,\n    ('slight', 'serosanguious'): 2,\n    ('moderate', 'serosanguious'): 1,\n    ('severe', 'serosanguious'): 0\n}\n\n# Create the new encoded feature using the combinations\ntotal['encoded_combination'] = total.apply(lambda row: encodings[(row['abdominal_distention'], row['abdomo_appearance'])], axis=1)\n\n# Print the updated DataFrame to see the new feature\nprint(total['encoded_combination'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.558040Z","iopub.execute_input":"2023-10-02T16:49:32.558439Z","iopub.status.idle":"2023-10-02T16:49:32.615773Z","shell.execute_reply.started":"2023-10-02T16:49:32.558402Z","shell.execute_reply":"2023-10-02T16:49:32.614483Z"},"trusted":true},"execution_count":702,"outputs":[{"name":"stdout","text":"encoded_combination\n1     591\n2     278\n6     246\n10    209\n8     207\n11    191\n9     188\n0     142\n7     122\n3      94\n4      55\n5      35\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"****after trying various plots , these are my findings about possible abdominal_distention and  abdomo_appearance  ( arranged them from worst to best where 0 is the worst ****","metadata":{}},{"cell_type":"code","source":"total.drop(['abdominal_distention', 'abdomo_appearance'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.617702Z","iopub.execute_input":"2023-10-02T16:49:32.618156Z","iopub.status.idle":"2023-10-02T16:49:32.627925Z","shell.execute_reply.started":"2023-10-02T16:49:32.618112Z","shell.execute_reply":"2023-10-02T16:49:32.626694Z"},"trusted":true},"execution_count":703,"outputs":[]},{"cell_type":"code","source":"total[\"temp_of_extremities\"] = total[\"temp_of_extremities\"].map({'cool':0,'cold':1,'warm':2,'normal':3 })\ntotal[\"peripheral_pulse\"] = total[\"peripheral_pulse\"].map({'absent':0,'reduced':1,'increased':2,'normal':3})\ntotal[\"capillary_refill_time\"] = total[\"capillary_refill_time\"].map({'more_3_sec':0,'3':1,'less_3_sec':2})\ntotal[\"pain\"] = total[\"pain\"].map({'severe_pain':0.0,'extreme_pain':1.0,'depressed':2.0,'moderate':3.0,'mild_pain':4.0,'alert':5.0})\ntotal[\"peristalsis\"] = total[\"peristalsis\"].map({'absent':0,'hypermotile':1,'hypomotile':2,'normal':3})\n\ntotal[\"nasogastric_reflux\"] = total[\"nasogastric_reflux\"].map({'more_1_liter':0,'less_1_liter':1,'none':2})\ntotal[\"rectal_exam_feces\"] = total[\"rectal_exam_feces\"].map({\"absent\":0,'decreased':1,'increased':2,'normal':3})\ntotal[\"nasogastric_tube\"] = total[\"nasogastric_tube\"].map({'significant':0,'slight':1,'none':2})\n# total[\"abdominal_distention\"] = total[\"abdominal_distention\"].map({'none':0,'slight':1,'moderate':2,'severe':3})\n# total[\"abdomo_appearance\"] = total[\"abdomo_appearance\"].map({'serosanguious':0,'cloudy':1,'clear':2})\ntotal[\"abdomen\"] = total[\"abdomen\"].map({'distend_large':0,'distend_small':1,'firm':2,'other':3,'normal':4})\ntotal[\"site\"] = total[\"site\"].map({'gastric':0,'small intestine':1,'large colon':2,'large colon and cecum':4,'cecum':3 , 'transverse colon':5,'rectum/descending colon':6,'uterus':7, 'bladder':8 ,'all intestinal sites':10 ,'none':9 })\ntotal[\"type\"] = total[\"type\"].map({'simple':3,'inflammation':2,'strangulation':1,'other':0})\n# total[\"subtype\"] = total[\"subtype\"].map({'paralytic':0,'mechanical':1,'n/a':2})\ntotal[\"specific_code\"] = total[\"specific_code\"].map({'lipoma/splenic incarceration':0,'hernia':1,'adynamic':2,'volvulus/torsion':4,'obturation':3 , 'thromboembolic':5,'intussusception':6,'extrinsic':7, 'intrinsic':8 ,'n/a':9 ,'displacement':10 })\n# total[\"mucous_membrane\"] = total[\"mucous_membrane\"].map({'dark_cyanotic' : 0 , 'pale_cyanotic' : 1 , 'bright_red':2 , 'pale_pink' : 4 , 'bright_pink': 3 , 'normal_pink' : 5})\ntotal[\"surgery\"] = total[\"surgery\"].map({'yes':0,'no':1})\ntotal[\"age\"] = total[\"age\"].map({'young':0,'adult':1})\ntotal[\"surgical_lesion\"] = total[\"surgical_lesion\"].map({'yes':0,'no':1})\ntotal[\"cp_data\"] = total[\"cp_data\"].map({'no':0,'yes':1})","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.641013Z","iopub.execute_input":"2023-10-02T16:49:32.643942Z","iopub.status.idle":"2023-10-02T16:49:32.673461Z","shell.execute_reply.started":"2023-10-02T16:49:32.643882Z","shell.execute_reply":"2023-10-02T16:49:32.672547Z"},"trusted":true},"execution_count":704,"outputs":[]},{"cell_type":"code","source":"categorical_feats = []\nfor column in total.columns:\n   \n    if total[column].dtype == 'object':\n       \n        categorical_feats.append(column)\n\n\nprint(categorical_feats)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.675026Z","iopub.execute_input":"2023-10-02T16:49:32.675842Z","iopub.status.idle":"2023-10-02T16:49:32.682225Z","shell.execute_reply.started":"2023-10-02T16:49:32.675813Z","shell.execute_reply":"2023-10-02T16:49:32.681374Z"},"trusted":true},"execution_count":705,"outputs":[{"name":"stdout","text":"['mucous_membrane', 'subtype']\n","output_type":"stream"}]},{"cell_type":"code","source":"numerical_features = []\n\n\nfor column in total.columns:\n    \n    if pd.api.types.is_numeric_dtype(total[column]):\n     \n        numerical_features.append(column)\n\n\nprint(numerical_features)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.683354Z","iopub.execute_input":"2023-10-02T16:49:32.683808Z","iopub.status.idle":"2023-10-02T16:49:32.697506Z","shell.execute_reply.started":"2023-10-02T16:49:32.683778Z","shell.execute_reply":"2023-10-02T16:49:32.696482Z"},"trusted":true},"execution_count":706,"outputs":[{"name":"stdout","text":"['surgery', 'age', 'rectal_temp', 'pulse', 'respiratory_rate', 'temp_of_extremities', 'peripheral_pulse', 'capillary_refill_time', 'pain', 'peristalsis', 'nasogastric_tube', 'nasogastric_reflux', 'nasogastric_reflux_ph', 'rectal_exam_feces', 'abdomen', 'packed_cell_volume', 'total_protein', 'abdomo_protein', 'surgical_lesion', 'cp_data', 'outcome', 'frequency', 'site', 'type', 'specific_code', 'shock_probability', 'encoded_combination']\n","output_type":"stream"}]},{"cell_type":"code","source":"encfeats=['surgery','age','surgical_lesion','cp_data','mucous_membrane']","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.699446Z","iopub.execute_input":"2023-10-02T16:49:32.700131Z","iopub.status.idle":"2023-10-02T16:49:32.711264Z","shell.execute_reply.started":"2023-10-02T16:49:32.700089Z","shell.execute_reply":"2023-10-02T16:49:32.709710Z"},"trusted":true},"execution_count":707,"outputs":[]},{"cell_type":"code","source":"total_ohe = pd.get_dummies(total, columns=encfeats)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.715442Z","iopub.execute_input":"2023-10-02T16:49:32.715866Z","iopub.status.idle":"2023-10-02T16:49:32.733356Z","shell.execute_reply.started":"2023-10-02T16:49:32.715771Z","shell.execute_reply":"2023-10-02T16:49:32.732481Z"},"trusted":true},"execution_count":708,"outputs":[]},{"cell_type":"code","source":"total_ohe.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.737289Z","iopub.execute_input":"2023-10-02T16:49:32.738337Z","iopub.status.idle":"2023-10-02T16:49:32.748689Z","shell.execute_reply.started":"2023-10-02T16:49:32.738282Z","shell.execute_reply":"2023-10-02T16:49:32.747434Z"},"trusted":true},"execution_count":709,"outputs":[{"execution_count":709,"output_type":"execute_result","data":{"text/plain":"Index(['rectal_temp', 'pulse', 'respiratory_rate', 'temp_of_extremities',\n       'peripheral_pulse', 'capillary_refill_time', 'pain', 'peristalsis',\n       'nasogastric_tube', 'nasogastric_reflux', 'nasogastric_reflux_ph',\n       'rectal_exam_feces', 'abdomen', 'packed_cell_volume', 'total_protein',\n       'abdomo_protein', 'outcome', 'frequency', 'site', 'type', 'subtype',\n       'specific_code', 'shock_probability', 'encoded_combination',\n       'surgery_0', 'surgery_1', 'age_0', 'age_1', 'surgical_lesion_0',\n       'surgical_lesion_1', 'cp_data_0', 'cp_data_1',\n       'mucous_membrane_bright_pink', 'mucous_membrane_bright_red',\n       'mucous_membrane_dark_cyanotic', 'mucous_membrane_normal_pink',\n       'mucous_membrane_pale_cyanotic', 'mucous_membrane_pale_pink'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"total_ohe.drop(['cp_data_0', 'age_0', 'surgical_lesion_0','surgery_0', 'subtype','mucous_membrane_bright_pink'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.752422Z","iopub.execute_input":"2023-10-02T16:49:32.752740Z","iopub.status.idle":"2023-10-02T16:49:32.763683Z","shell.execute_reply.started":"2023-10-02T16:49:32.752713Z","shell.execute_reply":"2023-10-02T16:49:32.762593Z"},"trusted":true},"execution_count":710,"outputs":[]},{"cell_type":"code","source":"total_ohe.drop(['respiratory_rate' , 'abdomo_protein'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.767423Z","iopub.execute_input":"2023-10-02T16:49:32.767725Z","iopub.status.idle":"2023-10-02T16:49:32.778141Z","shell.execute_reply.started":"2023-10-02T16:49:32.767700Z","shell.execute_reply":"2023-10-02T16:49:32.777251Z"},"trusted":true},"execution_count":711,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.782029Z","iopub.execute_input":"2023-10-02T16:49:32.783081Z","iopub.status.idle":"2023-10-02T16:49:32.795541Z","shell.execute_reply.started":"2023-10-02T16:49:32.783039Z","shell.execute_reply":"2023-10-02T16:49:32.794418Z"},"trusted":true},"execution_count":712,"outputs":[{"execution_count":712,"output_type":"execute_result","data":{"text/plain":"surgery                    0\nage                        0\nrectal_temp                0\npulse                      0\nrespiratory_rate           0\ntemp_of_extremities        0\nperipheral_pulse           0\nmucous_membrane            0\ncapillary_refill_time      0\npain                       0\nperistalsis                0\nnasogastric_tube           0\nnasogastric_reflux         0\nnasogastric_reflux_ph      0\nrectal_exam_feces          0\nabdomen                    0\npacked_cell_volume         0\ntotal_protein              0\nabdomo_protein             0\nsurgical_lesion            0\ncp_data                    0\noutcome                  824\nfrequency                  0\nsite                       0\ntype                       0\nsubtype                    0\nspecific_code              0\nshock_probability          0\nencoded_combination        0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train_l = total_ohe[total_ohe[target].notnull()]\ntest_l = total_ohe[total_ohe[target].isnull()].drop(columns=[target])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.797261Z","iopub.execute_input":"2023-10-02T16:49:32.797663Z","iopub.status.idle":"2023-10-02T16:49:32.819797Z","shell.execute_reply.started":"2023-10-02T16:49:32.797624Z","shell.execute_reply":"2023-10-02T16:49:32.818708Z"},"trusted":true},"execution_count":713,"outputs":[]},{"cell_type":"code","source":"\nX_train = train_l.drop(columns=['outcome'])\ny_train = train_l['outcome']  ","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.821682Z","iopub.execute_input":"2023-10-02T16:49:32.822445Z","iopub.status.idle":"2023-10-02T16:49:32.830477Z","shell.execute_reply.started":"2023-10-02T16:49:32.822394Z","shell.execute_reply":"2023-10-02T16:49:32.829293Z"},"trusted":true},"execution_count":714,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(test_l)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.832514Z","iopub.execute_input":"2023-10-02T16:49:32.833414Z","iopub.status.idle":"2023-10-02T16:49:32.862309Z","shell.execute_reply.started":"2023-10-02T16:49:32.833370Z","shell.execute_reply":"2023-10-02T16:49:32.860100Z"},"trusted":true},"execution_count":715,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Fit PCA to your data\n# pca = PCA()\n# pca.fit(X_train_scaled)\n\n# # Plot explained variance\n# explained_variance_ratio = pca.explained_variance_ratio_\n# cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n# target_variance = 0.99999999999999\n\n# # Find the number of components to retain\n# num_components = np.argmax(cumulative_explained_variance >= target_variance) + 1  # Adding 1 to convert to number of components\n\n# print(\"Number of components to retain:\", num_components)\n# # Get the indices of the components sorted by their explained variance\n# component_indices = np.argsort(pca.explained_variance_ratio_)[::-1]\n\n# # Get the component names for the selected components in the correct order\n# selected_component_names = [X_train.columns[i] for i in component_indices[:num_components]]\n\n\n# # Print the component names\n# print(\"Selected Component Names:\")\n# for component_name in selected_component_names:\n#     print(component_name)\n\n# # Plot explained variance\n# plt.figure(figsize=(8, 6))\n# plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', linestyle='--')\n# plt.xlabel('Number of Components')\n# plt.ylabel('Cumulative Explained Variance')\n# plt.title('Explained Variance vs. Number of Components')\n# plt.grid(True)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.865714Z","iopub.execute_input":"2023-10-02T16:49:32.866725Z","iopub.status.idle":"2023-10-02T16:49:32.873732Z","shell.execute_reply.started":"2023-10-02T16:49:32.866675Z","shell.execute_reply":"2023-10-02T16:49:32.872657Z"},"trusted":true},"execution_count":716,"outputs":[]},{"cell_type":"markdown","source":"****i left the code for PCA and Random Forest Classifier for feature selection ( use it if you see fit it fits your preprocessing needs ) ****","metadata":{}},{"cell_type":"code","source":"# X_train_pca_selected = X_train_scaled[selected_component_names]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.875303Z","iopub.execute_input":"2023-10-02T16:49:32.876084Z","iopub.status.idle":"2023-10-02T16:49:32.888038Z","shell.execute_reply.started":"2023-10-02T16:49:32.876031Z","shell.execute_reply":"2023-10-02T16:49:32.887038Z"},"trusted":true},"execution_count":717,"outputs":[]},{"cell_type":"code","source":"\n# X_test_pca_selected = X_test_scaled[selected_component_names]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.889387Z","iopub.execute_input":"2023-10-02T16:49:32.889952Z","iopub.status.idle":"2023-10-02T16:49:32.903924Z","shell.execute_reply.started":"2023-10-02T16:49:32.889921Z","shell.execute_reply":"2023-10-02T16:49:32.902657Z"},"trusted":true},"execution_count":718,"outputs":[]},{"cell_type":"code","source":"\n# rf_classifier = RandomForestClassifier(random_state=42)\n\n\n# rf_classifier.fit(X_train_scaled, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.905728Z","iopub.execute_input":"2023-10-02T16:49:32.906595Z","iopub.status.idle":"2023-10-02T16:49:32.921943Z","shell.execute_reply.started":"2023-10-02T16:49:32.906553Z","shell.execute_reply":"2023-10-02T16:49:32.920514Z"},"trusted":true},"execution_count":719,"outputs":[]},{"cell_type":"code","source":"\n# feature_importances = rf_classifier.feature_importances_\n\n\n\n\n# sorted_indices = (-feature_importances).argsort()\n\n\n# top_n = 62  # Adjust as needed\n# top_feature_names = [selected_component_names[i] for i in sorted_indices[:top_n]]\n# top_feature_importances = feature_importances[sorted_indices[:top_n]]\n\n\n# plt.figure(figsize=(10, 6))\n# plt.barh(range(top_n), top_feature_importances, align='center')\n# plt.yticks(range(top_n), top_feature_names)\n# plt.xlabel('Feature Importance')\n# plt.title('Top {} Feature Importances'.format(top_n))\n# plt.gca().invert_yaxis()  # Invert y-axis to display the most important feature at the top\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.924233Z","iopub.execute_input":"2023-10-02T16:49:32.925774Z","iopub.status.idle":"2023-10-02T16:49:32.939401Z","shell.execute_reply.started":"2023-10-02T16:49:32.925723Z","shell.execute_reply":"2023-10-02T16:49:32.938246Z"},"trusted":true},"execution_count":720,"outputs":[]},{"cell_type":"code","source":"# X_train_lst = X_train_pca_selected.iloc[: , sorted_indices[:top_n]]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.941048Z","iopub.execute_input":"2023-10-02T16:49:32.941887Z","iopub.status.idle":"2023-10-02T16:49:32.963108Z","shell.execute_reply.started":"2023-10-02T16:49:32.941828Z","shell.execute_reply":"2023-10-02T16:49:32.962028Z"},"trusted":true},"execution_count":721,"outputs":[]},{"cell_type":"code","source":"# X_test_lst = X_test_pca_selected.iloc[: , sorted_indices[:top_n]]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.973071Z","iopub.execute_input":"2023-10-02T16:49:32.973819Z","iopub.status.idle":"2023-10-02T16:49:32.979687Z","shell.execute_reply.started":"2023-10-02T16:49:32.973777Z","shell.execute_reply":"2023-10-02T16:49:32.978260Z"},"trusted":true},"execution_count":722,"outputs":[]},{"cell_type":"code","source":"# X_test_last = X_test_pca_selected.iloc[: , sorted_indices[:top_n]]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:32.981538Z","iopub.execute_input":"2023-10-02T16:49:32.982333Z","iopub.status.idle":"2023-10-02T16:49:32.998427Z","shell.execute_reply.started":"2023-10-02T16:49:32.982281Z","shell.execute_reply":"2023-10-02T16:49:32.996842Z"},"trusted":true},"execution_count":723,"outputs":[]},{"cell_type":"code","source":"X = X_train_scaled\ny = y_train.astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:33.000390Z","iopub.execute_input":"2023-10-02T16:49:33.001332Z","iopub.status.idle":"2023-10-02T16:49:33.015096Z","shell.execute_reply.started":"2023-10-02T16:49:33.001280Z","shell.execute_reply":"2023-10-02T16:49:33.013822Z"},"trusted":true},"execution_count":724,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:33.017046Z","iopub.execute_input":"2023-10-02T16:49:33.017978Z","iopub.status.idle":"2023-10-02T16:49:33.035488Z","shell.execute_reply.started":"2023-10-02T16:49:33.017932Z","shell.execute_reply":"2023-10-02T16:49:33.033742Z"},"trusted":true},"execution_count":725,"outputs":[{"execution_count":725,"output_type":"execute_result","data":{"text/plain":"(1534, 29)"},"metadata":{}}]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:33.037278Z","iopub.execute_input":"2023-10-02T16:49:33.038623Z","iopub.status.idle":"2023-10-02T16:49:33.050177Z","shell.execute_reply.started":"2023-10-02T16:49:33.038573Z","shell.execute_reply":"2023-10-02T16:49:33.048390Z"},"trusted":true},"execution_count":726,"outputs":[{"execution_count":726,"output_type":"execute_result","data":{"text/plain":"(1534,)"},"metadata":{}}]},{"cell_type":"code","source":"y.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:33.052360Z","iopub.execute_input":"2023-10-02T16:49:33.053084Z","iopub.status.idle":"2023-10-02T16:49:33.070905Z","shell.execute_reply.started":"2023-10-02T16:49:33.053040Z","shell.execute_reply":"2023-10-02T16:49:33.069190Z"},"trusted":true},"execution_count":727,"outputs":[{"execution_count":727,"output_type":"execute_result","data":{"text/plain":"outcome\n2    752\n1    487\n0    295\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# model creation","metadata":{}},{"cell_type":"markdown","source":"# decision tree","metadata":{}},{"cell_type":"code","source":"\n# from sklearn.model_selection import train_test_split\n# from sklearn.tree import DecisionTreeClassifier\n# from sklearn.metrics import accuracy_score\n# from sklearn.model_selection import GridSearchCV\n\n\n\n# # Split the dataset into training and testing sets\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# # Create a decision tree classifier\n# clf = DecisionTreeClassifier()\n\n# # Define a grid of hyperparameters to search over\n# param_grid = {\n#     'criterion': ['gini', 'entropy'],\n#     'max_depth': [None, 10, 20, 30],  # You can adjust the depth values\n#     'min_samples_split': [2, 5, 10],\n#     'min_samples_leaf': [1, 2, 4],\n#     'max_features': ['sqrt', 'log2', None],  # You can adjust this based on the number of features\n#     'random_state': [42]\n# }\n\n# # Perform grid search with cross-validation to find the best hyperparameters\n# grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')\n# grid_search.fit(X_train, y_train)\n\n# # Get the best hyperparameters from the grid search\n# best_params = grid_search.best_params_\n# print(\"Best Hyperparameters:\", best_params)\n\n# # Create a decision tree classifier with the best hyperparameters\n# best_clf = DecisionTreeClassifier(**best_params)\n\n# # Fit the classifier to the training data\n# best_clf.fit(X_train, y_train)\n\n# # Make predictions on the test data\n# y_pred = best_clf.predict(X_test)\n\n# # Calculate the accuracy of the model\n# accuracy = accuracy_score(y_test, y_pred)\n# print(f\"Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:33.073120Z","iopub.execute_input":"2023-10-02T16:49:33.073925Z","iopub.status.idle":"2023-10-02T16:49:33.083466Z","shell.execute_reply.started":"2023-10-02T16:49:33.073882Z","shell.execute_reply":"2023-10-02T16:49:33.082267Z"},"trusted":true},"execution_count":728,"outputs":[]},{"cell_type":"markdown","source":"# light GBM with grid search","metadata":{}},{"cell_type":"code","source":"\n\n# # Split the dataset into training and testing sets\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# # Create a LightGBM dataset\n# train_data = lgb.Dataset(X_train, label=y_train)\n\n# # Define hyperparameters for tuning\n# param_grid = {\n#     'objective': ['multiclass'],\n#     'num_class': [3],\n#     'boosting_type': ['gbdt'],\n#     'metric': ['multi_logloss'],\n#     'num_leaves': [31, 50, 100],   \n#     'max_depth': [-1],             \n#     'learning_rate': [0.05, 0.1],  \n#     'feature_fraction': [1.0],     \n#     'bagging_fraction': [0.8],    \n#     'bagging_freq': [5],\n#     'verbose': [-1],\n#     'seed': [42],\n# }\n\n\n# clf = lgb.LGBMClassifier()\n\n# # Perform grid search with cross-validation to find the best hyperparameters\n# grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')\n# grid_search.fit(X_train, y_train)\n\n# # Get the best hyperparameters from the grid search\n# best_params = grid_search.best_params_\n# print(\"Best Hyperparameters:\", best_params)\n\n# # Create a LightGBM classifier with the best hyperparameters\n# best_clf = lgb.LGBMClassifier(**best_params)\n\n# # Train the classifier on the training data\n# best_clf.fit(X_train, y_train)\n\n# # Make predictions on the test data\n# y_pred = best_clf.predict(X_test)\n\n# # Calculate accuracy and ROC AUC\n# accuracy = accuracy_score(y_test, y_pred)\n# y_prob = best_clf.predict_proba(X_test)\n# roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n\n# print(f\"Accuracy: {accuracy}\")\n# print(f\"ROC AUC: {roc_auc}\")\n\n# # Plot the learning curve\n# def plot_learning_curve(estimator, X, y):\n#     train_sizes, train_scores, valid_scores = learning_curve(\n#         estimator, X, y, train_sizes=np.linspace(0.1, 1.0, 10), cv=5, scoring='accuracy'\n#     )\n\n#     train_mean = np.mean(train_scores, axis=1)\n#     train_std = np.std(train_scores, axis=1)\n#     valid_mean = np.mean(valid_scores, axis=1)\n#     valid_std = np.std(valid_scores, axis=1)\n\n#     plt.figure(figsize=(10, 6))\n#     plt.plot(train_sizes, train_mean, marker='o', label='Training Accuracy', color='b')\n#     plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='b')\n#     plt.plot(train_sizes, valid_mean, marker='o', label='Validation Accuracy', color='g')\n#     plt.fill_between(train_sizes, valid_mean - valid_std, valid_mean + valid_std, alpha=0.15, color='g')\n\n#     plt.title('Learning Curve')\n#     plt.xlabel('Training Examples')\n#     plt.ylabel('Accuracy')\n#     plt.legend(loc='best')\n#     plt.grid()\n#     plt.show()\n\n# # Plot the learning curve for the best LightGBM classifier\n# plot_learning_curve(best_clf, X_train, y_train)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-10-02T16:49:33.085565Z","iopub.execute_input":"2023-10-02T16:49:33.086010Z","iopub.status.idle":"2023-10-02T16:49:33.106944Z","shell.execute_reply.started":"2023-10-02T16:49:33.085973Z","shell.execute_reply":"2023-10-02T16:49:33.105728Z"},"trusted":true},"execution_count":729,"outputs":[]},{"cell_type":"markdown","source":"# light GBM with optuna","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, StratifiedKFold\n\ndef plot_learning_curve(estimator, X, y):\n    train_sizes, train_scores, valid_scores = learning_curve(\n        estimator, X, y, train_sizes=np.linspace(0.1, 1.0, 10), cv=5, scoring='accuracy'\n    )\n\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    valid_mean = np.mean(valid_scores, axis=1)\n    valid_std = np.std(valid_scores, axis=1)\n\n    plt.figure(figsize=(10, 6))\n    plt.plot(train_sizes, train_mean, marker='o', label='Training Accuracy', color='b')\n    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='b')\n    plt.plot(train_sizes, valid_mean, marker='o', label='Validation Accuracy', color='g')\n    plt.fill_between(train_sizes, valid_mean - valid_std, valid_mean + valid_std, alpha=0.15, color='g')\n\n    plt.title('Learning Curve')\n    plt.xlabel('Training Examples')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='best')\n    plt.grid()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:33.108445Z","iopub.execute_input":"2023-10-02T16:49:33.109293Z","iopub.status.idle":"2023-10-02T16:49:33.129997Z","shell.execute_reply.started":"2023-10-02T16:49:33.109249Z","shell.execute_reply":"2023-10-02T16:49:33.128927Z"},"trusted":true},"execution_count":730,"outputs":[]},{"cell_type":"code","source":"\n\n    # Split the data into training and testing sets\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    k_best = SelectKBest(score_func=f_classif, k='all')\n    X_train_best = k_best.fit_transform(X_train, y_train)\n    X_test_best = k_best.transform(X_test)\n    tt = k_best.transform(X_test_scaled)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:33.131365Z","iopub.execute_input":"2023-10-02T16:49:33.132541Z","iopub.status.idle":"2023-10-02T16:49:33.156125Z","shell.execute_reply.started":"2023-10-02T16:49:33.132497Z","shell.execute_reply":"2023-10-02T16:49:33.153963Z"},"trusted":true},"execution_count":731,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        'objective': 'multiclass',\n        'num_class': 3,\n        'min_child_samples': trial.suggest_int('min_child_samples', 2, 50),\n        'boosting_type': 'gbdt',\n        'metric': 'multi_logloss',\n        'num_leaves': trial.suggest_int('num_leaves', 31, 100),\n        'max_depth': -1,\n        'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.1),\n        'feature_fraction': 1.0,\n        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n        'bagging_freq': 5,\n        'verbose': -1,\n        'seed': 42,\n    }\n\n    # Create a LightGBM classifier with the trial parameters\n    clf = lgb.LGBMClassifier(**params)\n\n    # Use 5-fold cross-validation to evaluate the model\n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    scores = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n\n    # Calculate the mean accuracy from cross-validation\n    accuracy = np.mean(scores)\n\n    return accuracy\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T16:49:33.157883Z","iopub.execute_input":"2023-10-02T16:49:33.159346Z","iopub.status.idle":"2023-10-02T16:49:33.170479Z","shell.execute_reply.started":"2023-10-02T16:49:33.159056Z","shell.execute_reply":"2023-10-02T16:49:33.169208Z"},"trusted":true},"execution_count":732,"outputs":[]},{"cell_type":"code","source":"# Optuna study and optimize the objective function\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=100)  # You can adjust the number of trials\n\n#the best hyperparameters\nbest_params = study.best_params\nbest_accuracy = study.best_value\nprint(\"Best Hyperparameters:\", best_params)\nprint(\"Best Accuracy:\", best_accuracy)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-10-02T16:49:33.172462Z","iopub.execute_input":"2023-10-02T16:49:33.174117Z","iopub.status.idle":"2023-10-02T17:12:18.579700Z","shell.execute_reply.started":"2023-10-02T16:49:33.173811Z","shell.execute_reply":"2023-10-02T17:12:18.578480Z"},"trusted":true},"execution_count":733,"outputs":[{"name":"stderr","text":"[I 2023-10-02 16:49:33,181] A new study created in memory with name: no-name-b364add0-3c55-4416-ac1d-dfcddd6c3eb7\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6668627705945596, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6668627705945596\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6668627705945596, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6668627705945596\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6668627705945596, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6668627705945596\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6668627705945596, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6668627705945596\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6668627705945596, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6668627705945596\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:49:46,098] Trial 0 finished with value: 0.7392518788188457 and parameters: {'num_leaves': 42, 'learning_rate': 0.05825553947172259, 'bagging_fraction': 0.6668627705945596}. Best is trial 0 with value: 0.7392518788188457.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8522564823990855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522564823990855\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8522564823990855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522564823990855\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8522564823990855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522564823990855\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8522564823990855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522564823990855\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8522564823990855, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8522564823990855\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:50:02,674] Trial 1 finished with value: 0.735988162909029 and parameters: {'num_leaves': 45, 'learning_rate': 0.09596717749619148, 'bagging_fraction': 0.8522564823990855}. Best is trial 0 with value: 0.7392518788188457.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8833128793371108, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8833128793371108\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8833128793371108, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8833128793371108\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8833128793371108, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8833128793371108\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8833128793371108, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8833128793371108\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8833128793371108, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8833128793371108\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:50:19,725] Trial 2 finished with value: 0.7457686657724979 and parameters: {'num_leaves': 69, 'learning_rate': 0.0791179320546321, 'bagging_fraction': 0.8833128793371108}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.5447828667315902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5447828667315902\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.5447828667315902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5447828667315902\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.5447828667315902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5447828667315902\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.5447828667315902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5447828667315902\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.5447828667315902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5447828667315902\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:50:30,047] Trial 3 finished with value: 0.7353303101913947 and parameters: {'num_leaves': 47, 'learning_rate': 0.0955830622772211, 'bagging_fraction': 0.5447828667315902}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9591606127160326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9591606127160326\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9591606127160326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9591606127160326\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9591606127160326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9591606127160326\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9591606127160326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9591606127160326\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9591606127160326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9591606127160326\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:50:49,686] Trial 4 finished with value: 0.7411977603201976 and parameters: {'num_leaves': 57, 'learning_rate': 0.09214248927229583, 'bagging_fraction': 0.9591606127160326}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8747209990542739, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8747209990542739\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8747209990542739, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8747209990542739\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8747209990542739, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8747209990542739\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8747209990542739, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8747209990542739\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8747209990542739, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8747209990542739\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:51:05,965] Trial 5 finished with value: 0.7340316365416959 and parameters: {'num_leaves': 44, 'learning_rate': 0.08977776782915485, 'bagging_fraction': 0.8747209990542739}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8399407522153401, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8399407522153401\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8399407522153401, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8399407522153401\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8399407522153401, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8399407522153401\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8399407522153401, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8399407522153401\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8399407522153401, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8399407522153401\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:51:21,252] Trial 6 finished with value: 0.740556939388133 and parameters: {'num_leaves': 71, 'learning_rate': 0.09118927310636872, 'bagging_fraction': 0.8399407522153401}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6606242965462414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6606242965462414\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6606242965462414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6606242965462414\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6606242965462414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6606242965462414\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6606242965462414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6606242965462414\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6606242965462414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6606242965462414\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:51:33,447] Trial 7 finished with value: 0.7294671180089842 and parameters: {'num_leaves': 67, 'learning_rate': 0.08556836782039984, 'bagging_fraction': 0.6606242965462414}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7327382169002945, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7327382169002945\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7327382169002945, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7327382169002945\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7327382169002945, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7327382169002945\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7327382169002945, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7327382169002945\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7327382169002945, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7327382169002945\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:51:47,925] Trial 8 finished with value: 0.7320751101743629 and parameters: {'num_leaves': 53, 'learning_rate': 0.0923873342007509, 'bagging_fraction': 0.7327382169002945}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6363465703730773, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6363465703730773\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6363465703730773, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6363465703730773\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6363465703730773, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6363465703730773\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6363465703730773, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6363465703730773\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6363465703730773, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6363465703730773\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:52:00,063] Trial 9 finished with value: 0.7346894892593302 and parameters: {'num_leaves': 69, 'learning_rate': 0.09690541210387082, 'bagging_fraction': 0.6363465703730773}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9989354123373165, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9989354123373165\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9989354123373165, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9989354123373165\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9989354123373165, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9989354123373165\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9989354123373165, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9989354123373165\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9989354123373165, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9989354123373165\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:52:19,247] Trial 10 finished with value: 0.7405399076025633 and parameters: {'num_leaves': 92, 'learning_rate': 0.07650466032308881, 'bagging_fraction': 0.9989354123373165}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9938478827673962, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9938478827673962\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9938478827673962, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9938478827673962\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9938478827673962, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9938478827673962\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9938478827673962, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9938478827673962\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9938478827673962, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9938478827673962\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:52:37,804] Trial 11 finished with value: 0.7353303101913947 and parameters: {'num_leaves': 83, 'learning_rate': 0.07873271488694507, 'bagging_fraction': 0.9938478827673962}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9398110531097317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398110531097317\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9398110531097317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398110531097317\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9398110531097317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398110531097317\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9398110531097317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398110531097317\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9398110531097317, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9398110531097317\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:52:56,384] Trial 12 finished with value: 0.7340444103808733 and parameters: {'num_leaves': 57, 'learning_rate': 0.06950827262163636, 'bagging_fraction': 0.9398110531097317}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9070008073432835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9070008073432835\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9070008073432835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9070008073432835\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9070008073432835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9070008073432835\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9070008073432835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9070008073432835\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9070008073432835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9070008073432835\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:53:09,353] Trial 13 finished with value: 0.737299610397905 and parameters: {'num_leaves': 31, 'learning_rate': 0.08327684478501647, 'bagging_fraction': 0.9070008073432835}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.804689898360802, subsample=1.0 will be ignored. Current value: bagging_fraction=0.804689898360802\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.804689898360802, subsample=1.0 will be ignored. Current value: bagging_fraction=0.804689898360802\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.804689898360802, subsample=1.0 will be ignored. Current value: bagging_fraction=0.804689898360802\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.804689898360802, subsample=1.0 will be ignored. Current value: bagging_fraction=0.804689898360802\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.804689898360802, subsample=1.0 will be ignored. Current value: bagging_fraction=0.804689898360802\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:53:25,251] Trial 14 finished with value: 0.7372953524515127 and parameters: {'num_leaves': 80, 'learning_rate': 0.07089927861013876, 'bagging_fraction': 0.804689898360802}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.936559028879633, subsample=1.0 will be ignored. Current value: bagging_fraction=0.936559028879633\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.936559028879633, subsample=1.0 will be ignored. Current value: bagging_fraction=0.936559028879633\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.936559028879633, subsample=1.0 will be ignored. Current value: bagging_fraction=0.936559028879633\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.936559028879633, subsample=1.0 will be ignored. Current value: bagging_fraction=0.936559028879633\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.936559028879633, subsample=1.0 will be ignored. Current value: bagging_fraction=0.936559028879633\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:53:47,090] Trial 15 finished with value: 0.7392348470332759 and parameters: {'num_leaves': 61, 'learning_rate': 0.0994812706634646, 'bagging_fraction': 0.936559028879633}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7927585127250145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7927585127250145\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7927585127250145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7927585127250145\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7927585127250145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7927585127250145\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7927585127250145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7927585127250145\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7927585127250145, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7927585127250145\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:54:04,231] Trial 16 finished with value: 0.741857742011028 and parameters: {'num_leaves': 78, 'learning_rate': 0.08339559069375281, 'bagging_fraction': 0.7927585127250145}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8052647818880092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8052647818880092\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8052647818880092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8052647818880092\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8052647818880092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8052647818880092\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8052647818880092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8052647818880092\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8052647818880092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8052647818880092\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:54:20,866] Trial 17 finished with value: 0.7412126631325712 and parameters: {'num_leaves': 98, 'learning_rate': 0.08267022124233686, 'bagging_fraction': 0.8052647818880092}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7601133517255524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7601133517255524\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7601133517255524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7601133517255524\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7601133517255524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7601133517255524\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7601133517255524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7601133517255524\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7601133517255524, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7601133517255524\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:54:36,113] Trial 18 finished with value: 0.7320836260671478 and parameters: {'num_leaves': 78, 'learning_rate': 0.07184221299622946, 'bagging_fraction': 0.7601133517255524}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8980132244489066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8980132244489066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8980132244489066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8980132244489066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8980132244489066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8980132244489066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8980132244489066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8980132244489066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8980132244489066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8980132244489066\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:54:56,629] Trial 19 finished with value: 0.7366268548678973 and parameters: {'num_leaves': 88, 'learning_rate': 0.06493561209581883, 'bagging_fraction': 0.8980132244489066}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8222801879832398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8222801879832398\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8222801879832398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8222801879832398\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8222801879832398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8222801879832398\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8222801879832398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8222801879832398\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8222801879832398, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8222801879832398\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:55:11,759] Trial 20 finished with value: 0.7386025419939963 and parameters: {'num_leaves': 75, 'learning_rate': 0.07930802587871164, 'bagging_fraction': 0.8222801879832398}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7828704245036112, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7828704245036112\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7828704245036112, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7828704245036112\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7828704245036112, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7828704245036112\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7828704245036112, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7828704245036112\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7828704245036112, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7828704245036112\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:55:24,777] Trial 21 finished with value: 0.7438100104319687 and parameters: {'num_leaves': 100, 'learning_rate': 0.08372543239677038, 'bagging_fraction': 0.7828704245036112}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7672279938270066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7672279938270066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7672279938270066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7672279938270066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7672279938270066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7672279938270066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7672279938270066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7672279938270066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7672279938270066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7672279938270066\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:55:38,308] Trial 22 finished with value: 0.7385918971280152 and parameters: {'num_leaves': 100, 'learning_rate': 0.08524710822963895, 'bagging_fraction': 0.7672279938270066}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8705065753834201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8705065753834201\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8705065753834201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8705065753834201\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8705065753834201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8705065753834201\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8705065753834201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8705065753834201\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8705065753834201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8705065753834201\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:55:52,565] Trial 23 finished with value: 0.7392540077920419 and parameters: {'num_leaves': 90, 'learning_rate': 0.07588263378151078, 'bagging_fraction': 0.8705065753834201}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7232846919324113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7232846919324113\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7232846919324113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7232846919324113\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7232846919324113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7232846919324113\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7232846919324113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7232846919324113\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7232846919324113, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7232846919324113\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:56:04,363] Trial 24 finished with value: 0.7327287049456047 and parameters: {'num_leaves': 83, 'learning_rate': 0.08165942805568586, 'bagging_fraction': 0.7232846919324113}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8013304951004449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8013304951004449\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8013304951004449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8013304951004449\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8013304951004449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8013304951004449\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8013304951004449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8013304951004449\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8013304951004449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8013304951004449\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:56:17,597] Trial 25 finished with value: 0.7399033446168912 and parameters: {'num_leaves': 64, 'learning_rate': 0.08744830260462569, 'bagging_fraction': 0.8013304951004449}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8394903075997395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8394903075997395\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8394903075997395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8394903075997395\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8394903075997395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8394903075997395\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8394903075997395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8394903075997395\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8394903075997395, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8394903075997395\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:56:31,486] Trial 26 finished with value: 0.7333801707436504 and parameters: {'num_leaves': 74, 'learning_rate': 0.08013975389127231, 'bagging_fraction': 0.8394903075997395}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8924969395953963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8924969395953963\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8924969395953963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8924969395953963\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8924969395953963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8924969395953963\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8924969395953963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8924969395953963\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8924969395953963, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8924969395953963\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:56:45,610] Trial 27 finished with value: 0.7398926997509101 and parameters: {'num_leaves': 93, 'learning_rate': 0.08783045369534145, 'bagging_fraction': 0.8924969395953963}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7893916436795635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7893916436795635\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7893916436795635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7893916436795635\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7893916436795635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7893916436795635\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7893916436795635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7893916436795635\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7893916436795635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7893916436795635\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:56:58,624] Trial 28 finished with value: 0.7373059973174938 and parameters: {'num_leaves': 87, 'learning_rate': 0.07462022515671997, 'bagging_fraction': 0.7893916436795635}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7110609936809181, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7110609936809181\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7110609936809181, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7110609936809181\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7110609936809181, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7110609936809181\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7110609936809181, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7110609936809181\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7110609936809181, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7110609936809181\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:57:12,977] Trial 29 finished with value: 0.7412062762129825 and parameters: {'num_leaves': 96, 'learning_rate': 0.08397020047135854, 'bagging_fraction': 0.7110609936809181}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7774004244737733, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7774004244737733\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7774004244737733, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7774004244737733\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7774004244737733, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7774004244737733\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7774004244737733, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7774004244737733\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7774004244737733, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7774004244737733\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:57:26,288] Trial 30 finished with value: 0.7431734474462967 and parameters: {'num_leaves': 38, 'learning_rate': 0.08003141598987212, 'bagging_fraction': 0.7774004244737733}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7769316351960867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769316351960867\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7769316351960867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769316351960867\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7769316351960867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769316351960867\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7769316351960867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769316351960867\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7769316351960867, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769316351960867\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:57:38,989] Trial 31 finished with value: 0.7340295075684997 and parameters: {'num_leaves': 37, 'learning_rate': 0.08009177185876312, 'bagging_fraction': 0.7769316351960867}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8305077100202601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8305077100202601\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8305077100202601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8305077100202601\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8305077100202601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8305077100202601\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8305077100202601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8305077100202601\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8305077100202601, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8305077100202601\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:57:52,317] Trial 32 finished with value: 0.7307785654978604 and parameters: {'num_leaves': 50, 'learning_rate': 0.08561006172340396, 'bagging_fraction': 0.8305077100202601}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8590381388467372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8590381388467372\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8590381388467372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8590381388467372\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8590381388467372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8590381388467372\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8590381388467372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8590381388467372\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8590381388467372, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8590381388467372\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:58:04,197] Trial 33 finished with value: 0.7366374997338784 and parameters: {'num_leaves': 37, 'learning_rate': 0.054722643372611846, 'bagging_fraction': 0.8590381388467372}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7675398162937678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7675398162937678\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7675398162937678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7675398162937678\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7675398162937678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7675398162937678\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7675398162937678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7675398162937678\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7675398162937678, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7675398162937678\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:58:17,543] Trial 34 finished with value: 0.7346916182325265 and parameters: {'num_leaves': 62, 'learning_rate': 0.07784668649710633, 'bagging_fraction': 0.7675398162937678}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8204258398423625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8204258398423625\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8204258398423625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8204258398423625\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8204258398423625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8204258398423625\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8204258398423625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8204258398423625\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8204258398423625, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8204258398423625\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:58:30,380] Trial 35 finished with value: 0.741857742011028 and parameters: {'num_leaves': 57, 'learning_rate': 0.08171537714467444, 'bagging_fraction': 0.8204258398423625}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.743121098206007, subsample=1.0 will be ignored. Current value: bagging_fraction=0.743121098206007\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.743121098206007, subsample=1.0 will be ignored. Current value: bagging_fraction=0.743121098206007\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.743121098206007, subsample=1.0 will be ignored. Current value: bagging_fraction=0.743121098206007\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.743121098206007, subsample=1.0 will be ignored. Current value: bagging_fraction=0.743121098206007\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.743121098206007, subsample=1.0 will be ignored. Current value: bagging_fraction=0.743121098206007\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:58:44,086] Trial 36 finished with value: 0.7379425603031657 and parameters: {'num_leaves': 72, 'learning_rate': 0.0899493460061497, 'bagging_fraction': 0.743121098206007}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8455072649078091, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455072649078091\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8455072649078091, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455072649078091\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8455072649078091, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455072649078091\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8455072649078091, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455072649078091\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8455072649078091, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455072649078091\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:58:58,606] Trial 37 finished with value: 0.7340358944880884 and parameters: {'num_leaves': 67, 'learning_rate': 0.07419450714985647, 'bagging_fraction': 0.8455072649078091}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6999125786334969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6999125786334969\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6999125786334969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6999125786334969\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6999125786334969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6999125786334969\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6999125786334969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6999125786334969\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6999125786334969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6999125786334969\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:59:10,653] Trial 38 finished with value: 0.7398990866704989 and parameters: {'num_leaves': 49, 'learning_rate': 0.08756982286456873, 'bagging_fraction': 0.6999125786334969}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.74874783720814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.74874783720814\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.74874783720814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.74874783720814\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.74874783720814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.74874783720814\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.74874783720814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.74874783720814\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.74874783720814, subsample=1.0 will be ignored. Current value: bagging_fraction=0.74874783720814\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:59:22,878] Trial 39 finished with value: 0.7346809733665454 and parameters: {'num_leaves': 40, 'learning_rate': 0.07761813113238412, 'bagging_fraction': 0.74874783720814}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8760004898847458, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8760004898847458\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8760004898847458, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8760004898847458\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8760004898847458, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8760004898847458\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8760004898847458, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8760004898847458\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8760004898847458, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8760004898847458\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:59:37,134] Trial 40 finished with value: 0.7385918971280152 and parameters: {'num_leaves': 79, 'learning_rate': 0.09398362643203323, 'bagging_fraction': 0.8760004898847458}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8217104481284102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8217104481284102\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8217104481284102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8217104481284102\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8217104481284102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8217104481284102\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8217104481284102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8217104481284102\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8217104481284102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8217104481284102\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 16:59:50,658] Trial 41 finished with value: 0.7399054735900875 and parameters: {'num_leaves': 57, 'learning_rate': 0.08042914335426447, 'bagging_fraction': 0.8217104481284102}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8033880012099659, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8033880012099659\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8033880012099659, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8033880012099659\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8033880012099659, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8033880012099659\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8033880012099659, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8033880012099659\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8033880012099659, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8033880012099659\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:00:03,532] Trial 42 finished with value: 0.734042281407677 and parameters: {'num_leaves': 54, 'learning_rate': 0.08232787785702653, 'bagging_fraction': 0.8033880012099659}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7823026925827394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7823026925827394\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7823026925827394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7823026925827394\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7823026925827394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7823026925827394\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7823026925827394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7823026925827394\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7823026925827394, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7823026925827394\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:00:17,212] Trial 43 finished with value: 0.7346831023397415 and parameters: {'num_leaves': 43, 'learning_rate': 0.08179762096742056, 'bagging_fraction': 0.7823026925827394}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8555159900785466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8555159900785466\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8555159900785466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8555159900785466\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8555159900785466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8555159900785466\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8555159900785466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8555159900785466\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8555159900785466, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8555159900785466\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:00:31,934] Trial 44 finished with value: 0.740556939388133 and parameters: {'num_leaves': 60, 'learning_rate': 0.0845546722299486, 'bagging_fraction': 0.8555159900785466}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8200406870787591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8200406870787591\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8200406870787591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8200406870787591\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8200406870787591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8200406870787591\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8200406870787591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8200406870787591\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8200406870787591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8200406870787591\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:00:42,862] Trial 45 finished with value: 0.7314257733495135 and parameters: {'num_leaves': 32, 'learning_rate': 0.07769551766154098, 'bagging_fraction': 0.8200406870787591}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.744461040683652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.744461040683652\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.744461040683652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.744461040683652\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.744461040683652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.744461040683652\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.744461040683652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.744461040683652\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.744461040683652, subsample=1.0 will be ignored. Current value: bagging_fraction=0.744461040683652\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:00:55,760] Trial 46 finished with value: 0.7366502735730557 and parameters: {'num_leaves': 69, 'learning_rate': 0.09042269838610408, 'bagging_fraction': 0.744461040683652}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7890899149280765, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7890899149280765\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7890899149280765, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7890899149280765\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7890899149280765, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7890899149280765\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7890899149280765, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7890899149280765\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7890899149280765, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7890899149280765\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:01:09,179] Trial 47 finished with value: 0.7385940261012114 and parameters: {'num_leaves': 85, 'learning_rate': 0.08648386577434725, 'bagging_fraction': 0.7890899149280765}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8451078310090891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8451078310090891\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8451078310090891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8451078310090891\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8451078310090891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8451078310090891\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8451078310090891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8451078310090891\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8451078310090891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8451078310090891\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:01:24,062] Trial 48 finished with value: 0.7346831023397415 and parameters: {'num_leaves': 53, 'learning_rate': 0.08377721035004515, 'bagging_fraction': 0.8451078310090891}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6755223647236748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6755223647236748\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6755223647236748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6755223647236748\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6755223647236748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6755223647236748\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6755223647236748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6755223647236748\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.6755223647236748, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6755223647236748\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:01:36,347] Trial 49 finished with value: 0.7359796470162441 and parameters: {'num_leaves': 46, 'learning_rate': 0.08887128013437194, 'bagging_fraction': 0.6755223647236748}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7607564946035613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7607564946035613\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7607564946035613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7607564946035613\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7607564946035613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7607564946035613\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7607564946035613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7607564946035613\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7607564946035613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7607564946035613\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:01:50,245] Trial 50 finished with value: 0.7320814970939515 and parameters: {'num_leaves': 76, 'learning_rate': 0.08096891387373942, 'bagging_fraction': 0.7607564946035613}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7982121136650094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7982121136650094\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7982121136650094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7982121136650094\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7982121136650094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7982121136650094\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7982121136650094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7982121136650094\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7982121136650094, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7982121136650094\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:02:03,889] Trial 51 finished with value: 0.7359902918822252 and parameters: {'num_leaves': 100, 'learning_rate': 0.08232774619954078, 'bagging_fraction': 0.7982121136650094}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7804667715334571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7804667715334571\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7804667715334571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7804667715334571\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7804667715334571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7804667715334571\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7804667715334571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7804667715334571\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7804667715334571, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7804667715334571\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:02:16,275] Trial 52 finished with value: 0.7281705733324817 and parameters: {'num_leaves': 96, 'learning_rate': 0.08367157105511042, 'bagging_fraction': 0.7804667715334571}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8685679159291919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8685679159291919\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8685679159291919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8685679159291919\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8685679159291919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8685679159291919\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8685679159291919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8685679159291919\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8685679159291919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8685679159291919\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:02:31,660] Trial 53 finished with value: 0.7346809733665454 and parameters: {'num_leaves': 96, 'learning_rate': 0.07656849771370304, 'bagging_fraction': 0.8685679159291919}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8148910182465553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148910182465553\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8148910182465553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148910182465553\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8148910182465553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148910182465553\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8148910182465553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148910182465553\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8148910182465553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148910182465553\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:02:44,674] Trial 54 finished with value: 0.7372847075855316 and parameters: {'num_leaves': 93, 'learning_rate': 0.07951870005414137, 'bagging_fraction': 0.8148910182465553}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8317053114995548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8317053114995548\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8317053114995548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8317053114995548\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8317053114995548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8317053114995548\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8317053114995548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8317053114995548\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8317053114995548, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8317053114995548\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:02:58,105] Trial 55 finished with value: 0.7333844286900428 and parameters: {'num_leaves': 98, 'learning_rate': 0.08572561182797916, 'bagging_fraction': 0.8317053114995548}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8076626144881647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8076626144881647\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8076626144881647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8076626144881647\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8076626144881647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8076626144881647\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8076626144881647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8076626144881647\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8076626144881647, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8076626144881647\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:03:10,425] Trial 56 finished with value: 0.7405505524685444 and parameters: {'num_leaves': 71, 'learning_rate': 0.07886716018422421, 'bagging_fraction': 0.8076626144881647}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7640941189582093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7640941189582093\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7640941189582093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7640941189582093\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7640941189582093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7640941189582093\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7640941189582093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7640941189582093\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7640941189582093, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7640941189582093\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:03:21,950] Trial 57 finished with value: 0.7392603947116305 and parameters: {'num_leaves': 64, 'learning_rate': 0.08304169530219198, 'bagging_fraction': 0.7640941189582093}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8877252293042072, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8877252293042072\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8877252293042072, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8877252293042072\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8877252293042072, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8877252293042072\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8877252293042072, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8877252293042072\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8877252293042072, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8877252293042072\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:03:36,492] Trial 58 finished with value: 0.7405441655489557 and parameters: {'num_leaves': 82, 'learning_rate': 0.08089335673619714, 'bagging_fraction': 0.8877252293042072}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7243603171511082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7243603171511082\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7243603171511082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7243603171511082\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7243603171511082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7243603171511082\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7243603171511082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7243603171511082\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7243603171511082, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7243603171511082\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:03:48,086] Trial 59 finished with value: 0.7353366971109834 and parameters: {'num_leaves': 90, 'learning_rate': 0.09149676473039375, 'bagging_fraction': 0.7243603171511082}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9185890851117363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9185890851117363\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9185890851117363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9185890851117363\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9185890851117363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9185890851117363\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9185890851117363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9185890851117363\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.9185890851117363, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9185890851117363\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:04:03,277] Trial 60 finished with value: 0.7340337655148922 and parameters: {'num_leaves': 59, 'learning_rate': 0.08861888477640395, 'bagging_fraction': 0.9185890851117363}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7923606848443044, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923606848443044\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7923606848443044, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923606848443044\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7923606848443044, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923606848443044\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7923606848443044, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923606848443044\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7923606848443044, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7923606848443044\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:04:16,404] Trial 61 finished with value: 0.7320836260671478 and parameters: {'num_leaves': 96, 'learning_rate': 0.08501649729928679, 'bagging_fraction': 0.7923606848443044}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7099988395600284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7099988395600284\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7099988395600284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7099988395600284\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7099988395600284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7099988395600284\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7099988395600284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7099988395600284\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7099988395600284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7099988395600284\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:04:27,610] Trial 62 finished with value: 0.7288113942645462 and parameters: {'num_leaves': 91, 'learning_rate': 0.08363619233315167, 'bagging_fraction': 0.7099988395600284}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8289603678624102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8289603678624102\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8289603678624102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8289603678624102\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8289603678624102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8289603678624102\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8289603678624102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8289603678624102\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8289603678624102, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8289603678624102\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:04:41,229] Trial 63 finished with value: 0.7255625811671031 and parameters: {'num_leaves': 94, 'learning_rate': 0.08706433308722034, 'bagging_fraction': 0.8289603678624102}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7355527725965062, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7355527725965062\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7355527725965062, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7355527725965062\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7355527725965062, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7355527725965062\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7355527725965062, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7355527725965062\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7355527725965062, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7355527725965062\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:04:52,611] Trial 64 finished with value: 0.7405462945221519 and parameters: {'num_leaves': 100, 'learning_rate': 0.08160508096110113, 'bagging_fraction': 0.7355527725965062}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7782547540756051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7782547540756051\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7782547540756051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7782547540756051\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7782547540756051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7782547540756051\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7782547540756051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7782547540756051\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7782547540756051, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7782547540756051\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:05:07,081] Trial 65 finished with value: 0.7451214579208447 and parameters: {'num_leaves': 86, 'learning_rate': 0.08483279948905276, 'bagging_fraction': 0.7782547540756051}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8095696651890437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8095696651890437\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8095696651890437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8095696651890437\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8095696651890437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8095696651890437\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8095696651890437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8095696651890437\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8095696651890437, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8095696651890437\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:05:19,991] Trial 66 finished with value: 0.7366502735730557 and parameters: {'num_leaves': 88, 'learning_rate': 0.08604946061595785, 'bagging_fraction': 0.8095696651890437}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7576387912840911, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7576387912840911\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7576387912840911, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7576387912840911\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7576387912840911, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7576387912840911\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7576387912840911, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7576387912840911\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7576387912840911, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7576387912840911\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:05:32,555] Trial 67 finished with value: 0.7346916182325265 and parameters: {'num_leaves': 76, 'learning_rate': 0.07839691109232287, 'bagging_fraction': 0.7576387912840911}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7713562692388927, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7713562692388927\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7713562692388927, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7713562692388927\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7713562692388927, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7713562692388927\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7713562692388927, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7713562692388927\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7713562692388927, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7713562692388927\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:05:45,495] Trial 68 finished with value: 0.7327393498115858 and parameters: {'num_leaves': 85, 'learning_rate': 0.07564137988270125, 'bagging_fraction': 0.7713562692388927}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8507456128412489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8507456128412489\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8507456128412489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8507456128412489\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8507456128412489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8507456128412489\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8507456128412489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8507456128412489\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8507456128412489, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8507456128412489\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:05:59,367] Trial 69 finished with value: 0.7353388260841796 and parameters: {'num_leaves': 82, 'learning_rate': 0.0825524674310504, 'bagging_fraction': 0.8507456128412489}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7806924173224369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7806924173224369\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7806924173224369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7806924173224369\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7806924173224369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7806924173224369\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7806924173224369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7806924173224369\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7806924173224369, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7806924173224369\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:06:12,545] Trial 70 finished with value: 0.7444678631496029 and parameters: {'num_leaves': 73, 'learning_rate': 0.0798996828453781, 'bagging_fraction': 0.7806924173224369}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.78329191813603, subsample=1.0 will be ignored. Current value: bagging_fraction=0.78329191813603\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.78329191813603, subsample=1.0 will be ignored. Current value: bagging_fraction=0.78329191813603\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.78329191813603, subsample=1.0 will be ignored. Current value: bagging_fraction=0.78329191813603\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.78329191813603, subsample=1.0 will be ignored. Current value: bagging_fraction=0.78329191813603\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.78329191813603, subsample=1.0 will be ignored. Current value: bagging_fraction=0.78329191813603\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:06:25,181] Trial 71 finished with value: 0.7268655127631943 and parameters: {'num_leaves': 69, 'learning_rate': 0.07923556552402343, 'bagging_fraction': 0.78329191813603}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7966412515497351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7966412515497351\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7966412515497351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7966412515497351\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7966412515497351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7966412515497351\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7966412515497351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7966412515497351\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7966412515497351, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7966412515497351\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:06:37,484] Trial 72 finished with value: 0.7307785654978604 and parameters: {'num_leaves': 73, 'learning_rate': 0.08043847700362092, 'bagging_fraction': 0.7966412515497351}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8339466987676594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8339466987676594\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8339466987676594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8339466987676594\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8339466987676594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8339466987676594\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8339466987676594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8339466987676594\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8339466987676594, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8339466987676594\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:06:50,784] Trial 73 finished with value: 0.7320751101743629 and parameters: {'num_leaves': 79, 'learning_rate': 0.08469458947857049, 'bagging_fraction': 0.8339466987676594}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7759971508300488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7759971508300488\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7759971508300488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7759971508300488\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7759971508300488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7759971508300488\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7759971508300488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7759971508300488\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7759971508300488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7759971508300488\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:07:03,216] Trial 74 finished with value: 0.7392625236848268 and parameters: {'num_leaves': 67, 'learning_rate': 0.07727525684683413, 'bagging_fraction': 0.7759971508300488}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7579007942806616, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7579007942806616\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7579007942806616, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7579007942806616\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7579007942806616, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7579007942806616\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7579007942806616, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7579007942806616\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7579007942806616, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7579007942806616\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:07:16,191] Trial 75 finished with value: 0.7366396287070746 and parameters: {'num_leaves': 77, 'learning_rate': 0.08141645236035149, 'bagging_fraction': 0.7579007942806616}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8124379313041081, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8124379313041081\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8124379313041081, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8124379313041081\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8124379313041081, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8124379313041081\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8124379313041081, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8124379313041081\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8124379313041081, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8124379313041081\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:07:28,962] Trial 76 finished with value: 0.7340401524344808 and parameters: {'num_leaves': 74, 'learning_rate': 0.08463748478618024, 'bagging_fraction': 0.8124379313041081}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7509928345360932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509928345360932\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7509928345360932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509928345360932\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7509928345360932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509928345360932\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7509928345360932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509928345360932\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7509928345360932, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509928345360932\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:07:41,294] Trial 77 finished with value: 0.7281748312788742 and parameters: {'num_leaves': 65, 'learning_rate': 0.0744596588339423, 'bagging_fraction': 0.7509928345360932}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7914420347109066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7914420347109066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7914420347109066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7914420347109066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7914420347109066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7914420347109066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7914420347109066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7914420347109066\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7914420347109066, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7914420347109066\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:07:54,683] Trial 78 finished with value: 0.7431691894999042 and parameters: {'num_leaves': 81, 'learning_rate': 0.07946109949691275, 'bagging_fraction': 0.7914420347109066}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.794348813573455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.794348813573455\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.794348813573455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.794348813573455\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.794348813573455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.794348813573455\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.794348813573455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.794348813573455\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.794348813573455, subsample=1.0 will be ignored. Current value: bagging_fraction=0.794348813573455\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:08:07,390] Trial 79 finished with value: 0.7425198526750548 and parameters: {'num_leaves': 80, 'learning_rate': 0.0791294559532311, 'bagging_fraction': 0.794348813573455}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7750994191051561, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7750994191051561\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7750994191051561, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7750994191051561\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7750994191051561, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7750994191051561\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7750994191051561, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7750994191051561\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7750994191051561, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7750994191051561\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:08:20,089] Trial 80 finished with value: 0.73730812629069 and parameters: {'num_leaves': 85, 'learning_rate': 0.07630755935069028, 'bagging_fraction': 0.7750994191051561}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7901429931960835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901429931960835\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7901429931960835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901429931960835\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7901429931960835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901429931960835\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7901429931960835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901429931960835\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7901429931960835, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7901429931960835\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:08:32,924] Trial 81 finished with value: 0.7372868365587277 and parameters: {'num_leaves': 81, 'learning_rate': 0.07897703126429383, 'bagging_fraction': 0.7901429931960835}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.82241525684986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.82241525684986\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.82241525684986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.82241525684986\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.82241525684986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.82241525684986\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.82241525684986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.82241525684986\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.82241525684986, subsample=1.0 will be ignored. Current value: bagging_fraction=0.82241525684986\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:08:46,685] Trial 82 finished with value: 0.7327372208383897 and parameters: {'num_leaves': 79, 'learning_rate': 0.08007764705504139, 'bagging_fraction': 0.82241525684986}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8045184046167017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8045184046167017\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8045184046167017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8045184046167017\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8045184046167017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8045184046167017\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8045184046167017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8045184046167017\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8045184046167017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8045184046167017\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:09:00,568] Trial 83 finished with value: 0.7320729812011667 and parameters: {'num_leaves': 70, 'learning_rate': 0.0817411201976661, 'bagging_fraction': 0.8045184046167017}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7696375869196204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7696375869196204\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7696375869196204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7696375869196204\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7696375869196204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7696375869196204\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7696375869196204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7696375869196204\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7696375869196204, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7696375869196204\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:09:12,975] Trial 84 finished with value: 0.7353324391645909 and parameters: {'num_leaves': 77, 'learning_rate': 0.07821344810640331, 'bagging_fraction': 0.7696375869196204}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8376581672782315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8376581672782315\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8376581672782315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8376581672782315\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8376581672782315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8376581672782315\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8376581672782315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8376581672782315\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8376581672782315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8376581672782315\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:09:27,047] Trial 85 finished with value: 0.736652402546252 and parameters: {'num_leaves': 74, 'learning_rate': 0.08285922198239443, 'bagging_fraction': 0.8376581672782315}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7925288608974193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7925288608974193\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7925288608974193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7925288608974193\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7925288608974193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7925288608974193\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7925288608974193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7925288608974193\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7925288608974193, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7925288608974193\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:09:39,273] Trial 86 finished with value: 0.7320751101743629 and parameters: {'num_leaves': 84, 'learning_rate': 0.07985511556640247, 'bagging_fraction': 0.7925288608974193}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7422967632928283, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7422967632928283\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7422967632928283, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7422967632928283\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7422967632928283, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7422967632928283\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7422967632928283, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7422967632928283\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7422967632928283, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7422967632928283\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:09:50,834] Trial 87 finished with value: 0.7353303101913947 and parameters: {'num_leaves': 87, 'learning_rate': 0.07692716250768078, 'bagging_fraction': 0.7422967632928283}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8183529691259045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8183529691259045\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8183529691259045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8183529691259045\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8183529691259045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8183529691259045\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8183529691259045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8183529691259045\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8183529691259045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8183529691259045\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:10:03,832] Trial 88 finished with value: 0.7340316365416959 and parameters: {'num_leaves': 40, 'learning_rate': 0.08656353410881346, 'bagging_fraction': 0.8183529691259045}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8582848939720374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8582848939720374\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8582848939720374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8582848939720374\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8582848939720374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8582848939720374\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8582848939720374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8582848939720374\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8582848939720374, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8582848939720374\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:10:17,876] Trial 89 finished with value: 0.7386025419939963 and parameters: {'num_leaves': 72, 'learning_rate': 0.08342300051010651, 'bagging_fraction': 0.8582848939720374}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7769938125955796, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769938125955796\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7769938125955796, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769938125955796\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7769938125955796, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769938125955796\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7769938125955796, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769938125955796\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7769938125955796, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7769938125955796\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:10:30,420] Trial 90 finished with value: 0.7385918971280152 and parameters: {'num_leaves': 80, 'learning_rate': 0.08092380355979556, 'bagging_fraction': 0.7769938125955796}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7977292804890463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7977292804890463\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7977292804890463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7977292804890463\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7977292804890463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7977292804890463\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7977292804890463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7977292804890463\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7977292804890463, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7977292804890463\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:10:42,369] Trial 91 finished with value: 0.7385940261012114 and parameters: {'num_leaves': 50, 'learning_rate': 0.08230931447948388, 'bagging_fraction': 0.7977292804890463}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8073200290106104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073200290106104\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8073200290106104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073200290106104\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8073200290106104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073200290106104\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8073200290106104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073200290106104\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.8073200290106104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8073200290106104\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:10:55,242] Trial 92 finished with value: 0.7294798918481616 and parameters: {'num_leaves': 98, 'learning_rate': 0.08433482908578431, 'bagging_fraction': 0.8073200290106104}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7841211376366333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7841211376366333\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7841211376366333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7841211376366333\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7841211376366333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7841211376366333\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7841211376366333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7841211376366333\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7841211376366333, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7841211376366333\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:11:07,854] Trial 93 finished with value: 0.741866257903813 and parameters: {'num_leaves': 63, 'learning_rate': 0.07835801394463654, 'bagging_fraction': 0.7841211376366333}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7545063997264104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7545063997264104\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7545063997264104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7545063997264104\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7545063997264104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7545063997264104\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7545063997264104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7545063997264104\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7545063997264104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7545063997264104\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:11:19,391] Trial 94 finished with value: 0.7288156522109387 and parameters: {'num_leaves': 63, 'learning_rate': 0.07816693568172046, 'bagging_fraction': 0.7545063997264104}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7887093483775011, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7887093483775011\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7887093483775011, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7887093483775011\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7887093483775011, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7887093483775011\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7887093483775011, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7887093483775011\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7887093483775011, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7887093483775011\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:11:32,103] Trial 95 finished with value: 0.7444636052032105 and parameters: {'num_leaves': 66, 'learning_rate': 0.07982813141460618, 'bagging_fraction': 0.7887093483775011}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7810695403972925, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7810695403972925\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7810695403972925, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7810695403972925\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7810695403972925, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7810695403972925\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7810695403972925, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7810695403972925\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7810695403972925, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7810695403972925\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:11:43,968] Trial 96 finished with value: 0.7359924208554214 and parameters: {'num_leaves': 68, 'learning_rate': 0.07513603297011683, 'bagging_fraction': 0.7810695403972925}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.768694364263352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.768694364263352\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.768694364263352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.768694364263352\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.768694364263352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.768694364263352\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.768694364263352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.768694364263352\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.768694364263352, subsample=1.0 will be ignored. Current value: bagging_fraction=0.768694364263352\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:11:54,903] Trial 97 finished with value: 0.7346958761789188 and parameters: {'num_leaves': 34, 'learning_rate': 0.07330101595170418, 'bagging_fraction': 0.768694364263352}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7354852980173572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7354852980173572\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7354852980173572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7354852980173572\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7354852980173572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7354852980173572\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7354852980173572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7354852980173572\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7354852980173572, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7354852980173572\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:12:06,576] Trial 98 finished with value: 0.7359902918822252 and parameters: {'num_leaves': 75, 'learning_rate': 0.07710582450280105, 'bagging_fraction': 0.7354852980173572}. Best is trial 2 with value: 0.7457686657724979.\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0\n[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n","output_type":"stream"},{"name":"stderr","text":"[I 2023-10-02 17:12:18,574] Trial 99 finished with value: 0.7464201315705435 and parameters: {'num_leaves': 71, 'learning_rate': 0.07907000602148409, 'bagging_fraction': 0.7860507745938736}. Best is trial 99 with value: 0.7464201315705435.\n","output_type":"stream"},{"name":"stdout","text":"Best Hyperparameters: {'num_leaves': 71, 'learning_rate': 0.07907000602148409, 'bagging_fraction': 0.7860507745938736}\nBest Accuracy: 0.7464201315705435\n","output_type":"stream"}]},{"cell_type":"code","source":"lgbm_params = {'num_leaves': 74, 'learning_rate': 0.06342321790413148, 'bagging_fraction': 0.5333927103678943}","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:12:18.581029Z","iopub.execute_input":"2023-10-02T17:12:18.581397Z","iopub.status.idle":"2023-10-02T17:12:18.586495Z","shell.execute_reply.started":"2023-10-02T17:12:18.581371Z","shell.execute_reply":"2023-10-02T17:12:18.585758Z"},"trusted":true},"execution_count":734,"outputs":[]},{"cell_type":"code","source":"#  LightGBM classifier with the best hyperparameters\nbest_clf = lgb.LGBMClassifier(**best_params)\n\n\n\n\n# Train classifier on the training data\nbest_clf.fit(X_train_best, y_train)\n\n# Make predictions on the test data\ny_pred = best_clf.predict(X_test_best)\n\n# Calculate accuracy \naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy}\")\n\n# Plot the learning curve\nplot_learning_curve(best_clf, X_train_best, y_train)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-10-02T17:12:18.587632Z","iopub.execute_input":"2023-10-02T17:12:18.588572Z","iopub.status.idle":"2023-10-02T17:13:22.428188Z","shell.execute_reply.started":"2023-10-02T17:12:18.588530Z","shell.execute_reply":"2023-10-02T17:13:22.427158Z"},"trusted":true},"execution_count":735,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\nAccuracy: 0.7765726681127982\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAA1cAAAIjCAYAAADvBuGTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAACuiUlEQVR4nOzdeXhU1f0/8PedfSZ7yEZCgBA2URYFiVQpKhDcUHBD+LpAFZdKQVNLRVDEjWorRayW1oLrD0EttbUIgmlxYyuoLIIgIAIJ2ZfJ7DP33t8fl7lkyGRlMpNJ3q/nyUPmzp07Z04GmHfOOZ8jyLIsg4iIiIiIiM6JJtINICIiIiIi6gwYroiIiIiIiEKA4YqIiIiIiCgEGK6IiIiIiIhCgOGKiIiIiIgoBBiuiIiIiIiIQoDhioiIiIiIKAQYroiIiIiIiEKA4YqIiIiIiCgEGK6IiKhT6927N6ZPnx7pZhARURfAcEVERM164403IAgCdu7cGemmRB2Xy4U//vGPyMvLQ0JCAkwmE/r3749Zs2bh0KFDkW4eERGFkC7SDSAiImpPBw8ehEYTmd8lVlRU4KqrrsKuXbtw3XXXYdq0aYiNjcXBgwexevVq/PWvf4XH44lI24iIKPQYroiIKGr4fD5IkgSDwdDixxiNxnZsUdOmT5+Ob775Bh988AFuuummgPuefvppzJ8/PyTP05Z+ISKi0OO0QCIiCpmioiL84he/QHp6OoxGI84//3ysXLky4ByPx4MnnngCw4cPR0JCAmJiYjB69Gj897//DTjv2LFjEAQBf/jDH7B06VLk5ubCaDRi//79ePLJJyEIAg4fPozp06cjMTERCQkJmDFjBhwOR8B1zl5z5Z/i+NVXX6GgoACpqamIiYnB5MmTUV5eHvBYSZLw5JNPIjMzExaLBVdccQX279/fonVc27dvx7p163D33Xc3CFaAEvr+8Ic/qLcvv/xyXH755Q3Omz59Onr37t1sv3zzzTfQ6XRYtGhRg2scPHgQgiDgT3/6k3qspqYGDz30ELKzs2E0GtG3b188//zzkCSpyddFRESN48gVERGFRGlpKS655BIIgoBZs2YhNTUV69evx9133w2r1YqHHnoIAGC1WvG3v/0NU6dOxcyZM1FXV4cVK1ZgwoQJ2LFjB4YNGxZw3ddffx0ulwv33nsvjEYjkpOT1ftuvfVW5OTkYPHixfj666/xt7/9DWlpaXj++eebbe+vfvUrJCUlYeHChTh27BiWLl2KWbNmYc2aNeo58+bNwwsvvICJEydiwoQJ2L17NyZMmACXy9Xs9f/1r38BAO64444W9F7rnd0v3bt3x5gxY/Dee+9h4cKFAeeuWbMGWq0Wt9xyCwDA4XBgzJgxKCoqwn333YeePXtiy5YtmDdvHk6dOoWlS5e2S5uJiDo7hisiIgqJ+fPnQxRF7N27F926dQMA3H///Zg6dSqefPJJ3HfffTCbzUhKSsKxY8cCprDNnDkTAwcOxMsvv4wVK1YEXPfkyZM4fPgwUlNTGzznhRdeGHB+ZWUlVqxY0aJw1a1bN2zcuBGCIABQRqmWLVuG2tpaJCQkoLS0FEuWLMGkSZPwj3/8Q33cokWL8OSTTzZ7/QMHDgAABg8e3Oy5bRGsX6ZMmYL77rsP+/btwwUXXKAeX7NmDcaMGYP09HQAwJIlS3DkyBF888036NevHwDgvvvuQ2ZmJn7/+9/j17/+NbKzs9ul3UREnRmnBRIR0TmTZRl///vfMXHiRMiyjIqKCvVrwoQJqK2txddffw0A0Gq1arCSJAlVVVXw+XwYMWKEek59N910U9BgBSjhrb7Ro0ejsrISVqu12Tbfe++9arDyP1YURfz0008AgMLCQvh8Pvzyl78MeNyvfvWrZq8NQG1DXFxci85vrWD9cuONN0Kn0wWMvu3btw/79+/HlClT1GPvv/8+Ro8ejaSkpICf1bhx4yCKIj7//PN2aTMRUWfHkSsiIjpn5eXlqKmpwV//+lf89a9/DXpOWVmZ+v2bb76JF198Ed9//z28Xq96PCcnp8Hjgh3z69mzZ8DtpKQkAEB1dTXi4+ObbHNTjwWghqy+ffsGnJecnKye2xT/89fV1SExMbHZ81srWL+kpKRg7NixeO+99/D0008DUEatdDodbrzxRvW8H374AXv27Gk0tNb/WRERUcsxXBER0TnzF0G4/fbbcddddwU9Z8iQIQCAd955B9OnT8ekSZPwm9/8BmlpadBqtVi8eDGOHDnS4HFms7nR59VqtUGPy7LcbJvP5bEtMXDgQADA3r17MXr06GbPFwQh6HOLohj0/Mb65bbbbsOMGTPw7bffYtiwYXjvvfcwduxYpKSkqOdIkoTx48dj7ty5Qa/Rv3//ZttLREQNMVwREdE5S01NRVxcHERRxLhx45o894MPPkCfPn2wdu3agGl5ZxdhiLRevXoBAA4fPhwwSlRZWamObjVl4sSJWLx4Md55550WhaukpCQcPXq0wXH/CFpLTZo0Cffdd586NfDQoUOYN29ewDm5ubmw2WzN/qyIiKh1uOaKiIjOmVarxU033YS///3v2LdvX4P765c4948Y1R+l2b59O7Zu3dr+DW2FsWPHQqfT4c9//nPA8frlzJsyatQoXHXVVfjb3/6GDz/8sMH9Ho8HjzzyiHo7NzcX33//fUBf7d69G1999VWr2p2YmIgJEybgvffew+rVq2EwGDBp0qSAc2699VZs3boVn3zySYPH19TUwOfzteo5iYhIwZErIiJqsZUrV2LDhg0Njs+ZMwe/+93v8N///hd5eXmYOXMmBg0ahKqqKnz99df49NNPUVVVBQC47rrrsHbtWkyePBnXXnstfvzxRyxfvhyDBg2CzWYL90tqVHp6OubMmYMXX3wR119/Pa666irs3r0b69evR0pKSsCoW2Peeust5Ofn48Ybb8TEiRMxduxYxMTE4IcffsDq1atx6tQpda+rX/ziF1iyZAkmTJiAu+++G2VlZVi+fDnOP//8FhXoqG/KlCm4/fbb8eqrr2LChAkN1nz95je/wb/+9S9cd911mD59OoYPHw673Y69e/figw8+wLFjxwKmERIRUcswXBERUYudPYrjN336dPTo0QM7duzAU089hbVr1+LVV19Ft27dcP755weURp8+fTpKSkrwl7/8BZ988gkGDRqEd955B++//z42b94cplfSMs8//zwsFgtee+01fPrppxg1ahQ2btyIyy67DCaTqdnHp6amYsuWLXj11VexZs0azJ8/Hx6PB7169cL111+POXPmqOeed955eOutt/DEE0+goKAAgwYNwttvv41Vq1a1ul+uv/56mM1m1NXVBVQJ9LNYLPjss8/w3HPP4f3338dbb72F+Ph49O/fH4sWLUJCQkKrno+IiBSCHKqVu0RERF1ATU0NkpKS8Mwzz2D+/PmRbg4REXUgXHNFRETUCKfT2eDY0qVLAQCXX355eBtDREQdHqcFEhERNWLNmjV44403cM011yA2NhZffvkl3n33XeTn5+PSSy+NdPOIiKiDYbgiIiJqxJAhQ6DT6fDCCy/AarWqRS6eeeaZSDeNiIg6IK65IiIiIiIiCgGuuSIiIiIiIgoBhisiIiIiIqIQ4JqrICRJQnFxMeLi4lq0SSQREREREXVOsiyjrq4OmZmZ0GiaHptiuAqiuLgY2dnZkW4GERERERF1ECdOnECPHj2aPIfhKoi4uDgASgfGx8dHuDVt4/V6sXHjRuTn50Ov10e6OZ0a+zp82Nfhw74OL/Z3+LCvw4d9HT7s6/ZltVqRnZ2tZoSmMFwF4Z8KGB8fH9XhymKxID4+nn/J2hn7OnzY1+HDvg4v9nf4sK/Dh30dPuzr8GjJciEWtCAiIiIiIgoBhisiIiIiIqIQYLgiIiIiIiIKAYYrIiIiIiKiEGC4IiIiIiIiCgGGKyIiIiIiohBguCIiIiIiIgoBhisiIiIiIqIQYLgiIiIiIiIKAYYrIiIiIiKiEGC4IiIiIiIiCgGGKyIiIiIiohBguCIiIiIiIgoBXaQbQNQeRBH44gvg1Cmge3dg9GhAq410qzo+9lvbsN/ajn3XeuyzthNF4LPPBHz+eRZiYgRccQX7riX4nmsb9lvbRXPfRXTk6vPPP8fEiRORmZkJQRDw4YcfNvuYzZs346KLLoLRaETfvn3xxhtvNDjnlVdeQe/evWEymZCXl4cdO3aEvvHUYa1dC/TuDVxxBTBtmvJn797KcWoc+61t2G9tx75rPfZZ2/n7bvx4HZYsGYHx43Xsuxbge65t2G9tF+19F9FwZbfbMXToULzyyistOv/HH3/EtddeiyuuuALffvstHnroIdxzzz345JNP1HPWrFmDgoICLFy4EF9//TWGDh2KCRMmoKysrL1eBnUga9cCN98MnDwZeLyoSDkeLX8xw4391jbst7Zj37Ue+6zt2Hdtw35rG/Zb23WGvovotMCrr74aV199dYvPX758OXJycvDiiy8CAM477zx8+eWX+OMf/4gJEyYAAJYsWYKZM2dixowZ6mPWrVuHlStX4tFHHw39i6AOQxSBOXMAWW54n//Yvfcq54VyaNnnE/D1193hdgvQReFEW1EEHngg/P3WFh2pr6Op39qiPfu6s/ddWzTX3+yztmPftU0o+q0j/ZsdLpF6v3WGvm6u7wQBeOgh4IYbOvbfVUGWg72E8BMEAf/4xz8wadKkRs/5+c9/josuughLly5Vj73++ut46KGHUFtbC4/HA4vFgg8++CDgOnfddRdqamrwz3/+M+h13W433G63ettqtSI7OxsVFRWIj48/15cWEV6vF5s2bcL48eOh1+sj3Zyw+OwzAePHR+m/KERERETUrE2bfBgzJrzxxWq1IiUlBbW1tc1mg6j6JFpSUoL09PSAY+np6bBarXA6naiuroYoikHP+f777xu97uLFi7Fo0aIGxzdu3AiLxRKaxkfIpk2bIt2EsFm7ti+A85s9LzOzDgkJnvZvUJSorTWguDiu2fPYb4HYb23Hvms99lnbse/ahv3WNuy3tmtp361f/y3s9qIwtOgMh8PR4nOjKly1l3nz5qGgoEC97R+5ys/P58hVFCgtBRYu1ODtt1u2hPDNN80YM8YUsueP9r5WRvyaPy/U/dYWHamvo6nf2qI9+7qz911bNNff7LO2Y9+1TSj6rSP9mx0ukXq/dYa+bmnfXX31MIwZM7T9G1SP1Wpt8blRFa4yMjJQWloacKy0tBTx8fEwm83QarXQarVBz8nIyGj0ukajEUajscFxvV4ftW9Qv87wGhrjdAK//z3wwguA3a4cMxgATyO/CBIEoEcP4IordO0yVzda+/qKK5R+KSoKPs+5vfutLTpCX0djv7VFe/R1V+m7tmisv9lnbce+a5tQ9ltH+Dc7XCL9fovmvo503zWlNX0aVZsIjxo1CoWFhQHHNm3ahFGjRgEADAYDhg8fHnCOJEkoLCxUz6HoJ4rAa68BffsCCxcqwWrAAOXY8uXKXz5BCHyM//bSpR17EWQkaLXASy8p37PfWo791nbsu9Zjn7Ud+65t2G9tw35ru87SdxENVzabDd9++y2+/fZbAEqp9W+//RbHjx8HoEzXu/POO9Xz77//fhw9ehRz587F999/j1dffRXvvfceHn74YfWcgoICvPbaa3jzzTdx4MABPPDAA7Db7Wr1QIpeogisWwcMG6ZU2ikuBtLSgAULgA8/VPZCmDED+OADICsr8LE9eijHb7wxEi3v+G68kf3WFuy3tmPftR77rO3Yd23Dfmsb9lvbdYa+i+i0wJ07d+KKK65Qb/vXPd1111144403cOrUKTVoAUBOTg7WrVuHhx9+GC+99BJ69OiBv/3tb2oZdgCYMmUKysvL8cQTT6CkpATDhg3Dhg0bGhS5oOjh8QBff62EKP+gpMUC3H678tW/P5CaCmhO/6rgxhuVMp3RurN3pLDf2ob91nbsu9Zjn7Wdv+/++18f1q//FldfPYxTAVuA77m2Yb+1XbT3XUTD1eWXX46mKsG/8cYbQR/zzTffNHndWbNmYdasWefaPIowux04ehRYvBh4/33A51MC1OTJwB13KKGqZ08gJqbhY7Va4PLLw97kqMd+axv2W9ux71qPfdZ2Wi0wZowMu70IY8YMjZoPa5HG91zbsN/aLpr7LqoKWlDnJ0mA1apM+XvtNWDFCqCuTrnvssuU6YD9+wPZ2UB6evT8FoOIiIiIOj+GK+oQvF6gpkYpq/6vfwF//jNw8qRyX//+wJw5wAUXAN26KaNVcc1vg0BEREREFFYMVxRRTidQVaWEqp07lVB1ur4JunUDZs9WhoUNBmUxY0YGoOO7loiIiIg6IH5MpbCTZWWqX0WF8nX8OLByJbB+vXK/0ahU/bvzTmVEKylJGa1KSIhsu4mIiIiImsJwRWEjimem/tXUKAHrgw+At98G3G7lnOuvBx5+GDCZlPVXvXoBmZlAlO6HR0RERERdCMMVtTu3G6iuVkKV1apsBPfpp8ArrygjVwAwYgTw6KPK+qrqasBsVkarkpIi23YiIiIiopZiuKJ2Y7MBlZVAeblSVt1iAQ4eBH7/e+DQIeWcXr2A3/wGGDsWqK1VwlePHsrmcUZjZNtPRERERNQaDFcUUpKkhKTycqVQhder7ENVVwc8/riyIRygrJ/65S+BadOU2+Xlynm5uUohC0GI3GsgIiIiImoLhisKCY/nzHqq2lolHMXHK6HqhReUTYAlSVk7NW2aEqwSE5VzXS5l9+0ePZS1VkRERERE0Yjhis6Jw6GMUJWVKdMAjUYgORnw+YA33gD+8hdlSiAAjB8PPPII0Lu3MqJVWqpMFRw4EEhJ4WgVEREREUU3hitqNVlW1kaVlytrqtxuIDYWSE9X7lu3DliyBCguVs4//3xg3jzg4ouV23V1SihLSwOys5WARUREREQU7RiuqMV8PmXqX1mZUtFPloG4uDMV/XbtAn73O2DPHuV2RgZQUABMnAhoNMrjKyuVqX/9+inhSqOJ2MshIiIiIgophitqlsulhKlTp5Qpfnq9sl7Kv/fU8ePAH/4AfPKJcttiAe69F5g+XSmpDihTBm02Zfpfz57KSBcRERERUWfCcEVBybIShioqlC+HQ6nml5p6ZrSpthb485+Bd95R1lBpNMDNNwOzZyvnAcrGwZWVShDLzVVGs7TayL0uIiIiIqL2wnBFAURRCU3+qX8+nzL1r3v3M+d4vcC77yqbANfUKMcuuwyYOxcYMODMeQ6HsjarWzdlbVV8fFhfChERERFRWDFcEQClKEVNDVBSogQirVYJQwbDmXNkGSgsVDYBPnZMOdavnxKqfv7zM+dJklJBUBCAnBwlmOn4TiMiIiKiTo4febs4u10JQqWlykiTyaSsizp76t533ynFKnbsUG5366ZM/7v55sDg5F+flZSkrK1KTAzbSyEiIiIiiiiGqy5Iks6UUq+qUjYAjolRSqmfvddUSQnwxz8C//ynMnJlMAAzZigFK+oXpZBlJVSJorKPVWbmmYIXRERERERdAcNVF+L1KlP/SkuVPwVBmfrnL6Ven90O/O1vwMqVymgUoJRULyhQglN9Ho9StCIhQRmtSk5u71dCRERERNTxMFx1AU7nmal//lLqycnB10GJIrB2LfDSS8rIFgAMHw48+igwZEjgubKsFL/weJSCFVlZgNHY/q+HiIiIiKgjYrjqpGRZ+fPYMSVYud3K1L+0tIZT//y++gp4/nng4EHlds+ewCOPAPn5DR/j8SjXjY0F+vRR1mA1dl0iIiIioq6A4aqT8fmU0aTiYuX2qVPKdL1gU//8Dh8GXngB+Owz5XZ8PPDLXwL/93+B1QL9rFZlNCwzE+jRQymCQURERETU1TFcdRIu15lS6nV1Zzb6TU1tfNPeykrg5ZeB995TpgPqdMC0aUqwChbGfD7lMWazsp9VSsqZ5yEiIiIi6uoYrqKYLCtrqCorlU1/nU4l+KSmKvdVVAR/nNsNvPkmsHy58ngAGDdOmQKYkxP8MTabcm5amrK+ymJpn9dERERERBStGK6ikCgqU/PKypR1Tz6fsvapfil1UWz4OFkG1q0DliwBioqUY+efrxSrGDmy8eeqrFSmB/brp4QrjlYRERERETXEcBVFPJ4zU/9qa5WQk5AQfF3U2b7+WtkEePdu5XZ6ulJW/frrGw9LdrsyxTAlRSluUX9fKyIiIiIiCsRwFQWcTmX0yF9K3WhUAk9ja6nqO3FCGan65BPltsUCzJypbARsNgd/jCQpz6fTAbm5QEZGy56LiIiIiKgrY7iKAseOKVMA4+ICp/41xWoFXn/9fHz8sQ5erzI6ddNNwOzZytS+xjidyqhYt27K2qr4+JC9DCIiIiKiTo3hKgqIojLi1JJpeV4vsHo18Kc/6VBT0xcAcOmlwNy5wMCBjT9OkoDqauX7nByge/fgmwwTEREREVFw/PjcScgy8J//KPtVHTsGAAJ69KjDggVmXH65rsnRLpdLCVZJScraqsTE8LSZiIiIiKgzYbjqBL77TilWsWOHcjs5GZg1S8TQof/Feedd3WiwkmUlVIki0KuXsilwS4pjEBERERFRQwxXUay0FPjjH4EPP1SCksEATJ8O3HcfYDZLOHRIbvSxHo9Sxj0+XhmtSkpq2VouIiIiIiIKjuGqAxNF4IsvlBGp+HhgzBilap/dDqxYoXy5XMq5112nlFbPyjrz2GBkWSlY4fEAPXoo5xuN4Xk9RERERESdGcNVB7V2LTBnDnDy5Jlj6enA2LHApk1Aebly7KKLlE2Ahw5t/pr+0arYWKBPH6UiIEeriIiIiIhCg+GqA1q7Frj5ZmWUqb7SUmDVKuX77GzgkUeACRNaXprd6VSqAPbo0fgeV0RERERE1DYMVx2MKCojVmcHq/ri4oCPPmpZQPL5gIoK5dwBA5TNhzWa0LWXiIiIiIgU/JjdwXzxReBUwGDq6oA9e1p2vaoqIDUVGDRI2TyYwYqIiIiIqH1w5KqDOXWqZef511wFI4pn7s/NVaYCarXn3jYiIiIiImocxzE6mO7dW3Zeamrw43a7EqySkpTb6ekMVkRERERE4cBw1cGMHq0UnGisSIUgABkZwIgRgcclSQlVHo8yWtWvX/u3lYiIiIiIzmC46mC0WuCll5Tvzw5Y/tvz5weORjmdSiXBhATgvPOUvas4WkVEREREFF4RD1evvPIKevfuDZPJhLy8POzYsaPRc71eL5566ink5ubCZDJh6NCh2LBhQ8A5Tz75JARBCPgaOHBge7+MkLrxRuCDD85sCOyXng4sWwbk5yu3ZRmorAQcDiAnR6kGGB8f/vYSEREREVGEC1qsWbMGBQUFWL58OfLy8rB06VJMmDABBw8eRFpaWoPzFyxYgHfeeQevvfYaBg4ciE8++QSTJ0/Gli1bcOGFF6rnnX/++fj000/V2zpd9NXtuPFG4IYblOqBO3YooWnMmDMjUm43UF0NJCYCPXsqfxIRERERUeREdORqyZIlmDlzJmbMmIFBgwZh+fLlsFgsWLlyZdDz3377bTz22GO45ppr0KdPHzzwwAO45ppr8OKLLwacp9PpkJGRoX6lpKSE4+WEnFYLXH45cM01wPDhym1ZVsqrW61KqBo4kMGKiIiIiKgjiNiQjsfjwa5duzBv3jz1mEajwbhx47B169agj3G73TCZTAHHzGYzvvzyy4BjP/zwAzIzM2EymTBq1CgsXrwYPXv2bLQtbrcbbrdbvW21WgEo0xC9Xm+rX1uoSZLy5XIpo1VxcUrRi8REZR1WsCb6290R2t/Zsa/Dh30dPuzr8GJ/hw/7OnzY1+HDvm5frelXQZZluR3b0qji4mJkZWVhy5YtGDVqlHp87ty5+Oyzz7B9+/YGj5k2bRp2796NDz/8ELm5uSgsLMQNN9wAURTVcLR+/XrYbDYMGDAAp06dwqJFi1BUVIR9+/YhLi4uaFuefPJJLFq0qMHxVatWwWKxhOgVExERERFRtHE4HJg2bRpqa2sR30yBg6gKV+Xl5Zg5cyY++ugjCIKA3NxcjBs3DitXroTT6Qz6PDU1NejVqxeWLFmCu+++O+g5wUausrOzUVFR0WwHhsP33ytrrHr0AJKTGy/TXp/X68WmTZswfvx46PX69m9kF8a+Dh/2dfiwr8OL/R0+7OvwYV+HD/u6fVmtVqSkpLQoXEVsWmBKSgq0Wi1KS0sDjpeWliIjIyPoY1JTU/Hhhx/C5XKhsrISmZmZePTRR9GnT59GnycxMRH9+/fH4cOHGz3HaDTCaDQ2OK7X6zvEG7RXL0CvB8zm1j+2o7yGroB9HT7s6/BhX4cX+zt82Nfhw74OH/Z1+2hNn0asoIXBYMDw4cNRWFioHpMkCYWFhQEjWcGYTCZkZWXB5/Ph73//O2644YZGz7XZbDhy5Ai6d+8esraHW3x824IVERERERGFT0SrBRYUFOC1117Dm2++iQMHDuCBBx6A3W7HjBkzAAB33nlnQMGL7du3Y+3atTh69Ci++OILXHXVVZAkCXPnzlXPeeSRR/DZZ5/h2LFj2LJlCyZPngytVoupU6eG/fUREREREVHXEdENoKZMmYLy8nI88cQTKCkpwbBhw7Bhwwakp6cDAI4fPw6N5kz+c7lcWLBgAY4ePYrY2Fhcc801ePvtt5FYrxb5yZMnMXXqVFRWViI1NRWXXXYZtm3bhtTU1HC/PCIiIiIi6kIivrvurFmzMGvWrKD3bd68OeD2mDFjsH///iavt3r16lA1jYiIiIiIqMUiOi2QiIiIiIios2C4IiIiIiIiCgGGKyIiIiIiohBguCIiIiIiIgoBhisiIiIiIqIQYLgiIiIiIiIKAYYrIiIiIiKiEGC4IiIiIiIiCgGGKyIiIiIiohBguCIiIiIiIgoBhisiIiIiIqIQYLgiIiIiIiIKAYYrIiIiIiKiEGC4IiIiIiIiCgGGKyIiIiIiohBguCIiIiIiIgoBhisiIiIiIqIQYLgiIiIiIiIKAYYrIiIiIiKiEGC4IiIiIiIiCgGGKyIiIiIiohBguCIiIiIiIgoBhisiIiIiIqIQYLgiIiIiIiIKAYYrIiIiIiKiEGC4IiIiIiIiCgGGKyIiIiIiohBguCIiIiIiIgoBhisiIiIiIqIQYLgiIiIiIiIKAYYrIiIiIiKiEGC4IiIiIiIiCgGGKyIiIiIiohBguCIiIiIiIgoBhisiIiIiIqIQYLgiIiIiIiIKAYYrIiIiIiKiEGC4IiIiIiIiCgGGKyIiIiIiohBguCIiIiIiIgoBhisiIiIiIqIQiHi4euWVV9C7d2+YTCbk5eVhx44djZ7r9Xrx1FNPITc3FyaTCUOHDsWGDRvO6ZpEREREREShENFwtWbNGhQUFGDhwoX4+uuvMXToUEyYMAFlZWVBz1+wYAH+8pe/4OWXX8b+/ftx//33Y/Lkyfjmm2/afE0iIiIiIqJQ0EXyyZcsWYKZM2dixowZAIDly5dj3bp1WLlyJR599NEG57/99tuYP38+rrnmGgDAAw88gE8//RQvvvgi3nnnnTZdEwDcbjfcbrd622q1AlBGyrxeb+hecBj52x2t7Y8m7OvwYV+HD/s6vNjf4cO+Dh/2dfiwr9tXa/o1YuHK4/Fg165dmDdvnnpMo9Fg3Lhx2Lp1a9DHuN1umEymgGNmsxlffvllm68JAIsXL8aiRYsaHN+4cSMsFkurXldHs2nTpkg3octgX4cP+zp82Nfhxf4OH/Z1+LCvw4d93T4cDkeLz41YuKqoqIAoikhPTw84np6eju+//z7oYyZMmIAlS5bg5z//OXJzc1FYWIi1a9dCFMU2XxMA5s2bh4KCAvW21WpFdnY28vPzER8f39aXGFFerxebNm3C+PHjodfrI92cTo19HT7s6/BhX4cX+zt82Nfhw74OH/Z1+/LPamuJiE4LbK2XXnoJM2fOxMCBAyEIAnJzczFjxgysXLnynK5rNBphNBobHNfr9VH/Bu0MryFasK/Dh30dPuzr8GJ/hw/7OnzY1+HDvm4frenTiBW0SElJgVarRWlpacDx0tJSZGRkBH1MamoqPvzwQ9jtdvz000/4/vvvERsbiz59+rT5mkRERERERKEQsXBlMBgwfPhwFBYWqsckSUJhYSFGjRrV5GNNJhOysrLg8/nw97//HTfccMM5X5OIiIiIiOhcRHRaYEFBAe666y6MGDECI0eOxNKlS2G329VKf3feeSeysrKwePFiAMD27dtRVFSEYcOGoaioCE8++SQkScLcuXNbfE0iIiIiIqL2ENFwNWXKFJSXl+OJJ55ASUkJhg0bhg0bNqgFKY4fPw6N5szgmsvlwoIFC3D06FHExsbimmuuwdtvv43ExMQWX5OIiIiIiKg9RLygxaxZszBr1qyg923evDng9pgxY7B///5zuiYREREREVF7iNiaKyIiIiIios6E4YqIiIiIiCgEGK6IiIiIiIhCgOGKiIiIiIgoBBiuiIiIiIiIQoDhioiIiIiIKAQYroiIiIiIiEKA4YqIiIiIiCgEGK6IiIiIiIhCgOGKiIiIiIgoBBiuiIiIiIiIQoDhioiIiIiIKAQYroiIiIiIiEKA4YqIiIiIiCgEGK6IiIiIiIhCgOGKiIiIiIgoBBiuiIiIiIiIQoDhioiIiIiIKAQYroiIiIiIiEKA4YqIiIiIiCgEGK6IiIiIiIhCgOGKiIiIiIgoBBiuiIiIiIiIQoDhioiIiIiIKAQYroiIiIiIiEKA4YqIiIiIiCgEGK6IiIiIiIhCgOGKiIiIiIgoBBiuiIiIiIiIQoDhioiIiIiIKAQYroiIiIiIiEKA4YqIiIiIiCgEGK6IiIiIiIhCgOGKiIiIiIgoBBiuiIiIiIiIQoDhioiIiIiIKAQYroiIiIiIiEKA4YqIiIiIiCgEGK6IiIiIiIhCgOGKiIiIiIgoBCIerl555RX07t0bJpMJeXl52LFjR5PnL126FAMGDIDZbEZ2djYefvhhuFwu9f4nn3wSgiAEfA0cOLC9XwYREREREXVxukg++Zo1a1BQUIDly5cjLy8PS5cuxYQJE3Dw4EGkpaU1OH/VqlV49NFHsXLlSvzsZz/DoUOHMH36dAiCgCVLlqjnnX/++fj000/V2zpdRF8mERERERF1AREduVqyZAlmzpyJGTNmYNCgQVi+fDksFgtWrlwZ9PwtW7bg0ksvxbRp09C7d2/k5+dj6tSpDUa7dDodMjIy1K+UlJRwvBwiIiIiIurCIjak4/F4sGvXLsybN089ptFoMG7cOGzdujXoY372s5/hnXfewY4dOzBy5EgcPXoUH3/8Me64446A83744QdkZmbCZDJh1KhRWLx4MXr27NloW9xuN9xut3rbarUCALxeL7xe77m8zIjxtzta2x9N2Nfhw74OH/Z1eLG/w4d9HT7s6/BhX7ev1vSrIMuy3I5taVRxcTGysrKwZcsWjBo1Sj0+d+5cfPbZZ9i+fXvQxy1btgyPPPIIZFmGz+fD/fffjz//+c/q/evXr4fNZsOAAQNw6tQpLFq0CEVFRdi3bx/i4uKCXvPJJ5/EokWLGhxftWoVLBbLOb5SIiIiIiKKVg6HA9OmTUNtbS3i4+ObPDeqFiNt3rwZzz33HF599VXk5eXh8OHDmDNnDp5++mk8/vjjAICrr75aPX/IkCHIy8tDr1698N577+Huu+8Oet158+ahoKBAvW21WpGdnY38/PxmO7Cj8nq92LRpE8aPHw+9Xh/p5nRq7OvwYV+HD/s6vNjf4cO+Dh/2dfiwr9uXf1ZbS0QsXKWkpECr1aK0tDTgeGlpKTIyMoI+5vHHH8cdd9yBe+65BwAwePBg2O123HvvvZg/fz40moZLyBITE9G/f38cPny40bYYjUYYjcYGx/V6fdS/QTvDa4gW7OvwYV+HD/s6vNjf4cO+Dh/2dfiwr9tHa/o0YgUtDAYDhg8fjsLCQvWYJEkoLCwMmCZYn8PhaBCgtFotAKCx2Y02mw1HjhxB9+7dQ9RyIiIiIiKihiI6LbCgoAB33XUXRowYgZEjR2Lp0qWw2+2YMWMGAODOO+9EVlYWFi9eDACYOHEilixZggsvvFCdFvj4449j4sSJash65JFHMHHiRPTq1QvFxcVYuHAhtFotpk6dGrHXSUREREREnV9Ew9WUKVNQXl6OJ554AiUlJRg2bBg2bNiA9PR0AMDx48cDRqoWLFgAQRCwYMECFBUVITU1FRMnTsSzzz6rnnPy5ElMnToVlZWVSE1NxWWXXYZt27YhNTU17K+PiIiIiIi6jogXtJg1axZmzZoV9L7NmzcH3NbpdFi4cCEWLlzY6PVWr14dyuYRERERERG1SEQ3ESYiIiIiIuosGK6IiIiIiIhCgOGKiIiIiIgoBBiuiIiIiIiIQoDhioiIiIiIKAQYroiIiIiIiEKA4YqIiIiIiCgEGK6IiIiIiIhCgOGKiIiIiIgoBBiuiIiIiIiIQoDhioiIiIiIKAQYroiIiIiIiEKA4YqIiIiIiCgEGK6IiIiIiIhCgOGKiIiIiIgoBBiuiIiIiIiIQoDhioiIiIiIKAQYroiIiIiIiEKA4YqIiIiIiCgEWh2uevfujaeeegrHjx9vj/YQERERERFFpVaHq4ceeghr165Fnz59MH78eKxevRput7s92kZERERERBQ12hSuvv32W+zYsQPnnXcefvWrX6F79+6YNWsWvv766/ZoIxERERERUYfX5jVXF110EZYtW4bi4mIsXLgQf/vb33DxxRdj2LBhWLlyJWRZDmU7iYiIiIiIOjRdWx/o9Xrxj3/8A6+//jo2bdqESy65BHfffTdOnjyJxx57DJ9++ilWrVoVyrYSERERERF1WK0OV19//TVef/11vPvuu9BoNLjzzjvxxz/+EQMHDlTPmTx5Mi6++OKQNpSIiIiIiKgja3W4uvjiizF+/Hj8+c9/xqRJk6DX6xuck5OTg9tuuy0kDSQiIiIiIooGrQ5XR48eRa9evZo8JyYmBq+//nqbG0VERERERBRtWl3QoqysDNu3b29wfPv27di5c2dIGkVERERERBRtWh2uHnzwQZw4caLB8aKiIjz44IMhaRQREREREVG0aXW42r9/Py666KIGxy+88ELs378/JI0iIiIiIiKKNq0OV0ajEaWlpQ2Onzp1Cjpdmyu7ExERERERRbVWh6v8/HzMmzcPtbW16rGamho89thjGD9+fEgbR0REREREFC1aPdT0hz/8AT//+c/Rq1cvXHjhhQCAb7/9Funp6Xj77bdD3kAiIiIiIqJo0OpwlZWVhT179uD//b//h927d8NsNmPGjBmYOnVq0D2viIiIiIiIuoI2LZKKiYnBvffeG+q2EBERERERRa02V6DYv38/jh8/Do/HE3D8+uuvP+dGERERERERRZtWh6ujR49i8uTJ2Lt3LwRBgCzLAABBEAAAoiiGtoVERERERERRoNXVAufMmYOcnByUlZXBYrHgu+++w+eff44RI0Zg8+bN7dBEIiIiIiKijq/VI1dbt27Ff/7zH6SkpECj0UCj0eCyyy7D4sWLMXv2bHzzzTft0U4iIiIiIqIOrdUjV6IoIi4uDgCQkpKC4uJiAECvXr1w8ODB0LaOiIiIiIgoSrR65OqCCy7A7t27kZOTg7y8PLzwwgswGAz461//ij59+rRHG4mIiIiIiDq8Vo9cLViwAJIkAQCeeuop/Pjjjxg9ejQ+/vhjLFu2rNUNeOWVV9C7d2+YTCbk5eVhx44dTZ6/dOlSDBgwAGazGdnZ2Xj44YfhcrnO6ZpERERERETnqtUjVxMmTFC/79u3L77//ntUVVUhKSlJrRjYUmvWrEFBQQGWL1+OvLw8LF26FBMmTMDBgweRlpbW4PxVq1bh0UcfxcqVK/Gzn/0Mhw4dwvTp0yEIApYsWdKmaxIREREREYVCq0auvF4vdDod9u3bF3A8OTm51cEKAJYsWYKZM2dixowZGDRoEJYvXw6LxYKVK1cGPX/Lli249NJLMW3aNPTu3Rv5+fmYOnVqwMhUa69JREREREQUCq0audLr9ejZs2dI9rLyeDzYtWsX5s2bpx7TaDQYN24ctm7dGvQxP/vZz/DOO+9gx44dGDlyJI4ePYqPP/4Yd9xxR5uvCQButxtut1u9bbVaAShh0uv1ntPrjBR/u6O1/dGEfR0+7OvwYV+HF/s7fNjX4cO+Dh/2dftqTb+2elrg/Pnz8dhjj+Htt99GcnJyax+uqqiogCiKSE9PDzienp6O77//Puhjpk2bhoqKClx22WWQZRk+nw/3338/HnvssTZfEwAWL16MRYsWNTi+ceNGWCyW1r60DmXTpk2RbkKXwb4OH/Z1+LCvw4v9HT7s6/BhX4cP+7p9OByOFp/b6nD1pz/9CYcPH0ZmZiZ69eqFmJiYgPu//vrr1l6yxTZv3oznnnsOr776KvLy8nD48GHMmTMHTz/9NB5//PE2X3fevHkoKChQb1utVmRnZyM/Px/x8fGhaHrYeb1ebNq0CePHj4der490czo19nX4sK/Dh30dXuzv8GFfhw/7OnzY1+3LP6utJVodriZNmtTahwSVkpICrVaL0tLSgOOlpaXIyMgI+pjHH38cd9xxB+655x4AwODBg2G323Hvvfdi/vz5bbomABiNRhiNxgbH9Xp91L9BO8NriBbs6/BhX4cP+zq82N/hw74OH/Z1+LCv20dr+rTV4WrhwoWtfUhQBoMBw4cPR2FhoRrYJElCYWEhZs2aFfQxDocDGk1gDQ6tVgsAkGW5TdckIiIiIiIKhVaHq1AqKCjAXXfdhREjRmDkyJFYunQp7HY7ZsyYAQC48847kZWVhcWLFwMAJk6ciCVLluDCCy9UpwU+/vjjmDhxohqymrsmERERERFRe2h1uNJoNE2WXW9NJcEpU6agvLwcTzzxBEpKSjBs2DBs2LBBLUhx/PjxgJGqBQsWQBAELFiwAEVFRUhNTcXEiRPx7LPPtviaRERERERE7aHV4eof//hHwG2v14tvvvkGb775ZtCKe82ZNWtWo1P2Nm/eHHBbp9Nh4cKFzU5NbOqaRERERERE7aHV4eqGG25ocOzmm2/G+eefjzVr1uDuu+8OScOIiIiIiIiiiab5U1rmkksuQWFhYaguR0REREREFFVCEq6cTieWLVuGrKysUFyOiIiIiIgo6rR6WmBSUlJAQQtZllFXVweLxYJ33nknpI0jIiIiIiKKFq0OV3/84x8DwpVGo0Fqairy8vKQlJQU0sYRERERERFFi1aHq+nTp7dDM4iIiIiIiKJbq9dcvf7663j//fcbHH///ffx5ptvhqRRRERERERE0abV4Wrx4sVISUlpcDwtLQ3PPfdcSBpFREREREQUbVodro4fP46cnJwGx3v16oXjx4+HpFFERERERETRptXhKi0tDXv27GlwfPfu3ejWrVtIGkVERERERBRtWh2upk6ditmzZ+O///0vRFGEKIr4z3/+gzlz5uC2225rjzYSERERERF1eK2uFvj000/j2LFjGDt2LHQ65eGSJOHOO+/kmisiIiIiIuqyWh2uDAYD1qxZg2eeeQbffvstzGYzBg8ejF69erVH+4iIiIiIiKJCq8OVX79+/dCvX79QtoWIiIiIiChqtXrN1U033YTnn3++wfEXXngBt9xyS0gaRUREREREFG1aHa4+//xzXHPNNQ2OX3311fj8889D0igiIiIiIqJo0+pwZbPZYDAYGhzX6/WwWq0haRQREREREVG0aXW4Gjx4MNasWdPg+OrVqzFo0KCQNIqIiIiIiCjatLqgxeOPP44bb7wRR44cwZVXXgkAKCwsxKpVq/DBBx+EvIFERERERETRoNXhauLEifjwww/x3HPP4YMPPoDZbMbQoUPxn//8B8nJye3RRiIiIiIiog6vTaXYr732Wlx77bUAAKvVinfffRePPPIIdu3aBVEUQ9pAIiIiIiKiaNDqNVd+n3/+Oe666y5kZmbixRdfxJVXXolt27aFsm1ERERERERRo1UjVyUlJXjjjTewYsUKWK1W3HrrrXC73fjwww9ZzIKIiIiIiLq0Fo9cTZw4EQMGDMCePXuwdOlSFBcX4+WXX27PthEREREREUWNFo9crV+/HrNnz8YDDzyAfv36tWebiIiIiIiIok6LR66+/PJL1NXVYfjw4cjLy8Of/vQnVFRUtGfbiIiIiIiIokaLw9Ull1yC1157DadOncJ9992H1atXIzMzE5IkYdOmTairq2vPdhIREREREXVora4WGBMTg1/84hf48ssvsXfvXvz617/G7373O6SlpeH6669vjzYSERERERF1eG0uxQ4AAwYMwAsvvICTJ0/i3XffDVWbiIiIiIiIos45hSs/rVaLSZMm4V//+lcoLkdERERERBR1QhKuiIiIiIiIujqGKyIiIiIiohBguCIiIiIiIgoBhisiIiIiIqIQYLgiIiIiIiIKAYYrIiIiIiKiEGC4IiIiIiIiCgGGKyIiIiIiohBguCIiIiIiIgoBhisiIiIiIqIQYLgiIiIiIiIKgQ4Rrl555RX07t0bJpMJeXl52LFjR6PnXn755RAEocHXtddeq54zffr0BvdfddVV4XgpRERERETUReki3YA1a9agoKAAy5cvR15eHpYuXYoJEybg4MGDSEtLa3D+2rVr4fF41NuVlZUYOnQobrnlloDzrrrqKrz++uvqbaPR2H4vgoiIiIiIuryIj1wtWbIEM2fOxIwZMzBo0CAsX74cFosFK1euDHp+cnIyMjIy1K9NmzbBYrE0CFdGozHgvKSkpHC8HCIiIiIi6qIiOnLl8Xiwa9cuzJs3Tz2m0Wgwbtw4bN26tUXXWLFiBW677TbExMQEHN+8eTPS0tKQlJSEK6+8Es888wy6desW9Bputxtut1u9bbVaAQBerxder7e1L6tD8Lc7WtsfTdjX4cO+Dh/2dXixv8OHfR0+7Ovw6Yx9LckSZFmGVqONdFNa1a+CLMtyO7alScXFxcjKysKWLVswatQo9fjcuXPx2WefYfv27U0+fseOHcjLy8P27dsxcuRI9fjq1athsViQk5ODI0eO4LHHHkNsbCy2bt0KrbbhD+jJJ5/EokWLGhxftWoVLBbLObxCIiIiIiKKZg6HA9OmTUNtbS3i4+ObPDfia67OxYoVKzB48OCAYAUAt912m/r94MGDMWTIEOTm5mLz5s0YO3Zsg+vMmzcPBQUF6m2r1Yrs7Gzk5+c324EdldfrxaZNmzB+/Hjo9fpIN6dTY1+HD/s6fNjX4cX+Dh/2dfiwr8MnmvraK3rhET1wiS64vW7UeeqU731uiJIIANBqtBBlEbH6WAxOHxzhFp+Z1dYSEQ1XKSkp0Gq1KC0tDTheWlqKjIyMJh9rt9uxevVqPPXUU80+T58+fZCSkoLDhw8HDVdGozFowQu9Xt/h36DN6QyvIVqwr8OHfR0+7OvwYn+HD/s6fNjX4dOR+lqWZXhED9yiG26fGw6vA3XuM0FKkiUAgF6rh0FrQKIhEXrtmbbXueugETQd4vW0pg0RDVcGgwHDhw9HYWEhJk2aBACQJAmFhYWYNWtWk499//334Xa7cfvttzf7PCdPnkRlZSW6d+8eimYTEREREdFpkizB7XOrQcrusaPOUwe36IZH9ECWZQiCAIPWAIPWgBhzTIdYS9UeIj4tsKCgAHfddRdGjBiBkSNHYunSpbDb7ZgxYwYA4M4770RWVhYWL14c8LgVK1Zg0qRJDYpU2Gw2LFq0CDfddBMyMjJw5MgRzJ07F3379sWECRPC9rqIiIiIiDobURLhFt1w+ZQRKJvHhjpPnTrdDwA0ggZGnREmnQnxxnhohIgXKA+biIerKVOmoLy8HE888QRKSkowbNgwbNiwAenp6QCA48ePQ6MJ/IEcPHgQX375JTZu3NjgelqtFnv27MGbb76JmpoaZGZmIj8/H08//TT3uiIiIiIiaiGv6FWDlMvrQp2nDk6fE26fGz7JBwDQaXQw6oyIMcQgUZMIQRAi3OrIini4AoBZs2Y1Og1w8+bNDY4NGDAAjRU5NJvN+OSTT0LZPCIiIiKiTqup9VEenweirBSa8K+PijfGB6yPojM6RLgiIiIiCiVREuGTfA2+3B5lX8sqZxVi5ViYdKZOu/aDKJiz10c5vA5Y3dZG10dZzBboNIwMLcWeIiIioqghy3LQ0OSTfEp5Z58LbtGtHhMlET7ZB5ye8CKLyjcHKw5Cr9cr05n0MYg3xsOkM8GkM8GoM3apNSLUeXF9VPgxXBEREVGHoIah08HIK3khSiK8olcNTW5R2QvHH5pkyBAgQIYMDTTQarTQaXTQClqYdWZoNVpoBa26DkT0iahGNVJjUiEJEtyiG9WuapTZywBA/W19nDEOsYbYM4FLa+zya0mo47N77PB5fQHrozw+D7ySFwDXR4UDwxURERG1K0mWGh1tcvuU36p7RE/AaJN/jYefTqNTg5NBa4BWr3x/Lr9l12v1AetGZFmGV/LC7XOjzF6GYmuxOj3K/1v9GEOMGrgMWkObn5uorYKtj6q11wIA9pXtgyRIEARBXR8Va4zlezWMGK6IiIioTWRZhigHX9ukjjb53PBInsDRpnpFqTRC4GiTRW9Rb4db/XUmcYhTX6P/g2xxXTEkWfngatQaYdaZkWBKgFlvVgMX16ZQKEmydGa6axPro3SnP9InmBJgNLA6diTxXwAiIiJqwD89r3548opeiLKoftBz+VwBo1KSLKlT9ARBUAOTVqNV1zGd62hTuAmCAKPOCKPOCJz+zOovCODwOVBdUw0A0ArKazTrzYg3xAcELhbMoJYItj7K5rHBI3qaXR8l+kSUopThvgPgT4CIiKgLOdeCEADUdUz+qXpGnVENUV2BRtDArDfDrDerx/xTHK1uKyodlZAhQ69hwQwKzr9/lNvnhtPrbHR9lEFr4PqoKMNwRURE1Ek0Vn5c/SB3+sOcKIvquZIsqY8/e7TJpDOpIYof7Jqm0+igM+gQgxj1mH/EIVjBjHhjfEDBDIPWwD7uhERJhFdSKvO5fW44fU5YXdZG94/i+qjox3BFREQUZVw+F2wemxKafG64RGUakTqNT/SpH9oEQYAsywEFIfQavRqcuspoUyT4g5Rf/YIZpfZSFNcVAwJg1CrTvOIMcSyYEUXOrmx5dpEWt+iGV/Sq9/vXGhp1Ru4f1YnxJ0pERNTBybIMh9cBm8eGKmcVrG5rwBqM+gUhDFoDtIbA8uPUMTRWMMM/omh1WyFJEjQaDQtmRJgkS2owqh+gvKIXTp8TLp/rzH31fpkBnBkBrl+kRa/VcypoF8G/oURERB2QJEuwe+yweWyodFSqC9sNOgMseguSzEmRbiKFgCAIanDyEyURHtEDh8+BmpoayJDVghkWvQUJpoSA/bc4+tg69Yuw1A9Q/uDkr3AZbM3h2VNnzToztIbIVLekjonvBCIiog7CJ/ngcDlQ565DhbMCdo8doiTCpDdxLUYXotVoYdYEL5hR665FhaMCAKDX6GHQGRBnCNzw2KQzddlRS3/BlvrT9PwByuVzqdP11Cl9p4NT/emz/im0/pFCjgJTazBcERERRZBH9KDGVQMA+K78OzglJwDArDMjyZzE34gTgKYLZlQ4KlBiKwHQuQtmnF3psn6Acnqd6vTK+iNO9fdUq7/u0KgzwiJYWKyFQo7/YhMREYWZvyBFjasGNa4aOFwO9b4UcwqneVGL+INUrCEWQPMFMxKMCbDoLWrg0mv1EX4FZ/g3pA62zslfIMLlc6mVLv0FIvz7qvlDk798uVavhV6jZ3CisGO4IiIiamfBClK4fW7otDpY9BakWFJQjWrE6GMYrKjNghXMkGRJLQN+wn0CsiyrG9Fa9BbEGeLCUjDj7K0B/N+rU/V8bvhk35ktAiCp65zq76vmr3QZbZtRU9fBcEVERNQOWlOQQvSJTVyJqO00giZowQy36Eadu07Z8Pj0WqNgBTNMOlOzIcYfiM5e5+R0K1Nc95Xug6Q5U0RCkiV1jZO/2qVeo4dOo2NwoqjHcEVERBQiPskHu8eufGh1VsLuscMn+WDUGVmQgjoMrUYLi8YCi96iHgsomOGsAOTAghlxxjgYtUZlHzXJB4/oUdc5+cOUKIkBJclxen9qr+yFQWOAUWfk3mrU6TFcERERnQOP6IHNY4PVbUWVswp2rx0A1D2KOtK6FqLGtKhghoAGJcnr7+XkLxjhJ/pEVKEKcYY4aHUMVNQ1MFwRERG10tkFKZxeJwQIsBgsLEhBncbZBTOIqHkMV0RERM2QZRlOn1NdP1XnqYPb54ZG0MCityAtJo1VyYiIiOGKiIgomOYKUiQYExioiIgoAMMVERHRaSxIQUQUeaIkYmfxTlQ5q1DjrsHonqOjZro1wxUREXVpZxekcHgdkCHDpDWxIEUnI0oidhTtwJ7qPagpqsHI7JFR84GNoo8/IJQ7ypFqScWIzBF8v7XAxiMb8ewXzypFVE7rEd8DL131Em4878YItqxlGK6IiKjLaaogRTdzN34A6oQafGD7CciIzcD80fORn5sf2cZRpxMsIPD91ryNRzZi9vrZkP1lKU8rshbh5vduxge3ftDhAxZ3aCMiok5PlmU4vA6U2cvwfcX32FO6BwfKD6DUVgqtoEVqTCrSYtMQa4hlsOqE/B/Y6n/QBYBSWylmr5+NjUc2Rqhl1Bnx/dY2oiTi2S+ebRCsAKjHHtrwEESpY2+6zpErIiLqlIIVpPBKXui1emUPKhak6BKa+8AmQMCzXzyLsTljGazpnHXE95ssy5BkCaIsKn9KYsBtn+RrcFyUxTO3T28Ord7nvy1JzR8/fQ2f7Gtw/OznOV57vEEgPbv/TlhP4IvjX+Dy3peHpe/aguGKiIg6DVESYfPYAgpSiLKo7NXDghRdjk/yYeORjc1+YCuxlWBn8U7k9cgLY+uoM9petL1F77e7PrwLSaakwFDiDzxSkOBT73hA8Kn3vcfjAfYjaIjqTE7VnYp0E5rEcEVERFHNK3rVghSVzkqlIIUsw6RjQYrOzit6UWIvQZG1CEXWIhTXFaOorkj5shahxFbS4g+Wv1z3S/RJ7oPMuExkxWUhKz5L+TMuC5lxmYgxxLTzq6Fo4BE9OFV3KuB95n/fFdcVt/iD//+K/9c+DWxDjhIgQKvRQiNooNPooBE00ArKba1GC62gVe9v63H1uvWOB5yn0aLcXo5NRzc1297ucd3b0DHhw3BFRERRhwUpuoZgH2T9H2KLrEUotZdCkqUmr6EVtC0KWDavDXtK92BP6Z6g9yeaEtWw5Q9emfGZ6rE4Y1ybXiN1LC6fS3mPWYsD3mv+92C5vTzolL/Wun3w7eiT3EcNGGo4qRc4ggWdxo4LkoATe0+gz7A+0Ov00GiCBJhGrt1RpkeLkogr37oSpbbSoH0sQECP+B4Y3XN0BFrXcgxXRETU4cmyDKfPCZvHhipnFaxuK9w+NzSCBha9BakxqdAIrNEUbVw+F4rriht8gPV/35IPsgatAZlxmegR1wNZ8VkNRp6SzckY9/a4Jj+wpcWk4ZVrXkGpvRQnrScDPlQX1xWj1l2rBvnvyr8L2o54Y7w6ylV/1MvfJq7x6xjsHnuDEc76P+9KZ2Wz1zBqjQHvtR7xPdTv02PSMfXvU1Fqb/z9lh6bjsdGPxbSXwKJPhEwATmJOdDqovOXS1qNFvNHz8fs9bMhQAjoPwHK352lVy3t8L88Y7giIqIOSZIlOLyOgIIUbtENvUYPi97CD6tRwOl1oriuGCfrTgZO2zv9fbmjvNlrmHSmgJBy9ofZbpZuzQbr5j6wLfj5AgxOH4zBGBz08XXuugaBq6iuCCetJ1FcV4xqVzWsbiusbisOVBwIeo0YfUyDqYbq7fgsJJmS+H4OAavbqrznTv9szp4uWuOqafYaFr0FPeJ6qD+jswNzsjm5yZ/V/J83/X6bP3p+hw8IkZKfm49lVy8Lus/V0quWdvgy7ADDFRERdSBNFaSIMcQgSZsU6SZSPTaPrdFRp+K6YlQ5q5q9hv+DbP3w5J9u1yO+R0hCR2Mf2NJj01u071CcMQ4DjQMxMGVg0Pv9oyH+IFm/T4rrilHhqIDda8ehykM4VHko6DXMOnNgH8Rlokd8D/X7FEtKlw9fsiyjxlUTdLqeP0TVeeqavU5jo4z+2+f6i5tzfb91dfm5+RibMxaf//Q5qpxVGJU9CqN7jo6aQMpwRUREESPLMtyiG06vkwUpWkiUROws3olyRzlSLakYkTmi3T50+Eds6o8C1P9gW+OuafYasYbYgJGm+t+H4oNsS/k/sO04sQN79uzBkCFDMDJ7ZEj6LsYQg37d+qFft35B7/dPfzy7//zBoMxeBqfPicNVh3G46nDQaxi1xoB+O3v6Y3tOjQ3Xe06WZVQ6KwP65uzRJ4fX0ex1kkxJDcJp/T4Lx/o4//stXH9XOxutRqv0l6DFsO7DIt2cVmG4IiKisJBkCW6fG27RDZfPBbvHjjp3HdyiGx7RA0AZxWBBisZtPLKxwW/DM2Iz2vTbcFmWUeuuDTrNzT8S0JJRgERjYkBhh/qjTplxmYg3xrf6dbYXrUaLkVkjkXgiEf2z+oftfWbSmdAnqQ/6JPUJen9A4Y4gwaLUXgq36MaPNT/ix5ofg15Dr9Gje1z3RqdQpsekt+n1hvI9J8kSyu3lDars1b/tFt3NXifVktogMNV/3Ra9pdWvsz1oNVqW9++CGK6IiCjk/EHK5XPBLbpR566DzWODR/TAI3ogyzJ0Wh2MWiMsegsSTYldfspTczYe2YjZ62c3WCRfaivF7PWzsezqZQEfdmVZRrWr+syH9bPWPBXVFcHutTf7vEmmpAYFGuqPBsQaYkP+Wrsag9aAXom90CuxV9D7W1Jy3it5cbz2OI7XHg96DZ1Gh/SYdGTFZwVdT5QRk9FglLi17zmf5EOZvUx9f52sPYn9x/fDXm5HsU0pU+6VvE32hb/gQ7DQ5H/fGXXGlnQrUUQwXBER0TkRJVEdjXL73KjzKEHKK3rVESmdRqeum0rUMEi1liiJePaLZ4NWH/Mfe6zwMXx5/Eucsp1SP4A7fc5mr51iSWmyyl1HGQXoyvRaPbLjs5Ednx30/rNDzdlh2h9q/PftwI4G19AIGjV8ZcVlISM2A+/ue7fJ99y8wnkoPFqoPk9L9hXTClpkxGY0nK53OvSlx6Zzs2+KagxXRBTAI3pQ566DVqOFQWuAXqPnmhdSiZKojka5fC7Uuetg99rh8XnU30jrNDoYdUYGqRDxiB58dPCjgGlZwdR56rDmuzUNjqfFpAUdAfB/b9KZ2qvpFCY6jQ6ZcZnIjMvExbi4wf2iJKLCUaEU27AGVmz0F+DwiB6csp3CKdsp7MTOFj2vzWPDhwc/DDhWf3pi99juMNYYMeS8IchOzFamJ8amQ6fhx0/qvPjuJiIASrWrKmcVyuxlsHvtECBAp9FBr9XDoDXAorPAYrDAoDWoocugNXBtTCfn8Djg8/rg9DpR56mD0+eE2+eGT/IBAtT3Qawxlr9tPkcu0YXvyr/D0dqjOFp9FIerDuNI9RGcqD3Rok1wAWBszlhc0fsKNThlxmXy50LQarRIj01Hemw6hncf3uB+SZZQ6ahU13mdtJ7ElhNbsPXk1mavfU3fa3BlzpVBC2uIPhGHth1C/wH9o3bvJaLWYrgi6sJkWYbVbUW5oxyVjkp4RA9iDDFIj0kHoEw18UpeuH1u2D12+Gw+5YECYNAYlBEKrTJCYdab1Q/a/kDGTV2jh1f0qqNRLq8L1Y5qAMDesr2QNcoUIP/PNd4Yz9HMc1DrqsWR6iPKV5Xy5+HKwyi2FQN7gz/GpDPB5XM1e+27ht7FBfTUahpBg9SYVKTGpGJYxjAAwND0oS0KV7ddcBvfc0T1MFwRdUE+yYcaVw3K7GWodlZDlmXEm+KRZA7cQ0ivPT0l8KzP0bIswyt54RW9cPgcqHXXQpIlAMp/0v4RL7PODIveApPOFBC69Bo9p4pFkFf0qlP7/CNSDq8DHp8HPskHQRCghfJb5gRTAowGLh5vLX9Jaf/okz9EHak60uTGucmmZPRN7os+yX3QN6kvcpNzkZuUi27mbhj79liU2kqDroHxFwEYkTmiPV8WdSEjMkcgIzaD7zmiVmK4IupC3D43ql3VKLGVoM5dB71Wj0RTYqtHIQRBUKcHnk2URHXEy79vkSwr/zFrBS10Wh30Gj0segti9DEw6AwBUw05IhJaHtGjFppweB2ocytT+zyiB5IsQYAAvVYPo84Ii9miroUQfSLKUc61Ec2QZRmnbKdwuOpwwFS+I1VHUOuubfRxGbEZ6Jt0JkT1TugNHAFGXDai0elT80fPx+z1syFACPiwK0BQ7+c0XQoVrUbL9xxRG3SI/zVfeeUV/P73v0dJSQmGDh2Kl19+GSNHjgx67uWXX47PPvuswfFrrrkG69atA6D8Z7dw4UK89tprqKmpwaWXXoo///nP6Ncv+OZ+RJ2dzWNDpaNS2ajS64RZbw664WQoNorUarTQarQwouFoh0/yKcFL9KLaVY0ye5l6n3+0Sw1ehpiAtV1cN9I0WZbhET3q1D7/prz+ESp/wDXqjMoaKUMsPxS1gk/y4aT1ZIMQdbT6aKObmgoQkJ2QjdykXOQm56ojUX2S+jQoXy76RBz66VCTbcjPzceyq5c12HMoPTa9TXsOETWH7zmi1ot4uFqzZg0KCgqwfPly5OXlYenSpZgwYQIOHjyItLS0BuevXbsWHo9HvV1ZWYmhQ4filltuUY+98MILWLZsGd58803k5OTg8ccfx4QJE7B//36YTKyKRF2DJEuoddWi3F6OKmcVvJIXsYZYpMemB52SF8qNIhuj0+ig0+iCVifzil5lqqHkRYWj4kw7BEAvKCNaelkZ1Sq1lcJsNHfZ9V3+IOXyueDyuZQRKU8dXD6XuoeUIAgwahmkWssjenCs5liDEPVj9Y+N7s+j0+jQO7F3gxDVO7F3yCvx5efmY2zO2HP+JQhRS/E9R9Q6EQ9XS5YswcyZMzFjxgwAwPLly7Fu3TqsXLkSjz76aIPzk5OTA26vXr0aFotFDVeyLGPp0qVYsGABbrjhBgDAW2+9hfT0dHz44Ye47bbb2vkVEUWWV/SixlWDUlspatw1AIAEY0KTmy62dqPI9qCu7zrL2eu7AOBo9VEIWgGCIKhTCU06E2L0MTDpTGrg6gzru2RZDthDyuaxweaxKUFKUoKUVlDK5pt0JsQb47tU0Gwrh9ehhqeWVuYz6Uzok9QHfZL6oG9yXzVM9YzvGdbprFqNlgUEKKz4niNquYiGK4/Hg127dmHevHnqMY1Gg3HjxmHr1uYr1ADAihUrcNtttyEmJgYA8OOPP6KkpATjxo1Tz0lISEBeXh62bt0aNFy53W643W71ttVqBQB4vV54vU3vJN5R+dsdre2PJh2lr11elxKqHKVweBzQaXVIMCQErKEJRpREPPP5M41uFClAwLOfP4vLsy+P2G8qtVCmGuq1epSiFMnGZGh1WkiyBJ+oTDOs9dSiQqqA/2VoBI26vssfvPzru9SRsA62vkuSJXh8HrglJUw5PMqIlEf0wCsq7y+NRqMEKY0JsYbYBkFKFmWIaFnZ7qb43y+NvW+iRa27FkerT5c2r1aC1JHqI0plvkbEGmKRm5SLPol9lAB1+iszLjN4cJXPvZ86S39HA/Z1+LCvw6cz9rUkShAEIeKfr4DWfcaLaLiqqKiAKIpIT08POJ6eno7vv/++2cfv2LED+/btw4oVK9RjJSUl6jXOvqb/vrMtXrwYixYtanB848aNsFiie2f6TZs2RboJXUZH7OtyNF6VzG9v3V6U2ksbvV+GjBJ7CT4s/BCD4waHsnltdmTnkUg3octo774WZRH7bftR7atGki4Jg2IHQSu0LsTLsoxaXy1OuE7ghPsETrpO4oRL+bPaV93o4xJ0Cehh7IFsUzZ6mJQ/s03ZSNIlnRntdAE4BThOOXAYh8/hlbYM39vhw74OH/Z1+HTGvj6BE5FuAhyO4Gtrg4n4tMBzsWLFCgwePLjR4hctNW/ePBQUFKi3rVYrsrOzkZ+fj/j4+HNtZkR4vV5s2rQJ48ePh17fsX4739lEoq9FSYTVY0W5vRw1rhqIkohYQyzMenOrr/XDDz8ALfi3eGnxUlzZ+0pcknUJ8rLykGxObv5BISb6RBzZeQS5I3LPaUNKn3i6sIasTDcUpdO/6RMAnXB642SNAWa9UkreP8pl0ChrvFo77U6URGWNlOiCx+eB1W2Fw3em9DmgTLsxaA0wao3QaXQRn8oYqr5uyqajm/DcV88FhPv0mHQ8duljGN9nfIPz/ZX5/IUkjlQfwdEaZUTK6rY2+jwZMRnok6SMQvn/zE3MbbD1QCSFo79Jwb4OH/a18u+/KIkQBKFd/23vjH1t89igFbQYnB75X+z6Z7W1RETDVUpKCrRaLUpLA39rXlpaioyMjCYfa7fbsXr1ajz11FMBx/2PKy0tRffu3QOuOWzYsKDXMhqNMBobrkfR6/VRH0w6w2uIFuHoa4/oQY2rBiW2EtS6aqERNEiwJJxTJb2U2JQWnVfprMT7B97H+wfeBwD079Yfo3qMwiU9LsHFmRcjzhjX5ja0llanPaf/PLS64NUM66/v8kge2N12iE4leAVb3+WvvFe/qqEkS2qFPpfPhTp3HexeOzw+j1oQQd2M1xDf4deEnWtfN2bjkY14aONDDaajltnL8NDGh7Dg5wuQEZvR5sp8uUm5yn5RQSrzdWTt1d/UEPs6fDpzX/v/3/BXw/VXxPXz7/0IGfD4POrU9fZaG9yZ+lojaqARNB3ic2xr2hDRcGUwGDB8+HAUFhZi0qRJAABJklBYWIhZs2Y1+dj3338fbrcbt99+e8DxnJwcZGRkoLCwUA1TVqsV27dvxwMPPNAeL4Oo3Tm8DlQ5qlBqL4XdY4dRZ0SKJeWc10DZPDa8/s3rTZ4jQEBaTBqeGPMEdhTtwLaT23Cw8iAOVR7CocpDeHP3m9AIGgxOG4xLelyCS3pcgou6XxTyKmnh0NT+XZIswSf54BE9qHPXodpZHbBxsl6rh06jUyv5eSWvuoeUQWtArDGW5eRPEyURz37xbKPr/ADg6c+fDvrYsyvz+UNUe1TmIyICAvdv9AcoURaVoHS6oq1/jW+cIQ4WveVMcDq9xYgkS+p2Gf7iRE6fE3aPHR6p/UMXhU/EpwUWFBTgrrvuwogRIzBy5EgsXboUdrtdrR545513IisrC4sXLw543IoVKzBp0iR069Yt4LggCHjooYfwzDPPoF+/fmop9szMTDXAEUUDWZZR56lDhb0C5Y5yuH1uxBobL6XeWsV1xbjv3/fhUOUh6DV6NQwE2yhywc8XYFyfcRjXRykUU+WswraT27Dt5DZsP7kdx2qPYXfpbuwu3Y2/7PoL9Bo9Lux+oRq2hqQN6XDFI1pLI2ia3DjZ/5+uIAiIN8ZH/ettD9XOauwt24uPf/g4oOR/Y3ol9MLg9MERrcxHRJ2fLMuBI0+nZzD4+Uef9Fq9MgVfZ1Yr0/pnNOg1+man/Z09dd8/Zdz/5fK5GoQuAQJkWWboiiIRD1dTpkxBeXk5nnjiCZSUlGDYsGHYsGGDWpDi+PHj0GgC1zccPHgQX375JTZu3Bj0mnPnzoXdbse9996LmpoaXHbZZdiwYQP3uKKoIEqiUvXPXqqOjsQb40O6PmRP6R48sO4BVDgqkGpJxavXvooSW0mLN4pMNifjmn7X4Jp+1wBQgtr2k9ux7eQ2bD25FaX2Uuwo2oEdRTuwbPsyWPQWjMgcgUuyLsGo7FEYmDKwU5UL92+cTGc4vU58V/4d9pXtw57SPdhTugcnrK1blDw7bzau639dO7WQiLqSoKNP0pnKenrNmdGnWEOsOvrkD07+70P5f5dWo4VZY24QuiRZgtvnbjJ0nT3SpZMj/pGeTusQP4lZs2Y1Og1w8+bNDY4NGDAAstxwOomfIAh46qmnGqzHIurI3D43ql3VKLWVwuq2QqfRIcF0buupgvnk8CeY++lcuHwu9O/WH3+57i/IjMvEkPQhbd4oMjMuE5PPm4zJ502GLMs4VnMM24q2qaNbNa4afP7T5/j8p88BAInGRIzMGqmMbGVfgj6JffhbuCjmk3z4ofIH7C3bqwapw1WHg+4X1TuhN7rHdcfWk81vt5FqSW2P5hJRJ9Sa0acYfQzMejPMOnOrR5/CQSNolPYFCV0e0aMGL7fPjTpPnRK6vHYAQLm9HIL2zJR0fzCM9GvqSjpEuCLqyuweO6qcynoqh9cBk84UkvVUZ5NlGa99/Rpe3PoiAGBMrzFYMmFJwGL/UGwUKQgCcpJykJOUg6kXTIUkSzhUeUgZ1TqxFTuKd6DGXYONRzdi41Fl9DnVkopLelyiFsjIis86pzZQ+5FlGSesJ9QQtbdsL/aX74fL52pwbqolFUPSh2Bw+mAMSRuCC9IuQIIpAaIk4sq3rkSprTTouisBAtJj0zEic0Q4XhIRRYmWjj7pBB1iTcFHn3QaXdTONNAIGph0pgbrSyVZgsPlQCEK0a9bP4gQ1dDl8DpQ465pMNLlD5SdaRZJR8FwRRQBkizB6raiwlGBSkclPKIHMYYYpMeEZj3V2TyiBws3L8TaA2sBAHcMuQOPXvaousFwe9IIGgxMGYiBKQMxfdh0eEUvviv/Tp1C+PWpr1HuKMdHhz7CR4c+AgBkx2erQSuvRx5SLC2raEihV+GowHeV36mjUvtK9yn/UZ8l1hCLwWmDMThtsBqoGns/azVazB89H7PXz250nd/80fOj9gMQEbVNsNEnn+RTZyvVH32y6CyB22V0sNGncNIIGhh1SgXcFEuKWtnOP9LlH+Vy+9ywe+2we+1weB3wur1q3zJ0hQ7DFVEY+SQfalw1KLOXocpZBchAvCm066nOVuOqwa/W/wo7inZAI2gwf/R83D7k9iYf4xE97bZgVq/VY1jGMAzLGIb7R9wPt8+Nb0q+wdaTW7H95HZ1bc6J/Sfw3v73AAD9kvvhkh6XYGT3kUjydZy9iTobm8eG78q+w56yPdhTsgffnPgG5d823Ihar9HjvNTzMCRNCVGD0wcjJzGnVf8Z5+fmY9nVy1q8zo+oLfwf1v0f0r2iF16vMlWs3FEOQSNAEAQIEKARNOq/eRpBE3BMgHKe//jZj/Efo+bVr7wabPRJp9EpAUqjDzr65P+Tv3xpXsBIV73dRxi62hfDFVEYuHwuVDurUWovRZ27DnqtHkmmpHavenas5hju+/d9OFZzDDH6GPzxqj9iTK8xTT6mzl0Hh88ByFArI7VnCXGjzqhWFQSUD/g7i3eq67UOVBzAD1U/4IeqH/D2nrehgQaDSgdhVPYotey7RW9pt/Z1Vh7Rg4MVB7GnTBmN2lO2B0eqjjSYpidAQG5yrjKtL/0CDEkbggEpA0LynsjPzW/zOj8iv2AByl+5U5blgEIFCcYEGAUjqlGNPol9oNFp1E1eRVn5kmQJkiypxyVIkCFDlETIsqxuwSDJEmRZhgwZEiR12pX/edVRWQGAjAYhDWh5iDv7WEdWf/TJ4/UAUIKsRquBLMscfeoAWhK6PKIHLq9LDVzBQld7FfqIdgxXRO3I5rGh0lGJMnsZnF4nzHozUmNSw/KP0P+K/odZH89CjbsGmXGZWH7tcgxIGdDkY9w+N5w+J/ol94NG0KDCUQGrywqP6IFZb0asIbbdP/jGGmJxee/LcXnvywEoZd/9+2ttO7kNP9b8iH3l+7CvfB9e+/o16DXKSJha9j19CPeTOoskS/ix5kfsLd2LvaV7sadsDw6UH1A3Na4vMy4Tg9MG44KUC5BYkYgJYyYgwZLQbm0LxTo/6vyaC1D+D+v+AGXWmWHUGRv81h0AvF4vvsE3SI9Nb9HGoP5AJUMODFSnvz/7vkZvS5Ia4PxhLliIkyQJXtkLGbLyXPWv0VSIq8cf1hoLccGOtSbE+UefvKJX/ZkEG33yP3/P+J4wGxsWj+AvUjqWxtZ0+fdvdItuhq4WYLgiCjFJllDrqkW5vRxVzip4JS9iDbHIiMsIWxs+/P5DLPjPAnglL4akD8Gr17yK1JimK6+JkohqVzV6JvRU18qkWlJh99qV1+MoR6WzErIsq2Vqw/FbxWRzMq7qexWu6nsVRJ+ILZ9vQUVGBXYU78DWk1txynYK/yv+H/5X/D+8vONlmHVmDM8crhbIOC/lvC73H3iprVQtOLGnbA/2le2DzWNrcF6iMVEZjUofoq6X8r9PRJ+IQ9sOBRQ8IWpPZwco/4f3tgSoUBIEAVqh/f8NqR+iWhPazr6vJSEOUP7Nr3+NxkIcgAYBLtjok1lvDvhQrdfoIYsyTuIksuKzWhRkqWMSBAFGnVFd1+V3dujyiB5l9ovXAafPiVp3bYPQ5f/72plDF8MVUYh4RS9qPDUotZWixl0DAcpmsmf/Y9SeJFnCS9tfwvKdywEAV/W9Cs+Pe77Bb6HOJssyKhwVSItJQ4/4HmpoEgQBsYZYJRzGZqDOU4dqZzUqncponE6jQ6whNqyvMcWQgp/1/xkmD1LKvh+vPa6Map0u/V7lrMKXx7/El8e/BADEG+OVsu+n99jKTcrtVFNNal21yl5SZXuUUanSPSh3NFwnZdKZMCh1kLpOakj6EGTHZ3eqvqCOr6MGqI4gnCGuLaHN/zj/eqiWjD4FGx2nziNo6Io7E7rqBy+bxwa7xw6XzwWr2xo0dHWW0UyGK6Jz5PIqJaj3V+yHU3RCr9Uj2Zwclkp8Ae3wufDop49i/eH1AID7h9+POZfMadFvh6qcVYgzxqFXQq9G263VaJFoSkSiKRFZ8VlqtcNaVy2qXdUw6UyINcSG9XULgoBeib3QK7EXplwwBZIs4YfKH7CtSCn7/r/i/8HqtuLTo5/i06OfAlAqKV2SpeyvdUmPS5Adnx229p4rl8+FA+UH1Mp9e0v34ljtsQbnaQUt+nXrp1buG5I+BH2T+4b9PUldU2MByq8rB6iOoH4xDqL2UD90xSFOPR4sdNk9dtg8Nrh8LtSJdeqaRp1GB1EWEauPvtkT/J+WqA1kWUadpw6VjkqU1pWqx9Ji0iIyElDhqMAv1/0Su0t3Q6/R46krnsKN593YosfaPDZoBA16J/ZusGFhYwxaA1IsKUixpMDhdcDqtqLMXoZqZzUkWUKMIQYWvSXs/3lrBA0GpAzAgJQBuGvoXfBJPuwv34+tJ7ZiW9E27CrehQpHBf79w7/x7x/+DQDIistSimNkKWXf02LSwtrmxoiSiCPVR9TpffvK9uFg5UH4JF+Dc3sm9FSD1AVpF2BQ6iAW+aB251/3VH8dlB8DFBGdrSWhyx+87B477B57szNvOiKGK6JWECURte5apZS6owqiLCJGGwNAKcQQiWB1qPIQ7v/3/SiqK0KCMQF/uuZPGJk1skWP9f/WqF+3fkg0Jbbp+S16Cyx6C9Ji0mDz2NRpg+WOcmigQawhtsWhLdR0Gp06cnPfiPvgET34tuRbbD25FdtObsOe0j0oqivCB/s/wAf7PwAA5CblqntsXZx1cYv6RZTEc6p4J8syiuqK1E1595buxXfl38HhdTQ4t5u5m7qPlH+dVHuW8qeu7VwDFCu+EVFzmlrTFWyj+Y6O4YqoBTyiRy2lXuuqhVajRbwpHgatAaJPbP4C7eSLn77AnA1zYPfa0TuhN5Zftxw5STkteqwoiahyVCE7IRvpMenn3BaNoEG8MR7xxnhkxmXC6rai0lGJGncNrG5rWMq6N8egNWBk1kiMzBqJOXlzYPfYsfOUUvZ9+8nt2F++H0eqj+BI9RG8s/cdCBAwKHWQWolwePfhiDHEBFxz45GNDfZqyojNaHKvpipnlVK5zz+9r2yvsu/ZWSx6Cy5IuyBgel/32O78sEoh1dIAFW+Mh0VnYYAiorDwT2GNNgxXRE1weB2oclSh1F4Ku8cOo86IFEtKh1hwuWrvKjzz+TMQZREXZ16Ml69+ucUjGP4CFikxKchOCH1RA71Wj26Wbuhm6Qan1wmr24pyezmsLit8sg8xemXaYKT7McYQgzG9xqh7f9W4agLKvh+pPoLvyr/Dd+XfYcU3K6DT6DA0fagatiocFSj4pKDBb9ZKbaWYvX42ll29DJf1vAz7y/er0/v2lu3FSevJBm3Ra/To362/GqIGpw1Gn6Q+Ee8j6hzaGqD81d8YoIiIWobhiugssiyrxRoqHBVw+9yINcYiPTa9Q3y4ECURv/vqd3hr91sAgMkDJ+OpK55q1YhQtasaMYYY9E7s3e5FDvwlev3TBmtdtShzlKHCUaFWIzTrzB2ibxNNicjPzVdHnEptpdhetF0NW0V1Rdh1ahd2ndqFV/73SqPX8Yethz95WNl4NMi0hpzEHDVEDUkfgoEpA8NadZE6HwYoIqLIY7giOs0n+VDrqkWpvRTVzmrIsow4Y1yHWs9i89jwyMZH8N9j/wUAFFxSgHuH39uqD0Q2jw2QlQ/34Sx6IAgC4oxxiDPGISMuA3XuM2XdrS4rDDpDxKcNni09Nh3XD7ge1w+4HrIs46T1JLad3IatJ7fii5++gNVjbfLx/uIT6THpSvnzNGVU6vy08xFvjA/HS6BG+MsAA2fCsP9YY7eDPf7sc9v6eP/0YqvbCsEntPjx9Quc+DduNWgNDFBERBHCcEVdntvnRrWrGiW2EtR56qATdEgwJXSoD/kAcKruFO5fdz++r/geRq0Rz49/Hlf3vbpV1/CIHti9duQm5kY0NOo0OiSZk5BkTkKWTynrXu5Qpg16RA/MejNiDbEdakqcIAjITshGdkI2bjn/Fnx08CM8sumRZh/3xM+fwP8N+b8wtDD6iJIIl88Ft+gOGGVpjH8vJP+Gpv7bwc45cwBokE0E/x9CvUNC4J+C0PCcs0JJU+ecfZ3ApxfUtQSCoHz5yw+btWZo9doGaw0CzseZ741aIww6g7r+iQGKiCiyGK6oy7J77OpmuHaPHRa9BSnmjrGe6mx7S/figXUPoNxRjhRLCl695lUMzRjaqmtIsoRKRyWy47OREZfRTi1tPaPOiFRdqlrWvcZVgwpHBSqdlZBlGTGGGMToYzrch8WWlmzvm9y3nVsSHWRZhlfyKmHK54YkS9AIGph0JiQYExBvjG8ymDQWelpyTlOPa805TT1XSx7XVFDzer34CT/hvLTzoNezRDkRUbRiuKIuRZIltbhCpaMSHsmDWEMsMmIzOtyHd7+NRzbiN5t+A5fPhf7J/bH8uuXIis9q9XXK7Uowy07I7pCbRwqCoAQpQwwyYjNQ51GmDVY5lYIiOo0OMZqY5i8UJiMyRyAjNgOlttKg07YECEiPTceIzBERaF3kBRuVMmgNMOlM6BbXDbGGWJh0Jpj1Zm5uTEREnQb/R6MuwSf5UO2sVja6dVVDgIB4YzySdcmRblqjZFnG3775G/6w5Q8AgNE9R2PpVUsRa2j9buXVzjMFLKJh406tRotEUyISTYnIis9SC4xU26sBALXuWsQJcRF9LVqNFvNHz8fs9bPVaWp+/hGK+aPnd8iR0FBrblQqwaTsgWTSmWDSmTrsLzKIiIjOFcMVdWounwvVzmqcsp2CzWODQWtAsjm5w/+m3CN6sOizRerGtrcPvh3zRs9rU7vtHjskWULvxN4N9miKBgatASmWFKRYUmC1WFGGMpi0JtS4aiBBUsu6R2I0Lj83H8uuXtZgn6v02PQm97mKdqIkwi264fK54JVOj0ppzoxKxRhi1DAVDWGeiIgoVDr2J0yiVpJlGQ6vAw6vA7XuWlQ7q+HwOhBjiEFaTFqHnA53tlpXLX61/lfYXrQdGkGDxy57DHcMvaNN1/KIHtg8NvRJ6oNkc8cdpWsps94MADgv9Ty4Zbe6PqvcXg6NoFHKup8+J1zyc/MxNmcsdhbvRLmjHKmWVIzIHNFpRqxkWYZH9KijUqIkQqvRwqgzclSKiIjoLAxXFPXcPjccXgdsHhuqnFVwep3wSB7oNDpY9BZ0N3WPdBNb7Kean3Dfv+/DjzU/wqK3YOmEpRjTe0ybriXJEqqcVciMy0T3uOjpg5bQCBrEG+IRb4xH99juqPPUocpZhSpnFWrdtTBow1vWXavRIq9HXlieq735R6UcbgcAoMJRAaPBCIPWgMy4TI5KERERNYHhiqKOKIlweB2we+2odlbD5rHB5XMBAEw6E2KNHWuvpJbaWbwTD378IGpcNege2x3Lr1uOgSkD23y9CnsFkk3J6JnQMypG7NpKr9Uj2ZyMZHMyXD4Xal21qHBUwOq2wif5YNabEaOP6TQjSaHmET1w+5Qpfv61UkadEXGGOJSjHANTByLOFMdRKSIiohZguKIOT5ZluHwu2L12ZeNZVzWcXickWYJeq4dZZw4o4xyN/nnwn5hfOB9eyYvBaYPx6rWvtrjUdzA1rhqY9Cb0TuodlUGzrUw6E0yxJqTFpMHmsaHWVYsyRxkqHBUQICDWGAuzzhzV75VzEbBWql4FP4PWgO6x3RFrPF3BT2cGJOAojiLJlMTS4ERERC3EcEUdklf0wu61w+5RRqfsXjs8ogeCIMCityDJnNThi1K0hCzLWLZjGV7936sAgAm5E/D8uOfPad2Qw+uAV/RiYMrANlUW7AwEQUCcMQ5xxjh0j+sOq9uKamc1Kp2VsLqsMOjCO20wUs4elRIEASadCfHGeCQYE2DWm2HWmWHUGRuMbvoLVRAREVHLRf+nU+oUJFmC0+uE3WtHjbMGdZ46OH1OyLIMo86oBqrOxO1zY17hPKz7YR0A4N6L7sXDox4+pyl8XtGLOncdchJz0M3SLVRNjWpajRZJ5iQkmZOQ5VPKupc7ymF1WeGVvDDpTIgxxER9WPePSrl9bnhEDwBAr9HDqDMiIzYDccY4dVSKa6WIiIjaR3R/mqCo5va5YffaYfPY1Kp+PskHrUYLs86MFEtKp10rVOmoxIMfP4hvSr6BTqPDU5c/hZsG3XRO15RkCZWOSnSP697pCliEilFnRKouFSmWFDi8DljdVpTZy1DlrIIsy8omxvqYqJg26B+VcotKBT//qFScMQ7xhnhYDBa1gl9n/XtERETU0TBcUdiIkgi71w6H14EqZxVsHhvcohuQlRLbcca4Tj9NCwB+qPwB9/37PhTVFSHBmIBlVy/DJT0uOefrVjgqkGhORM+Enize0AxBEJQgdbpEv81jQ7WrGpWOSpTZy6DVaBFrUNYfdQSSLKml0M8elUqPSVdL0Jt0pi7xd4iIiKijYriidiPLMpw+pzJC4LKixl0Dp9cJURJh0Blg1pmRYEyIilGCUPny+JeYs2EObB4beib0xF+u+wv6JPU55+vWumph1BqRk5gDo84YgpZ2HVqNFgkmZb+mzLhMWN1WVDoqUeOqQY2zBkadEbGG2LBOpas/KuWTfEoFP62Ro1JEREQdHMMVhZRH9Ch7TrmVkQCH1wG3z61M9dObkWxO7rKjKu/uexdPf/Y0RFnEiMwRePnql0Oysa/T64RbdGNAtwGIM8aFoKVdl0FrQIolJWDaYLm9HDWuGkiyBIveghhDTEgDjSRLatEJj+iBDBkGjYGjUkRERFGI4YrOiSRLyp5THjtqXbWweqxwep2AABi1RsQYYjpdIYrWEiURL3z1At7Y/QYAYNKASXj6yqdD8kHZJ/lQ66pFTlIOUiwp53w9OsOit8CitwSUdS93lKPcXg6NoFFDT2t5RA88ogcunyvoqJRZb1bDFEeliIiIogvDFbWay+eCw+sI2HPKK3qVPaf0ZqTGpPJD4Wl2jx2/3vhr/PfYfwEAD13yEO4ffn9IpkLKsoxKRyUyYjOQGZfZpaZXhpNG0CDeGI94Y7xa1r3KWYUqZxVq3bUwaBsv6372qBSgrJUy6AwclSIiIuqEGK6oWT7Jp45OVbuqlUIUPjcECDDplT1zWNq5oRJbCe7/9/04UHEABq0Bz497Htf0uyZk169wVCDeGI9eib267FTLcNNpdEg2JyPZnAyXzwWr24oKRwVqXbXwST6Y9WZoBA1cPpdawc+oVdZsqftKcVSKiIio02K4ogb8hSjsHjusbitq3bVweB2QZRl6rR4WvaXLFaJorX1l+/DAugdQZi9DN3M3vHrtqxiWMSxk17e6rdBr9chJYgGLSPEXlEi1pMLutavTBiVZQlpMGuIMp/eV0ps5KkVERNRFMFwRAGUdiN1jh91jR5WrCg6PA17JC42ggVlvRjdzN46OtNCnRz/FIxsfgdPnRL/kflh+3XL0iO8Rsuu7fC64fC7079Yf8cb4kF2X2kYQBMQaYhFriEVGbAYEQeCoFBERURfFcNVFSbIEu0fZc8o/1c/pdQJQfiMfawy+hoQaJ8syVn6zEi989QJkyLgs+zIsvWppSCv4+SQfalw16JXQC6mW1JBdl0KDv4AgIiLq2hiuuhCXzwW7x446Tx2qnUohClEWodPoWIjiHPlkH578/Em8f+B9AMDUC6Ziwc8XQKcJ3V8xfwGLtJg0ZMVncVomERERUQfDcNXJWd1WeFweVLuqUeeuUyuWWfQWJJgSWIgiBKxuK5468hT22PZAgIB5o+fhziF3hjz8VDmrEGeMQ+/E3iENbUREREQUGvyE1onIsgyH1wGH14EqexUA4Lvy7yBoBBi0Bpj1ZiSaEjniEUInak/g3o/uxVHbUZh1ZiyZsARX5lwZ8uexeWzQCBrkJObApDOF/PpEREREdO4YrqKc2+eGw+uAzWNDtasaDo8DHskDjaxM70s2JcNg4Nqp9rDr1C48uO5BVLuq0U3fDX+94a+4IOOCkD+P2+eG3WNH/279kWBKCPn1iYiIiCg0GK6ijCiJyp5TXjtqXDWoc9fB5XMBCCxEIfpEVKKSC+zbyUcHP8K8wnnwSl6cn3o+fp32a5yXcl7In0eURFQ5q9ArsRfSYtJCfn0iIiIiCh2Gqyjg9rlh89hgdVtR7aqGy+uCT/bBoDXApFM28eVUv/CQZRmv/O8VvLzjZQDAuD7j8LsrfoeTu062y3NVOCuQFpOGHvE9+DMmIiIi6uAiXhrulVdeQe/evWEymZCXl4cdO3Y0eX5NTQ0efPBBdO/eHUajEf3798fHH3+s3v/kk09CEISAr4EDB7b3y2hXR6uP4rvy71BUVwRZlpFoTkRGbAaSzcmw6C380B0mbp8bj2x6RA1W91x0D16++mVY9JZ2eb5qVzVi9bEsYEFEREQUJSL6iW3NmjUoKCjA8uXLkZeXh6VLl2LChAk4ePAg0tIaToHyeDwYP3480tLS8MEHHyArKws//fQTEhMTA847//zz8emnn6q3dbro/mAqSiLMOjPX20RQlbMKv1z3S3xT8g10Gh2eHPMkbjn/FgCACDHkz2fz2AAZyEnKgVlvDvn1iYiIiCj0Ipo6lixZgpkzZ2LGjBkAgOXLl2PdunVYuXIlHn300Qbnr1y5ElVVVdiyZQv0eqWEeO/evRucp9PpkJGR0a5tp67jSNUR3Pvve3HSehJxhji8fPXLGJU9qt2ezyN6YPfY0a9bPySaEtvteYiIiIgotCIWrjweD3bt2oV58+apxzQaDcaNG4etW7cGfcy//vUvjBo1Cg8++CD++c9/IjU1FdOmTcNvf/tbaLVnCjf88MMPyMzMhMlkwqhRo7B48WL07Nmz0ba43W643W71ttVqBQB4vV54vd5zfannTPJJkEQJoq/lIyT+c1vzGGpoy8kteHjjw6jz1CE7Pht/vvrP6JPUJ6BfQ9nXoiSi0lGJzLhMJBuSO8T7ryPx9wf7pf2xr8OL/R0+7OvwYV+HD/u6fbWmXwVZluV2bEujiouLkZWVhS1btmDUqDOjAHPnzsVnn32G7du3N3jMwIEDcezYMfzf//0ffvnLX+Lw4cP45S9/idmzZ2PhwoUAgPXr18Nms2HAgAE4deoUFi1ahKKiIuzbtw9xcXFB2/Lkk09i0aJFDY6vWrUKFkv7rKehjm9j5UYsP7EcEiScF3Me5uXMQ7wuPtLNIiIiIqIwcjgcmDZtGmpraxEf3/RnwagKV/3794fL5cKPP/6ojlQtWbIEv//973Hq1Kmgz1NTU4NevXphyZIluPvuu4OeE2zkKjs7GxUVFc12YDgcKDsAp+hEvLHlbRF9Io7sPILcEbnQ6liOvTVEScSS7Uvw+u7XAQDX9bsOz1z+DAza4PuFhaqvq13VMGgN6J/cn+usGuH1erFp0yaMHz9enRpM7YN9HV7s7/BhX4cP+zp82Nfty2q1IiUlpUXhKmLTAlNSUqDValFaWhpwvLS0tNH1Ut27d4derw+YAnjeeeehpKQEHo8n6Ga5iYmJ6N+/Pw4fPtxoW4xGI4xGY4Pjer2+Q7xBNToNNNC06YO7VqdluGoFh9eBRzY9gsIfCwEAvxr5Kzx48YMtqsh4Ln1t99ghaAT06dYH8ebIB/qOrqP83ewK2Nfhxf4OH/Z1+LCvw4d93T5a06cRK8VuMBgwfPhwFBYWqsckSUJhYWHASFZ9l156KQ4fPgxJktRjhw4dQvfu3YMGKwCw2Ww4cuQIunfvHtoXQJ1Oqa0Ut6+9HYU/FsKgNWBJ/hLMGjmr3Uvde0QPbB4beiX0QrI5uV2fi4iIiIjaT0T3uSooKMBrr72GN998EwcOHMADDzwAu92uVg+88847AwpePPDAA6iqqsKcOXNw6NAhrFu3Ds899xwefPBB9ZxHHnkEn332GY4dO4YtW7Zg8uTJ0Gq1mDp1athfH0WP/eX7ccv7t+C78u+QbE7GW5PewrX9r23355VkCVXOKmTFZSEjjhUuiYiIiKJZREuxT5kyBeXl5XjiiSdQUlKCYcOGYcOGDUhPTwcAHD9+HBrNmfyXnZ2NTz75BA8//DCGDBmCrKwszJkzB7/97W/Vc06ePImpU6eisrISqampuOyyy7Bt2zakpqaG/fVRdPjPj//Brzf+Gg6vA32T+2L5dcuRHZ8dlucut5ejm7kbshOyoREivqc3EREREZ2DiO+uO2vWLMyaNSvofZs3b25wbNSoUdi2bVuj11u9enWomkadnCzLeHP3m/jdl7+DDBmXZl+Kl656CXHG4FUlQ63aWQ2L3oLeib2h13J+NBEREVG0i3i4IooEr+jFM188g9X7lDA+5fwpePznj4ct5Di8DoiSiL7JfRFjiAnLcxIRERFR+2K4oi7H6rbioQ0P4asTX0GAgEcvexR3Db2r3QtX+HlED6xuK3KTctHN0i0sz0lERERE7Y/hirqUE9YTuO+j+3Ck+ggsegv+kP8HjM0ZG7bnl2QJlY5KZMVnoXscK1gSERERdSYMV9QpiZKIncU7Ue4oR6olFSMyR2B36W48+PGDqHJWIT0mHcuvW45BqYPC2q5KRyW6mbuhZ0JPFrAgIiIi6mQYrqjT2XhkI5794lmU2ErUYwnGBNi9dvgkHwalDsLya5cjPTY9rO2qcdXAqDOid1JvGLTB92UjIiIioujFcEWdysYjGzF7/WzIkAOO17prAQCD0wbjrclvwaK3hLVdTq8TXtGLASkDEGuIDetzExEREVF4cF4SdRqiJOLZL55tEKzqK3eUw6g1hrFVSmXCWlcteiX0QoolJazPTUREREThw5GrDkyURHxx/AvsOLkD8cZ4jOk9BlqNNtLNiiiP6IHNY4Pda4fD44Dda4fdY4fda8e+sn0BUwGDKbGVYGfxTuT1yAtLe2VZRqWjEhmxGSxgQURERNTJMVx1UGsPrMWcDXNw0npSPZYRm4H5o+cjPzc/gi1rOVmW4RE9AQGo/vdqODp9zOF1BJwX7H6v5D3ndpU7ykPw6lqmwlGBRHMieiX26vLBmIiIiKizY7jqgNYeWIub37u5wfS2UlspZq+fjWVXL2uXgCXLMtyi+0z48TrUUSI1/NQPR/XDUCP3+yRfyNsJACadCTH6GFj0FsQYYhCjj4FX8mJP6Z5mH5tqSW2XNp3N6rbCoDUgJzEHRl14pyISERERUfgxXHUwoiRizoY5QdcNyZAhQMCzXzyLsTljoRE0cPlcQcNNnasORyuPYtuebXCIjhaHI1EW2+V1mXVmxBhOhyF9jBqI6oejYPcHfH/6foveAp2m4VtXlERc+daVKLWVBu0/AQLSY9MxInNEu7zG+lw+F1w+FwZ0G4A4Y1y7Px8RERERRR7DVQfzxfEvAqYCnk2GjBJbCS7660XwiB5IstT0BU+0rR3+kBMQfvQxsBgsAaGnqXAUq49Vw1A4psRpNVrMHz0fs9fPhgAhIGAJEAAA80fPb/e2+CQfapw16J3UmwUsiIiIiLoQhqsO5lTdqRad5/K5Am6rocYfcnQWyHYZaWlpiDXEBh81Oiso+f8068xRuz4oPzcfy65e1mCfq/TY9LCsV5NlGRWOCqTHpiMrLguCILTr8xERERFRx8Fw1cG0tKLc8+Oex6geo9TQpBECq+qLPhGHth1C/0v6Q6uLzqDUVvm5+RibMxY7i3ei3FGOVEsqRmSOCEtgrHRWIsGYwAIWRERERF0Qw1UHM7rnaPSI74Eia1GT64Ym9p/ID+9N0Gq0YSu37mfz2KAVtMhJyoFJZwrrcxMRERFR5HET4Q5Gq9HipateAnBmnZBfONcNUes5fU7kJOUg3hgf6aYQERERUQQwXHVAN553Iz649QNkxWcFHE+PTW+3MuzUdv5y8z3ieoStzDsRERERdTycFngORFGE13vum9oGc03ONZhw3wTsOrULe0r2INYQi4uzLoZG0ED0NF8uXRIl6HQ6SF4JaKagIJ2bGlsNdDodkg3JcLvdkW5OSOj1emi1HB0lIiIiag2GqzaQZRklJSWoqalp9+dKRSpGJ4yGLMsQq0SIaPk+VBkZGRBrWvcYah1JlhCPeFgyLCg+WdypqgMmJiYiIyOjU70mIiIiovbEcNUG/mCVlpYGi8XS7h8+XV4XJFlq1TorWZbhcXpgMBv44bidiJIIGTIMWgOcdidiY2Oh0UT/TFtZluFwOFBWVgYA6N69ZRUsiYiIiLo6hqtWEkVRDVbdunULy3PKWrlN4QoiYDQZGa7agSzL8Ek+mHQmaAUtRK8Ik8nUKcIVAJjNZgBAWVkZ0tLSOEWQiIiIqAU6xyfBMPKvsbJYLBFuCUWKP1gZtAboNJ339xP+93h7rSskIiIi6mwYrtqIo0FdlKxUB9RpdDBoO/eUy8782oiIiIjaA8MVUSv4ZB80gqbTBysiIiIiaj2GqwgRRWDzZuDdd5U/xSgs6Deg7wC8/NLLLT7/888+h1lvDkuVxfYgSsoPyagzchNnIiIiImqA4SoC1q4FevcGrrgCmDZN+bN3b+V4ezDrzU1+PfPUM2267pdbv8TdM+9u8fmXjLoEP574EQkJCW16vrYYesFQJMQkoKSk5JyuI8tKUZHOvs6KiIiIiNqO4SrM1q4Fbr4ZOHky8HhRkXK8PQLWjyd+VL9+/+LvER8fH3DsoYKH1HNlWYbP52vRdVNTU1tV2MNgMIR136SvvvwKTqcTk2+cjHfefqfN16lfwEKv0bf5OiwMQURERNS5MVyFgCwDdnvzX1YrMHu2cn6wawDAnDnKeS25XrDrBJORkaF+JSQkQBAE9fahg4eQmpSKTzZ8gp+N/BkSYhKw5astOHrkKG658Rb0yuqFlMQUXHrJpfhP4X8Crnv2tECz3ozXV7yOW2++FcnxybjgvAvw74/+rd5/9rTAt998GxkpGdi0cROGDR6GlMQUXH/t9Th16pT6GJ/Ph4KHCpCRkoGs9CzMnzcf98y4B7fcdEuzr/vN19/ElNumYNrt0/DWG281uP/kyZO48/Y7kZmWiW4J3XBp3qXYsX2Hev+6f6/DpZdciqS4JORk5WDKLVPUYCgIAj788MOA6yUnJ+ONN94AABw7dgyCIGDNmjUYM2YMTCYT/t//+3+orKzE1KlTkZWVBYvFgsGDB+Pdd98NuI4kSXjhhRfQt29fGI1G9OzZE88++ywA4Morr8SsWbMCzi8vL4fBYEBhYWGzfUJERERE7YfhKgQcDiA2tvmvhARlhKoxsqyMaCUkBD4uNcmM9OQYpCSaAr4cjtC9hscfexxPP/c0vt37LS4YfAFsNhsmXDUBH3/yMbb9bxvyJ+Tjpkk34fjx401e59lnnsVNN9+E/339P0y4agJm3DkDVVVVjZ7vcDiwdMlSrHh9BTb9ZxNOnDiBeXPnqfe/+PsXsebdNfjL3/6C/3z2H9RZ6/DRvz5q9vXU1dVh7d/XYuq0qRg7biystVZ8+eWX6v02mw35Y/NRXFSM99e+jx27duDhRx6GJEkAgPUfr8eUm6cg/6p8fLX9K2zctBF5I/Oafd6zPfroo5gzZw4OHDiACRMmwOVyYfjw4Vi3bh327duHe++9F3fccQd27DgT6ubNm4ff/e53ePzxx7F//36sWrUK6enpAIB77rkHq1atgtvtVs9/5513kJWVhSuvvLLV7SMiIiKi0OHiEQIAPP7k4xg7bqx6Ozk5GUOGDlFvL1y0EP/657+w7qN1eODBBxq9zh133oEpt00BADz1zFN49U+vYuf/diJ/Qn7Q871eL15+5WX0ye0DALj/gfux+NnF6v1/fuXPeOS3j+CGSTcAAP647I/YsGFDs6/n/TXvo2/fvhh0/iAAwM233ow3V76Jyy67DACw5t01qCivwJdbv0RycjIAILdvrvr45xc/j5tvvRnzn5gPk84EnUaHiy68qNnnPdtDDz2EG2+8MeDYI488on7/q1/9Cp988gnee+89jBw5EnV1dXjppZfwpz/9CXfddZfSrtxctd033ngjZs2ahX/+85+49dZbAQBvvPEGpk+fzuqFRERERBHGkasQsFgAm635r48/btn1Pv448HHl1U6UVtlRUeMK+ArlPsYXDQ8MDjabDY/OfRTDBg9DRkoGUhJT8P2B73HixIkmr3PB4AvU72NiYhAfH4/ysvJGz7dYLGqwAoCM7hkoKysDANTW1qK0tBQXX3yxer9Wq8WFF13Y7Ot58403cdv/3abenjptKtb+fS3q6uoAAHt278HQYUPVYHW2Pbv3YMzlY865gMWIESMCbouiiKeffhqDBw9GcnIyYmNj8cknn6gjggcOHIDb7cbYsWODXQ4mkwl33HEHVq5cCQD4+uuvsW/fPkyfPr3NbSQiIiKi0ODIVQgIAhAT0/x5+flAjx7K1MBg66UEQbk/Px/Q1qv0rfECkgxo2zEKx5z1AubNnYfCwkIsfn4xcnNzYTabMW3KNHg8niavo9cHFnwQBEGdatfS8+WWLiZrxIH9B7Bj+w7s/N9OLJi3QD0uiiLeX/M+fnHPL2Aymxp9vCzLMJlN0Gq0jRawCNbOYAUrzu7X3//+93jppZewdOlSDB48GDExMXjooYfUfjWbzc2+vnvuuQfDhg3DyZMn8frrr+PKK69Er169mn0cEREREbUvjlyFkVYLvPSS8v3ZM7j8t5cuDQxWkbJ1y1bccecduGHSDbhg8AVIz0jHTz/9FNY2JCQkID09HTt37lSPiaKIb7/5tsnHvfH6G7hs9GXYsWsHtu/crn7Nfmg23nj9DQDA4MGDsWf3nqDrwXySD4MHD8Znmz9rdKpdampqQOGNI0eOwNGCRXBfffUVbrjhBtx+++0YOnQo+vTpg0OHDqn39+vXD2azucniFIMHD8aIESPw2muvYdWqVfjFL37R7PMSERERUftjuAqzG28EPvgAyMoKPN6jh3L8rOU5EZPbLxf//Mc/sfvb3dizew+m3zG9yRGo9vLAgw/gD8//AR/96yMcOngIv37416iprmk09Hi9Xrz7/97FrVNuxfkXnB/wNeMXM/C/Hf/D/u/249bbbkV6RjpuvelWbPlqC348+iP+sfYf2LJlCzSCBk888QRWv7saCxcuxIEDB7B37148//zz6vNceeWV+NOf/oRvvvkGO3fuREFBQYNRuGD69euHTZs2YcuWLThw4ADuu+8+lJaWqvebTCb89re/xdy5c/HWW2/hyJEj2LZtG1asWBFwnXvuuQe/+93vIMsyJk+e3MbeJSIiIqJQYriKgBtvBI4dA/77X2DVKuXPH3/sOMEKAF74/QtITErEFT+/AjdNvgnjxo/DsAuHhb0dv/7Nr3HLlFtwz4x7cPnoyxEbG4tx+eNgMgWf1vfvj/6NyspKXD/p+gb3DTxvIAaeNxBvvP4GDAYDPvr4I6SmpWLy9ZMx4sIR+MMLf4BGo4Hx/7d353FRlfsfwD9nZmDYF5E9FhUUF8AEF/SmlhaKkUsaGiqGee8tUUwt9Lph5XKzTM2ye0uxLPcUNVzCHdHUVFTuNUDD5XpBckFEBIaZ5/cHP851BAV1GJY+79drXnLOeeac53w9OPP1ec73KNXo9UIvbNiwAVu3bkX79u3xwgsv6FX0++STT+Dh4YHnnnsOw4cPR0xMTI2e+TV9+nR06NABoaGh6NmzJ1xcXDBgwAC9NjNmzMCkSZMwc+ZMtG7dGhEREfJ9aBWGDRsGlUqFYcOGPTQWRERERGRcknjaG1waoYKCAtja2uL27duwsbHR21ZcXIzs7Gw0a9bMaF9q72nuQSu0UErKGleEE0Kg5G4J1JbqRlVFTqfTob1/e7w6+FXMmj3LYPuteFCwWqmGqcr0sftUUFAAGxsbKBTG+f+KixcvokWLFjh+/Dg6dHj8KoY1URfXenU0Gg22b9+OsLCwGo0U0pNjrI2L8TYextp4GGvjYaxr16NygwexoEUDoJAU0AkdtDotBMpzYUmSIEGCJElQQAE0nvxJz6VLl7AneQ+e6/4cSkpK8OUXX+Ji9kW53LshVCRWJkoTmCjr9z9IGo0GN27cwPTp09GlS5daS6yIiIiI6PExuWoA1Co1TIQJhBAQQkAHHXQ6HXSi/KUVWrmtnGw1EgqFAqu+XYWpcVMhhECbtm2wfdd2+LX2M9gxtDotlAolTJWm9X6ULzU1Fc8//zxatmyJjRs31nV3iIiIiOg+TK4aCIX0wOiUsnzERUBAJ3TlSZf4X8JVMduzTFemN8pV8WdD4eHhgX0H99Xa/rU6LSRJglqpLo9xPdezZ8+nLlVPRERERLWDyVUDVpEsPZgUCCGg1WlRiEKoleryka77ErAHpxYqJAUkSI12auHDVCSiZqryZ1oRERERET0NJleNkCT9L+FSKVRQKBTyKJecYP3/n1qhhVZo9UZDFJKiQY5yPY6KBFStVEOl4K8BERERET29Op8H9fnnn8Pb2xtmZmbo3LmzXrnrquTn52Ps2LFwdXWFWq1Gy5YtsX379qfa5x9BRcKlVChhojSBqcoUZiZmsDCxgIXKAuYm5jBTmcFUaQqFVJ6MaYUWGq0GGq0GZboyaHVavSmHDZYony5poigvYNFYE0giIiIiMq46Ta7WrVuHiRMnYtasWTh58iQCAwMRGhpa6Zk+FUpLS/Hiiy/i4sWL2LhxIzIyMvDVV1/B/b4n8j7uPv/oJEmCQqGASqGCidIEapUa5ibmsDCxgLnKHOYm5lCrykd3JEmSK+s9mHQJIYAGknOV6crKC1io6n8BCyIiIiJqOOp0PtTChQsxZswYvPHGGwCAL7/8EklJSVixYgWmTJlSqf2KFStw8+ZNHD58WK7h7+3t/VT7BICSkhKUlJTIywUFBQDKy15rNBq9thqNpnxKna68Yl99VTG6VNHXJ/H/EwP1imlUTC2sKKSh0+mgg36ZePm99XBqoU6Ux8JUYQqI/y0/DUPEuj7S6cpHKTUaDZTK+nFPWsXv44O/l2R4jLVxMd7Gw1gbD2NtPIx17XqcuNbZQ4RLS0thYWGBjRs3YsCAAfL6qKgo5OfnY8uWLZXeExYWhiZNmsDCwgJbtmyBo6MjXn/9dcTFxUGpVD7RPgEgPj4es2fPrrR+9erVsLCw0FunUqng4uICDw8PmJo+3sNmiRqS0tJSXLlyBbm5uSgrK6vr7hARERHViaKiIrz++uv1+yHC169fh1arhbOzs956Z2dn/Prrr1W+57fffsPevXsRGRmJ7du34/z583j77beh0Wgwa9asJ9onAEydOhUTJ06UlwsKCuDh4YGXXnqpUgCLi4tx5coVWFlZwczM7HFPW6bVaZFyOQU5hTlwtXLFc57PGbRinRACd+7cgbW1tcFGjl544QUEBgbi008/BQA0b94csbGxiI2NrboPEFApVdjwwwa88sor0Ir/3bP1uKNcFqYWWLthLV7p/8oT9b3iHjJThanBHxRcG7GuD4qLi2Fubo7u3bs/1bVuSBqNBsnJyXjxxRf5BPpaxlgbF+NtPIy18TDWxsNY166KWW010aDKpOl0Ojg5OeGf//wnlEolgoKCcPXqVSxYsACzZs164v2q1Wqo1epK601MTCpdoFqtVr5PSaF4slvWNp3bhNidsfhPwX/kdc/YPIPFfRZjUOtBT7TPB1VMT5MkCf3794dGo8HOnTsrtUtJSUH37t1x+vRpBAQEVLvfinMHgOPHj8PS0rLaOKgUKpiqykf5qqpaWJF06aDDnNlzkLQtCYePHS5PuP4/6cq+kg17e/snS14EUCbK5H5Ut4979+7B3d0dCoUCV69erfLauN/9sX7Sa6I+UijKq0ZW9XtQ1+pjnxorxtq4GG/jYayNh7E2Hsa6djxOTOvsm2DTpk2hVCpx7do1vfXXrl2Di4tLle9xdXVFy5Yt9e7/aN26NXJzc1FaWvpE+zS2Tec2YfD6wXqJFQBcLbiKwesHY9O5TQY/5ujRo5GcnIz//Oc/lbYlJCQgODi4RonVgxwdHStNm6xOVVUL7y+gUVG9r+LPipLpDo4OUKgUelULa1pAo0yUF7BQq9Q1Ss5++OEHtG3bFn5+fkhMTHys8zM0IQSn5BERERE1EHWWXJmamiIoKAh79uyR1+l0OuzZswchISFVvqdbt244f/68XtGAzMxMuLq6wtTU9In2aQhCCNwtvVvtq6C4AON3jNebEifv4//Xxe6IRUFxQY32V9Pb5V5++WU4Ojpi5cqVeusLCwuxYcMGjB49Gjdu3MCwYcPg7u4OCwsL+Pv7Y82aNY/cr7e3NxYtWiQvZ2VlyVPI2rRpg+Tk5ErviYuLQ8uWLWFhYYHmzZtjxowZ0Gg0kCQJq75dhQ/e/wBnTp+BmYkZLE0tse77dTA3MYeNmQ12Ju2ESiofbD179ixCXwyFvbU93Jzd8NZf3kJBQYEckzHRYzDk1SFY+PFC+Hj5wMPFA+NixtXohsTly5dj+PDhGD58OJYvX15p+7/+9S+8/PLLsLGxgbW1NXr06IHs7Gx5+4oVK9C2bVuo1Wq4uroiJiYGAHDx4kVIkoS0tDS5bX5+PiRJwv79+wEA+/fvhyRJ2LFjB4KCgqBWq3Ho0CFcuHAB/fv3h7OzM6ysrNCxY0fs3r1br18lJSWIi4uDh4cH1Go1fHx8sHz5cggh4OPjg48//livfVpaGiRJwvnz56uNCRERERFVr06nBU6cOBFRUVEIDg5Gp06dsGjRIty9e1eu9Ddy5Ei4u7tj3rx5AIC33noLS5cuRWxsLMaNG4esrCzMnTsX48ePr/E+a0ORpghW86yeej8CAv+58x/Y/t22Ru0LpxbC0tSy2nYqlQojR47EypUrMW3aNHn0ZsOGDdBqtRg2bBgKCwsRFBSEuLg42NjYICkpCSNGjECLFi3QqVOnao+h0+kwaNAgODs74+jRo7h9+zYmTJhQqZ21tTVWrlwJNzc3nD17FmPGjIG1tTXee+89REREID09HTt37pQTB1tbW/leNBOFCcxMzFBYWIiBLw9Ely5dcPjnw7iWdw1v/eUtTJwwEV9+/SWErnzK4cH9B+Hs7Izk3cm4lH0JERERaN++PcaMGfPQ87hw4QKOHDmCTZs2QQiBd955B5cuXYKXlxcA4OrVq+jevTt69uyJvXv3wsbGBikpKfLo0rJlyzBx4kTMnz8fffv2xe3bt5Gamlpt/B40ZcoUfPzxx2jevDns7e1x5coVhIWFYc6cOVCr1fj2228RHh6OjIwMeHp6Aij/fTly5AiWLFmCwMBAZGdn4/r165AkCdHR0UhISMDkyZPlYyQkJKB79+7w8fF57P4RERERUWV1mlxFRETg999/x8yZM5Gbm4v27dtj586dckGKy5cv693D4uHhgV27duGdd95BQEAA3N3dERsbi7i4uBrv848qOjoaCxYswIEDB9CzZ08A5V+uX331Vdja2sLW1lbvi/e4ceOwa9curF+/vkbJ1e7du/Hrr79i165dcHNzAwDMnTsXffv21Ws3ffp0+Wdvb29MnjwZa9euxXvvvQdzc3NYWVnJFRkfZs2aNSguLsaqVatgaVmeXH6+9HOEh4fjo79/BCdnJygVStjZ2+GzpZ/BzMQM/m390a9fP+zZs+eRydWKFSvQt29f2NvbAwBCQ0ORkJCA+Pj48uN8/jlsbW2xdu1aef6tj4+PfKPjhx9+iEmTJukV+ejYsWO18XvQ+++/jxdffFFebtKkCQIDA+XlDz74AJs3b8bWrVsRExODzMxMrF+/HsnJyejduzeA8oIjFUaNGoWZM2fi2LFj6NSpEzQaDVavXl1pNIuIiIiInlydF7SIiYmRp009qGKq1P1CQkLw888/P/E+a4OFiQUKpxZW2+7gpYMIWx1Wbbvtr29Hd6/uNTpuTfn5+aFr165YsWIFevbsifPnzyMlJQXvv/8+gPJCHXPnzsX69etx9epVlJaWoqSkpMb3VJ07dw4eHh5yYgWgyqmY69atw5IlS3DhwgUUFhairKys2pKWVR0rMDBQTqyA8imjOp0O57POw83VDQpJgXZt28Hc1Fxu4+rqirNnzz50v1qtFt988w0WL14srxs+fDgmT56MmTNnQqFQIC0tDc8991yVNzbm5eXhv//9L3r16vVY51OV4OBgveXCwkLEx8cjKSkJOTk5KCsrw71793D58mUA5VP8lEolevToUeX+3Nzc0K9fP6xYsQKdOnXCtm3bUFJSgiFDhjx1X4mIiIioXOMpbVaHJEmCpallta+XWryEZ2yegYSqiypIkOBh44GXWrxUo/09buW80aNH44cffsCdO3eQkJCAFi1ayF/GFyxYgMWLFyMuLg779u1DWloaQkNDUVpa+tTxqXDkyBFERkYiLCwMP/74I06dOoVp06YZ9Bj3ezABkiTpkQ/53bVrF65evYqIiAioVCqoVCoMHToUly5dku/jMzc3f+j7H7UNgDwKe/+9cg+7B+z+xBEAJk+ejM2bN2Pu3LlISUlBWloa/P395dhVd2wAePPNN7F27Vrcu3cPCQkJiIiIeOyCJERERET0cEyujEipUGJxn/JRkQcTrIrlRX0WGfR5V/d77bXXoFAosHr1anz77beIjo6WE7TU1FT0798fw4cPR2BgIJo3b47MzMwa77t169a4cuUKcnJy5HUPjjAePnwYXl5emDZtGoKDg+Hr64tLly7ptTE1NYVWq632WKdPn8bdu3fldampqVAoFGjVqlWN+/yg5cuXY+jQoUhLS9N7DR06VC5sERAQgJSUlCqTImtra3h7e+sVVLmfo6MjAOjF6P7iFo+SmpqKUaNGYeDAgfD394eLiwsuXrwob/f394dOp8OBAwceuo+wsDBYWlpi2bJl2LlzJ6Kjo2t0bCIiIiKqGSZXRjao9SBsfG0j3G3c9dY/Y/MMNr620WDPuaqKlZUVIiIiMHXqVOTk5GDUqFHyNl9fXyQnJ+Pw4cM4d+4c/vKXv1Qqaf8ovXv3RsuWLREVFYXTp08jJSUF06ZN02vj6+uLy5cvY+3atbhw4QKWLFmCzZs367Xx9vZGdnY20tLScP36dZSUlFQ6VmRkJMzMzBAVFYX09HTs27cP48aNw4gRI5743rrff/8d27ZtQ1RUFNq1a6f3GjlyJBITE3Hz5k3ExMSgoKAAQ4cOxS+//IKsrCysWrUKWVlZAID4+Hh88sknWLJkCbKysnDy5El89tlnAMpHl7p06YL58+fj3LlzOHDggN49aI/i6+uLTZs2IS0tDadPn8brr7+uNwrn7e2NqKgoREdHIzExEdnZ2di/fz/Wr18vt1EqlRg1ahSmTp0KX1/fWq2gSURERPRHxOSqDgxqPQgXYy9iX9Q+rB60Gvui9iE7NrtWE6sKo0ePxq1btxAaGqp3f9T06dPRoUMHhIaGomfPnnBxccGAAQNqvF+FQoHNmzfj3r176NSpE958803MmTNHr80rr7yCd955BzExMWjfvj0OHz6MGTNm6LV59dVX0adPHzz//PNwdHSsshy8hYUFdu3ahZs3b6Jjx44YPHgwevXqhaVLlz5eMO7z7bffwtLSssr7pXr16gVzc3N89913cHBwwN69e1FYWIgePXogKCgIy5cvl6cgRkVFYdGiRfjiiy/Qtm1bvPzyy3LiBZQXzCgrK0NQUBAmTJiADz/8sEb9W7hwIezt7dG1a1eEh4cjNDQUHTp00GuzbNkyDB48GG+//Tb8/PwwZswYvdE9oPzvv7S0tFarZxIRERH9UUmipg9L+gMpKCiAra0tbt++XanYQnFxMbKzs9GsWTOYmZnVUQ+rp9PpUFBQABsbG72Ki2R4DSnWKSkp6NWrF65cuVLtKF99vNY1Gg22b9+OsLAwPoG+ljHWxsV4Gw9jbTyMtfEw1rXrUbnBg+q8WiAR1b6SkhL8/vvviI+Px5AhQ/7wjyYgIiIiqg31+7/Zicgg1qxZAy8vL+Tn5+Ojjz6q6+4QERERNUpMroj+AEaNGgWtVosTJ07A3d29+jcQERER0WNjckVERERERGQATK6eEOuAUGPHa5yIiIjo8TC5ekwVFViKiorquCdEtaviGmfVISIiIqKaYbXAx6RUKmFnZ4e8vDwA5c9ckiSpjntVmU6nQ2lpKYqLi+t9efCGrrHFWgiBoqIi5OXlwc7ODkqlsq67RERERNQgMLl6Ai4uLgAgJ1j1kRAC9+7dg7m5eb1M/hqTxhprOzs7+VonIiIiouoxuXoCkiTB1dUVTk5O0Gg0dd2dKmk0Ghw8eBDdu3fntK5a1hhjbWJiwhErIiIiosfE5OopKJXKevsFVKlUoqysDGZmZo3mC399xVgTEREREcCCFkRERERERAbB5IqIiIiIiMgAmFwREREREREZAO+5qkLFw1MLCgrquCdPTqPRoKioCAUFBbwPqJYx1sbDWBsPY21cjLfxMNbGw1gbD2Nduypygooc4VGYXFXhzp07AAAPD4867gkREREREdUHd+7cga2t7SPbSKImKdgfjE6nw3//+19YW1s32OcWFRQUwMPDA1euXIGNjU1dd6dRY6yNh7E2HsbauBhv42GsjYexNh7GunYJIXDnzh24ublBoXj0XVUcuaqCQqHAM888U9fdMAgbGxv+khkJY208jLXxMNbGxXgbD2NtPIy18TDWtae6EasKLGhBRERERERkAEyuiIiIiIiIDIDJVSOlVqsxa9YsqNXquu5Ko8dYGw9jbTyMtXEx3sbDWBsPY208jHX9wYIWREREREREBsCRKyIiIiIiIgNgckVERERERGQATK6IiIiIiIgMgMkVERERERGRATC5akAOHjyI8PBwuLm5QZIkJCYm6m0XQmDmzJlwdXWFubk5evfujaysLL02N2/eRGRkJGxsbGBnZ4fRo0ejsLDQiGfRMMybNw8dO3aEtbU1nJycMGDAAGRkZOi1KS4uxtixY+Hg4AArKyu8+uqruHbtml6by5cvo1+/frCwsICTkxPeffddlJWVGfNU6r1ly5YhICBAfvBhSEgIduzYIW9nnGvP/PnzIUkSJkyYIK9jvA0jPj4ekiTpvfz8/OTtjLNhXb16FcOHD4eDgwPMzc3h7++PX375Rd7Oz0fD8fb2rnRtS5KEsWPHAuC1bUharRYzZsxAs2bNYG5ujhYtWuCDDz7A/bXoeG3XQ4IajO3bt4tp06aJTZs2CQBi8+bNetvnz58vbG1tRWJiojh9+rR45ZVXRLNmzcS9e/fkNn369BGBgYHi559/FikpKcLHx0cMGzbMyGdS/4WGhoqEhASRnp4u0tLSRFhYmPD09BSFhYVym7/+9a/Cw8ND7NmzR/zyyy+iS5cuomvXrvL2srIy0a5dO9G7d29x6tQpsX37dtG0aVMxderUujilemvr1q0iKSlJZGZmioyMDPG3v/1NmJiYiPT0dCEE41xbjh07Jry9vUVAQICIjY2V1zPehjFr1izRtm1bkZOTI79+//13eTvjbDg3b94UXl5eYtSoUeLo0aPit99+E7t27RLnz5+X2/Dz0XDy8vL0ruvk5GQBQOzbt08IwWvbkObMmSMcHBzEjz/+KLKzs8WGDRuElZWVWLx4sdyG13b9w+SqgXowudLpdMLFxUUsWLBAXpefny/UarVYs2aNEEKIf//73wKAOH78uNxmx44dQpIkcfXqVaP1vSHKy8sTAMSBAweEEOWxNTExERs2bJDbnDt3TgAQR44cEUKUJ8MKhULk5ubKbZYtWyZsbGxESUmJcU+ggbG3txdff/0141xL7ty5I3x9fUVycrLo0aOHnFwx3oYza9YsERgYWOU2xtmw4uLixJ/+9KeHbufnY+2KjY0VLVq0EDqdjte2gfXr109ER0frrRs0aJCIjIwUQvDarq84LbCRyM7ORm5uLnr37i2vs7W1RefOnXHkyBEAwJEjR2BnZ4fg4GC5Te/evaFQKHD06FGj97khuX37NgCgSZMmAIATJ05Ao9HoxdvPzw+enp568fb394ezs7PcJjQ0FAUFBfjXv/5lxN43HFqtFmvXrsXdu3cREhLCONeSsWPHol+/fnpxBXhdG1pWVhbc3NzQvHlzREZG4vLlywAYZ0PbunUrgoODMWTIEDg5OeHZZ5/FV199JW/n52PtKS0txXfffYfo6GhIksRr28C6du2KPXv2IDMzEwBw+vRpHDp0CH379gXAa7u+UtV1B8gwcnNzAUDvH6uK5Yptubm5cHJy0tuuUqnQpEkTuQ1VptPpMGHCBHTr1g3t2rUDUB5LU1NT2NnZ6bV9MN5V/X1UbKP/OXv2LEJCQlBcXAwrKyts3rwZbdq0QVpaGuNsYGvXrsXJkydx/PjxStt4XRtO586dsXLlSrRq1Qo5OTmYPXs2nnvuOaSnpzPOBvbbb79h2bJlmDhxIv72t7/h+PHjGD9+PExNTREVFcXPx1qUmJiI/Px8jBo1CgD/DTG0KVOmoKCgAH5+flAqldBqtZgzZw4iIyMB8LtffcXkiqgaY8eORXp6Og4dOlTXXWm0WrVqhbS0NNy+fRsbN25EVFQUDhw4UNfdanSuXLmC2NhYJCcnw8zMrK6706hV/M8yAAQEBKBz587w8vLC+vXrYW5uXoc9a3x0Oh2Cg4Mxd+5cAMCzzz6L9PR0fPnll4iKiqrj3jVuy5cvR9++feHm5lbXXWmU1q9fj++//x6rV69G27ZtkZaWhgkTJsDNzY3Xdj3GaYGNhIuLCwBUqshz7do1eZuLiwvy8vL0tpeVleHmzZtyG9IXExODH3/8Efv27cMzzzwjr3dxcUFpaSny8/P12j8Y76r+Piq20f+YmprCx8cHQUFBmDdvHgIDA7F48WLG2cBOnDiBvLw8dOjQASqVCiqVCgcOHMCSJUugUqng7OzMeNcSOzs7tGzZEufPn+d1bWCurq5o06aN3rrWrVvL0zD5+Vg7Ll26hN27d+PNN9+U1/HaNqx3330XU6ZMwdChQ+Hv748RI0bgnXfewbx58wDw2q6vmFw1Es2aNYOLiwv27NkjrysoKMDRo0cREhICAAgJCUF+fj5OnDght9m7dy90Oh06d+5s9D7XZ0IIxMTEYPPmzdi7dy+aNWumtz0oKAgmJiZ68c7IyMDly5f14n327Fm9f9SSk5NhY2NT6YsA6dPpdCgpKWGcDaxXr144e/Ys0tLS5FdwcDAiIyPlnxnv2lFYWIgLFy7A1dWV17WBdevWrdKjMjIzM+Hl5QWAn4+1JSEhAU5OTujXr5+8jte2YRUVFUGh0P+qrlQqodPpAPDarrfquqIG1dydO3fEqVOnxKlTpwQAsXDhQnHq1Clx6dIlIUR5OU47OzuxZcsWcebMGdG/f/8qy3E+++yz4ujRo+LQoUPC19eX5Tir8NZbbwlbW1uxf/9+vZKzRUVFcpu//vWvwtPTU+zdu1f88ssvIiQkRISEhMjbK8rNvvTSSyItLU3s3LlTODo6stzsA6ZMmSIOHDggsrOzxZkzZ8SUKVOEJEnip59+EkIwzrXt/mqBQjDehjJp0iSxf/9+kZ2dLVJTU0Xv3r1F06ZNRV5enhCCcTakY8eOCZVKJebMmSOysrLE999/LywsLMR3330nt+Hno2FptVrh6ekp4uLiKm3jtW04UVFRwt3dXS7FvmnTJtG0aVPx3nvvyW14bdc/TK4akH379gkAlV5RUVFCiPKSnDNmzBDOzs5CrVaLXr16iYyMDL193LhxQwwbNkxYWVkJGxsb8cYbb4g7d+7UwdnUb1XFGYBISEiQ29y7d0+8/fbbwt7eXlhYWIiBAweKnJwcvf1cvHhR9O3bV5ibm4umTZuKSZMmCY1GY+Szqd+io6OFl5eXMDU1FY6OjqJXr15yYiUE41zbHkyuGG/DiIiIEK6ursLU1FS4u7uLiIgIvecuMc6GtW3bNtGuXTuhVquFn5+f+Oc//6m3nZ+PhrVr1y4BoFIMheC1bUgFBQUiNjZWeHp6CjMzM9G8eXMxbdo0vZL1vLbrH0mI+x7zTERERERERE+E91wREREREREZAJMrIiIiIiIiA2ByRUREREREZABMroiIiIiIiAyAyRUREREREZEBMLkiIiIiIiIyACZXREREREREBsDkioiIiIiIyACYXBERUZ3w9vbGokWLatx+//79kCQJ+fn5tdanxmDlypWws7Or624QEf0hMbkiIqJHkiTpka/4+Pgn2u/x48fx5z//ucbtu3btipycHNja2j7R8WqqIomr6pWbm1urxyYiooZNVdcdICKi+i0nJ0f+ed26dZg5cyYyMjLkdVZWVvLPQghotVqoVNV/vDg6Oj5WP0xNTeHi4vJY73kaGRkZsLGx0Vvn5ORktOMTEVHDw5ErIiJ6JBcXF/lla2sLSZLk5V9//RXW1tbYsWMHgoKCoFarcejQIVy4cAH9+/eHs7MzrKys0LFjR+zevVtvvw9OC5QkCV9//TUGDhwICwsL+Pr6YuvWrfL2B6cFVkx/27VrF1q3bg0rKyv06dNHLxksKyvD+PHjYWdnBwcHB8TFxSEqKgoDBgyo9rydnJz0zt3FxQUKhQLFxcVo27at3qjbhQsXYG1tjRUrVgAAbty4gWHDhsHd3R0WFhbw9/fHmjVr9Pbfs2dPjBs3DhMmTIC9vT2cnZ3x1Vdf4e7du3jjjTdgbW0NHx8f7Nixo1IMkpKSEBAQADMzM3Tp0gXp6emPPJctW7agQ4cOMDMzQ/PmzTF79myUlZUBKE+I4+Pj4enpCbVaDTc3N4wfP77a+BARUWVMroiI6KlNmTIF8+fPx7lz5xAQEIDCwkKEhYVhz549OHXqFPr06YPw8HBcvnz5kfuZPXs2XnvtNZw5cwZhYWGIjIzEzZs3H9q+qKgIH3/8MVatWoWDBw/i8uXLmDx5srz973//O77//nskJCQgNTUVBQUFSExMfKpzNTMzw/fff49vvvkGW7ZsgVarxfDhw/Hiiy8iOjoaAFBcXIygoCAkJSUhPT0df/7znzFixAgcO3ZMb1/ffPMNmjZtimPHjmHcuHF46623MGTIEHTt2hUnT57ESy+9hBEjRqCoqEjvfe+++y4++eQTHD9+HI6OjggPD4dGo6myvykpKRg5ciRiY2Px73//G//4xz+wcuVKzJkzBwDwww8/4NNPP8U//vEPZGVlITExEf7+/k8VIyKiPyxBRERUQwkJCcLW1lZe3rdvnwAgEhMTq31v27ZtxWeffSYve3l5iU8//VReBiCmT58uLxcWFgoAYseOHXrHunXrltwXAOL8+fPyez7//HPh7OwsLzs7O4sFCxbIy2VlZcLT01P079//of2sOI6lpaXeq02bNnrtPvroI9G0aVMRExMjXF1dxfXr1x95/v369ROTJk2Sl3v06CH+9Kc/6fXN0tJSjBgxQl6Xk5MjAIgjR47o9W3t2rVymxs3bghzc3Oxbt06OS73/x316tVLzJ07V68vq1atEq6urkIIIT755BPRsmVLUVpa+sj+ExFR9XjPFRERPbXg4GC95cLCQsTHxyMpKQk5OTkoKyvDvXv3qh25CggIkH+2tLSEjY0N8vLyHtrewsICLVq0kJddXV3l9rdv38a1a9fQqVMnebtSqURQUBB0Ol2155SSkgJra2t52cTERG/7pEmTkJiYiKVLl2LHjh1wcHCQt2m1WsydOxfr16/H1atXUVpaipKSElhYWDz0fJVKJRwcHPRGjZydnQGgUgxCQkLkn5s0aYJWrVrh3LlzVZ7H6dOnkZqaKo9UVfSvuLgYRUVFGDJkCBYtWoTmzZujT58+CAsLQ3h4eI3umyMiIn38l5OIiJ6apaWl3vLkyZORnJyMjz/+GD4+PjA3N8fgwYNRWlr6yP08mMBIkvTIRKiq9kKIx+x91Zo1a/bIkuZ5eXnIzMyEUqlEVlYW+vTpI29bsGABFi9ejEWLFsHf3x+WlpaYMGFCpfOvqv/3r5MkCQBqlAw+TGFhIWbPno1BgwZV2mZmZgYPDw9kZGRg9+7dSE5Oxttvv40FCxbgwIEDlfpHRESPxuSKiIgMLjU1FaNGjcLAgQMBlH/Bv3jxolH7YGtrC2dnZxw/fhzdu3cHUD5ic/LkSbRv3/6p9x8dHQ1/f3+MHj0aY8aMQe/evdG6dWsA5effv39/DB8+HEB5cpSZmYk2bdo89XEB4Oeff4anpycA4NatW8jMzJSP/aAOHTogIyMDPj4+D92fubk5wsPDER4ejrFjx8LPzw9nz55Fhw4dDNJfIqI/CiZXRERkcL6+vti0aRPCw8MhSRJmzJjxVKMvT2rcuHGYN28efHx84Ofnh88++wy3bt2SR4QeJS8vD8XFxXrrHBwcYGJigs8//xxHjhzBmTNn4OHhgaSkJERGRuLnn3+GqakpfH19sXHjRhw+fBj29vZYuHAhrl27ZrDk6v3334eDgwOcnZ0xbdo0NG3a9KEVEGfOnImXX34Znp6eGDx4MBQKBU6fPo309HR8+OGHWLlyJbRaLTp37gwLCwt89913MDc3h5eXl0H6SkT0R8JqgUREZHALFy6Evb09unbtivDwcISGhtbJKEhcXByGDRuGkSNHIiQkBFZWVggNDYWZmVm1723VqhVcXV31XidOnMCvv/6Kd999F1988QU8PDwAAF988QWuX7+OGTNmAACmT5+ODh06IDQ0FD179oSLi0uNyr/X1Pz58xEbG4ugoCDk5uZi27ZtMDU1rbJtaGgofvzxR/z000/o2LEjunTpgk8//VROnuzs7PDVV1+hW7duCAgIwO7du7Ft2za9e8iIiKhmJGGoyelERET1nE6nQ+vWrfHaa6/hgw8+qOvuPLb9+/fj+eefx61btx55PxgREdUNTgskIqJG69KlS/jpp5/Qo0cPlJSUYOnSpcjOzsbrr79e110jIqJGiNMCiYio0VIoFFi5ciU6duyIbt264ezZs9i9e/dDiz8QERE9DU4LJCIiIiIiMgCOXBERERERERkAkysiIiIiIiIDYHJFRERERERkAEyuiIiIiIiIDIDJFRERERERkQEwuSIiIiIiIjIAJldEREREREQGwOSKiIiIiIjIAP4P2zJges9+v5UAAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"code","source":"# feature_importances = best_clf.feature_importances_\n\n# #  store and display feature importances\n# importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n\n# # Sort by importance in descending order\n# importance_df = importance_df.sort_values(by='Importance', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:22.429646Z","iopub.execute_input":"2023-10-02T17:13:22.430060Z","iopub.status.idle":"2023-10-02T17:13:22.435691Z","shell.execute_reply.started":"2023-10-02T17:13:22.430020Z","shell.execute_reply":"2023-10-02T17:13:22.434461Z"},"trusted":true},"execution_count":736,"outputs":[]},{"cell_type":"code","source":"# importance_df","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:22.438653Z","iopub.execute_input":"2023-10-02T17:13:22.438984Z","iopub.status.idle":"2023-10-02T17:13:22.449002Z","shell.execute_reply.started":"2023-10-02T17:13:22.438957Z","shell.execute_reply":"2023-10-02T17:13:22.447689Z"},"trusted":true},"execution_count":737,"outputs":[]},{"cell_type":"code","source":"# perm_importance = permutation_importance(best_clf, X_test, y_test, n_repeats=30, random_state=42)\n\n# # Visualize the feature importances\n# sorted_idx = perm_importance.importances_mean.argsort()[::-1]\n# plt.figure(figsize=(10, 6))\n# plt.bar(range(X_test.shape[1]), perm_importance.importances_mean[sorted_idx])\n# plt.xticks(range(X_test.shape[1]), sorted_idx)\n# plt.xlabel(\"Feature Index\")\n# plt.ylabel(\"Permutation Importance\")\n# plt.title(\"Permutation Feature Importance\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:22.452763Z","iopub.execute_input":"2023-10-02T17:13:22.453141Z","iopub.status.idle":"2023-10-02T17:13:22.461979Z","shell.execute_reply.started":"2023-10-02T17:13:22.453110Z","shell.execute_reply":"2023-10-02T17:13:22.461119Z"},"trusted":true},"execution_count":738,"outputs":[]},{"cell_type":"code","source":"best_clf.fit(X ,y)\ntrialll = best_clf.predict(tt)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:22.463011Z","iopub.execute_input":"2023-10-02T17:13:22.463894Z","iopub.status.idle":"2023-10-02T17:13:26.534327Z","shell.execute_reply.started":"2023-10-02T17:13:22.463832Z","shell.execute_reply":"2023-10-02T17:13:26.533136Z"},"trusted":true},"execution_count":739,"outputs":[{"name":"stdout","text":"[LightGBM] [Warning] bagging_fraction is set=0.7860507745938736, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7860507745938736\n","output_type":"stream"}]},{"cell_type":"code","source":"# final = best_clf.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.536230Z","iopub.execute_input":"2023-10-02T17:13:26.536627Z","iopub.status.idle":"2023-10-02T17:13:26.541512Z","shell.execute_reply.started":"2023-10-02T17:13:26.536585Z","shell.execute_reply":"2023-10-02T17:13:26.540314Z"},"trusted":true},"execution_count":740,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': test['id'], 'outcome': trialll})\nsubmission['outcome'] = submission['outcome'].map({1:'died',0:'euthanized',2:'lived'})\nsubmission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.543207Z","iopub.execute_input":"2023-10-02T17:13:26.543605Z","iopub.status.idle":"2023-10-02T17:13:26.558542Z","shell.execute_reply.started":"2023-10-02T17:13:26.543560Z","shell.execute_reply":"2023-10-02T17:13:26.557756Z"},"trusted":true},"execution_count":741,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGB","metadata":{}},{"cell_type":"code","source":"# from hyperopt import fmin, tpe, hp\n# from sklearn.model_selection import train_test_split, cross_val_score\n# from mlxtend.feature_selection import PermutationImportance","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.560085Z","iopub.execute_input":"2023-10-02T17:13:26.560668Z","iopub.status.idle":"2023-10-02T17:13:26.567419Z","shell.execute_reply.started":"2023-10-02T17:13:26.560640Z","shell.execute_reply":"2023-10-02T17:13:26.566219Z"},"trusted":true},"execution_count":742,"outputs":[]},{"cell_type":"code","source":"\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n# space = {\n#     'n_estimators': hp.choice('n_estimators', range(100, 1000)),\n#     'max_depth': hp.choice('max_depth', range(1, 20)),\n#     'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n#     'subsample': hp.uniform('subsample', 0.5, 1),\n#     'min_child_weight': hp.choice('min_child_weight', range(1, 10)),\n# }\n\n\n# def objective(params):\n#     model = xgb.XGBClassifier(\n#         n_estimators=params['n_estimators'],\n#         max_depth=params['max_depth'],\n#         learning_rate=params['learning_rate'],\n#         subsample=params['subsample'],\n#         min_child_weight=params['min_child_weight'],\n#         random_state=42,\n#         tree_method='gpu_hist',  # Use GPU acceleration\n#         gpu_id=0,  # Specify GPU device ID\n#     )\n#     score = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n#     return -score  \n\n# # Hyperparameter tuning with hyperopt\n# best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50, rstate=np.random.seed(42))\n\n\n# model = xgb.XGBClassifier(\n#     n_estimators=best['n_estimators'],\n#     max_depth=best['max_depth'],\n#     learning_rate=best['learning_rate'],\n#     subsample=best['subsample'],\n#     min_child_weight=best['min_child_weight'],\n#     random_state=42,\n#     tree_method='gpu_hist', \n#     gpu_id=0,  \n# )\n\n\n# model.fit(X_train, y_train)\n\n\n# y_pred = model.predict(X_test)\n\n\n# accuracy = accuracy_score(y_test, y_pred)\n# print(\"Accuracy:\", accuracy)\n\n\n# train_sizes, train_scores, test_scores = learning_curve(\n#     model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n# train_mean = np.mean(train_scores, axis=1)\n# train_std = np.std(train_scores, axis=1)\n# test_mean = np.mean(test_scores, axis=1)\n# test_std = np.std(test_scores, axis=1)\n\n# plt.figure(figsize=(10, 6))\n# plt.plot(train_sizes, train_mean, label='Training Accuracy', marker='o', linestyle='-')\n# plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15)\n# plt.plot(train_sizes, test_mean, label='Validation Accuracy', marker='o', linestyle='-')\n# plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15)\n# plt.xlabel('Number of Training Samples')\n# plt.ylabel('Accuracy')\n# plt.legend()\n# plt.grid()\n# plt.title('Learning Curve')\n# plt.show()\n\n\n# plt.figure(figsize=(10, 6))\n# xgb.plot_importance(model, importance_type='weight', xlabel='Weight')\n# plt.title('Feature Importance (Weight)')\n# plt.show()\n\n\n# permuter = PermutationImportance(model, scoring='accuracy', n_iter=10, random_state=42)\n# permuter.fit(X_test, y_test)\n# feature_names = X_test.columns.tolist()\n# perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n# # Get feature importances\n# perm_importance_scores = perm_importance.importances_mean\n\n# # Plot permutation feature importance\n# plt.figure(figsize=(10, 6))\n# plt.barh(feature_names, perm_importance_scores)\n# plt.xlabel('Permutation Importance (Accuracy)')\n# plt.title('Permutation Feature Importance')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.568761Z","iopub.execute_input":"2023-10-02T17:13:26.569114Z","iopub.status.idle":"2023-10-02T17:13:26.581573Z","shell.execute_reply.started":"2023-10-02T17:13:26.569087Z","shell.execute_reply":"2023-10-02T17:13:26.580557Z"},"trusted":true},"execution_count":743,"outputs":[]},{"cell_type":"code","source":"# resultss=model.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.582957Z","iopub.execute_input":"2023-10-02T17:13:26.583572Z","iopub.status.idle":"2023-10-02T17:13:26.597554Z","shell.execute_reply.started":"2023-10-02T17:13:26.583543Z","shell.execute_reply":"2023-10-02T17:13:26.596750Z"},"trusted":true},"execution_count":744,"outputs":[]},{"cell_type":"code","source":"# submission = pd.DataFrame({'id': test['id'], 'outcome': resultss})\n# submission['outcome'] = submission['outcome'].map({1:'died',0:'euthanized',2:'lived'})\n# submission.to_csv('xgbb.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.598792Z","iopub.execute_input":"2023-10-02T17:13:26.599385Z","iopub.status.idle":"2023-10-02T17:13:26.610965Z","shell.execute_reply.started":"2023-10-02T17:13:26.599348Z","shell.execute_reply":"2023-10-02T17:13:26.610114Z"},"trusted":true},"execution_count":745,"outputs":[]},{"cell_type":"markdown","source":"#  scikit learn HistGradientBoostingClassifier ","metadata":{}},{"cell_type":"code","source":"# from sklearn.experimental import enable_hist_gradient_boosting\n# from sklearn.ensemble import HistGradientBoostingClassifier\n# # Step 1: Import the necessary libraries\n\n# # Step 2: Split your data into training and testing sets\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# # Step 3: Define the objective function for Optuna\n# def objective(trial):\n#     params = {\n#         'max_iter': trial.suggest_categorical('max_iter', [100, 200, 300]),\n#         'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n#         'max_depth': trial.suggest_categorical('max_depth', [3, 4, 5]),\n#         'min_samples_leaf': trial.suggest_categorical('min_samples_leaf', [1, 2, 4]),\n#     }\n    \n#     clf = HistGradientBoostingClassifier(random_state=42, **params)\n#     clf.fit(X_train, y_train)\n    \n#     y_pred = clf.predict(X_test)\n#     accuracy = accuracy_score(y_test, y_pred)\n    \n#     return accuracy\n\n# # Step 4: Create and run the Optuna study\n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=100)  # You can adjust the number of trials\n\n# # Step 5: Get the best hyperparameters and create the best model\n# best_params = study.best_params\n# best_model = HistGradientBoostingClassifier(random_state=42, **best_params)\n\n# # Step 6: Fit the best model on the full training data\n# best_model.fit(X_train, y_train)\n\n# # Step 7: Calculate and print the accuracy on the test set\n# y_pred = best_model.predict(X_test)\n# accuracy = accuracy_score(y_test, y_pred)\n# print(\"Best Hyperparameters:\", best_params)\n# print(\"Accuracy on Test Set:\", accuracy)\n\n# # Step 8: Plot the learning curve\n# def plot_learning_curve(estimator, X, y, title=None, ylim=None, cv=None,\n#                         n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n#     plt.figure()\n#     if title is not None:\n#         plt.title(title)\n#     if ylim is not None:\n#         plt.ylim(*ylim)\n#     plt.xlabel(\"Training examples\")\n#     plt.ylabel(\"Score\")\n\n#     train_sizes, train_scores, test_scores = learning_curve(\n#         estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='accuracy')\n    \n#     train_scores_mean = np.mean(train_scores, axis=1)\n#     train_scores_std = np.std(train_scores, axis=1)\n#     test_scores_mean = np.mean(test_scores, axis=1)\n#     test_scores_std = np.std(test_scores, axis=1)\n\n#     plt.grid()\n\n#     plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n#                      train_scores_mean + train_scores_std, alpha=0.1,\n#                      color=\"r\")\n#     plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n#                      test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n#     plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n#              label=\"Training score\")\n#     plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n#              label=\"Cross-validation score\")\n\n#     plt.legend(loc=\"best\")\n#     return plt\n\n# plot_learning_curve(best_model, X_train, y_train, cv=3)\n# plt.show()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-10-02T17:13:26.612362Z","iopub.execute_input":"2023-10-02T17:13:26.612828Z","iopub.status.idle":"2023-10-02T17:13:26.626148Z","shell.execute_reply.started":"2023-10-02T17:13:26.612788Z","shell.execute_reply":"2023-10-02T17:13:26.625281Z"},"trusted":true},"execution_count":746,"outputs":[]},{"cell_type":"code","source":"# resultssss = best_model.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.627353Z","iopub.execute_input":"2023-10-02T17:13:26.627648Z","iopub.status.idle":"2023-10-02T17:13:26.642228Z","shell.execute_reply.started":"2023-10-02T17:13:26.627622Z","shell.execute_reply":"2023-10-02T17:13:26.641406Z"},"trusted":true},"execution_count":747,"outputs":[]},{"cell_type":"code","source":"# submission = pd.DataFrame({'id': test['id'], 'outcome': resultssss})\n# submission['outcome'] = submission['outcome'].map({1:'died',0:'euthanized',2:'lived'})\n# submission.to_csv('asd.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.643491Z","iopub.execute_input":"2023-10-02T17:13:26.644601Z","iopub.status.idle":"2023-10-02T17:13:26.655388Z","shell.execute_reply.started":"2023-10-02T17:13:26.644560Z","shell.execute_reply":"2023-10-02T17:13:26.654456Z"},"trusted":true},"execution_count":748,"outputs":[]},{"cell_type":"markdown","source":"# simple model  ensemble","metadata":{}},{"cell_type":"code","source":"\n\n# from sklearn.ensemble import (\n#     RandomForestClassifier,\n#     GradientBoostingClassifier,\n#     AdaBoostClassifier,\n#     VotingClassifier,\n# )\n\n\n# from sklearn.svm import SVC\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.tree import DecisionTreeClassifier\n# import lightgbm as lgb\n\n\n\n\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# def objective(trial):\n \n#     n_estimators = trial.suggest_int(\"n_estimators\", 50, 300)\n#     max_depth = trial.suggest_int(\"max_depth\", 2, 32, log=True)\n#     learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 1.0, log=True)\n\n\n#     model = GradientBoostingClassifier(\n#         n_estimators=n_estimators,\n#         max_depth=max_depth,\n#         learning_rate=learning_rate,\n#         random_state=42,\n#     )\n\n \n#     model.fit(X_train, y_train)\n\n \n#     y_pred = model.predict(X_test)\n#     accuracy = accuracy_score(y_test, y_pred)\n\n#     return accuracy\n\n# study = optuna.create_study(direction=\"maximize\")\n# study.optimize(objective, n_trials=100) \n\n\n# best_params = study.best_params\n# print(\"Best Hyperparameters:\", best_params)\n\n# rf = RandomForestClassifier(n_estimators=best_params[\"n_estimators\"], random_state=42)\n# svc = SVC(probability=True)\n# lr = LogisticRegression(max_iter=1000)\n# dt = DecisionTreeClassifier(max_depth=best_params[\"max_depth\"], random_state=42)\n# lgbm = lgb.LGBMClassifier(\n#     n_estimators=best_params[\"n_estimators\"],\n#     max_depth=best_params[\"max_depth\"],\n#     learning_rate=best_params[\"learning_rate\"],\n#     random_state=41,\n# )\n\n\n# ensemble = VotingClassifier(\n#     estimators=[\n#         (\"rf\", rf),\n#         (\"svc\", svc),\n#         (\"lr\", lr),\n#         (\"dt\", dt),\n#         (\"lgbm\", lgbm),\n#     ],\n#     voting=\"soft\",  \n# )\n\n# ensemble.fit(X_train, y_train)\n# ensemble_preds = ensemble.predict(X_test)\n# ensemble_accuracy = accuracy_score(y_test, ensemble_preds)\n# print(\"Ensemble Accuracy:\", ensemble_accuracy)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-10-02T17:13:26.658611Z","iopub.execute_input":"2023-10-02T17:13:26.658904Z","iopub.status.idle":"2023-10-02T17:13:26.668588Z","shell.execute_reply.started":"2023-10-02T17:13:26.658879Z","shell.execute_reply":"2023-10-02T17:13:26.667597Z"},"trusted":true},"execution_count":749,"outputs":[]},{"cell_type":"code","source":"# yz = ensemble.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.669823Z","iopub.execute_input":"2023-10-02T17:13:26.670252Z","iopub.status.idle":"2023-10-02T17:13:26.685927Z","shell.execute_reply.started":"2023-10-02T17:13:26.670214Z","shell.execute_reply":"2023-10-02T17:13:26.684851Z"},"trusted":true},"execution_count":750,"outputs":[]},{"cell_type":"code","source":"# submission = pd.DataFrame({'id': test['id'], 'outcome': yz})\n# submission['outcome'] = submission['outcome'].map({1:'died',0:'euthanized',2:'lived'})\n# submission.to_csv('asd3.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.687338Z","iopub.execute_input":"2023-10-02T17:13:26.688507Z","iopub.status.idle":"2023-10-02T17:13:26.697252Z","shell.execute_reply.started":"2023-10-02T17:13:26.688467Z","shell.execute_reply":"2023-10-02T17:13:26.696229Z"},"trusted":true},"execution_count":751,"outputs":[]},{"cell_type":"markdown","source":"# meta ensmeble","metadata":{}},{"cell_type":"markdown","source":"****this meta ensemble is working \"just fine\" but i will keep working on trying different models with different optimizations****","metadata":{}},{"cell_type":"code","source":"# from sklearn.ensemble import VotingClassifier, StackingClassifier\n# from sklearn.neighbors import KNeighborsClassifier\n# from sklearn.naive_bayes import GaussianNB\n# from sklearn.neural_network import MLPClassifier\n# from xgboost import XGBClassifier\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.svm import SVC\n\n\n# def objective(trial):\n  \n#     svc_c = trial.suggest_loguniform('svc_c', 1e-3, 1e3)\n#     lr_C = trial.suggest_loguniform('lr_C', 1e-3, 1e3)\n#     xgb_n_estimators = trial.suggest_int('xgb_n_estimators', 10, 500)\n#     lgbm_num_leaves = trial.suggest_int('lgbm_num_leaves', 2, 50)\n\n   \n#     svc = SVC(C=svc_c, probability=True)\n#     lr = LogisticRegression(C=lr_C)\n#     xgb = XGBClassifier(n_estimators=xgb_n_estimators)\n#     lgbm = LGBMClassifier(num_leaves=lgbm_num_leaves)\n\n   \n#     base_ensemble_1 = VotingClassifier(\n#         estimators=[\n#             (\"svc\", svc),\n#             (\"lr\", lr),\n#             (\"xgb\", xgb)\n#         ],\n#         voting=\"soft\"\n#     )\n\n#     base_ensemble_2 = VotingClassifier(\n#         estimators=[\n#             (\"lgbm\", lgbm)\n#         ],\n#         voting=\"soft\"\n#     )\n\n\n#     meta_ensemble = StackingClassifier(\n#         estimators=[\n#             (\"base_ensemble_1\", base_ensemble_1),\n#             (\"base_ensemble_2\", base_ensemble_2),\n          \n#         ],\n#         final_estimator=LogisticRegression()\n#     )\n\n\n#     meta_ensemble.fit(X_train, y_train)\n\n  \n#     meta_ensemble_preds = meta_ensemble.predict(X_val)\n\n   \n#     meta_ensemble_accuracy = accuracy_score(y_val, meta_ensemble_preds)\n\n#     return meta_ensemble_accuracy\n\n\n# study = optuna.create_study(direction='maximize')\n# study.optimize(objective, n_trials=100)  \n\n# best_params = study.best_params\n# print(\"Best Hyperparameters:\", best_params)\n\n\n# svc = SVC(C=best_params['svc_c'], probability=True)\n# lr = LogisticRegression(C=best_params['lr_C'])\n# xgb = XGBClassifier(n_estimators=best_params['xgb_n_estimators'])\n# lgbm = LGBMClassifier(num_leaves=best_params['lgbm_num_leaves'])\n\n\n# meta_ensemble.fit(X_train, y_train)\n\n\n# meta_ensemble_preds = meta_ensemble.predict(X_test)\n\n\n# meta_ensemble_accuracy = accuracy_score(y_test, meta_ensemble_preds)\n# print(\"Meta-Ensemble Accuracy:\", meta_ensemble_accuracy)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-10-02T17:13:26.698741Z","iopub.execute_input":"2023-10-02T17:13:26.699735Z","iopub.status.idle":"2023-10-02T17:13:26.714218Z","shell.execute_reply.started":"2023-10-02T17:13:26.699696Z","shell.execute_reply":"2023-10-02T17:13:26.713275Z"},"trusted":true},"execution_count":752,"outputs":[]},{"cell_type":"code","source":"# me=meta_ensemble.predict(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.715334Z","iopub.execute_input":"2023-10-02T17:13:26.716372Z","iopub.status.idle":"2023-10-02T17:13:26.733403Z","shell.execute_reply.started":"2023-10-02T17:13:26.716334Z","shell.execute_reply":"2023-10-02T17:13:26.732310Z"},"trusted":true},"execution_count":753,"outputs":[]},{"cell_type":"code","source":"# submission = pd.DataFrame({'id': test['id'], 'outcome': me})\n# submission['outcome'] = submission['outcome'].map({1:'died',0:'euthanized',2:'lived'})\n# submission.to_csv('meta6.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:13:26.734830Z","iopub.execute_input":"2023-10-02T17:13:26.735677Z","iopub.status.idle":"2023-10-02T17:13:26.745838Z","shell.execute_reply.started":"2023-10-02T17:13:26.735647Z","shell.execute_reply":"2023-10-02T17:13:26.745121Z"},"trusted":true},"execution_count":754,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}